# 심리측정 모듈 (Psychometric)

> **최종 업데이트**: 2026-01-07
> **관련 코드**: `src/core/irt.ts`, `src/core/quadrature.ts`, `src/core/fsrs.ts`
> **상태**: 활성

---

**네비게이션**: [이전: 기초 모듈](../00-foundation/) | [다음: 언어학 모듈](../02-linguistic/)

---

## 개요

이 문서는 LOGOS 적응형 학습 시스템의 **심리측정학적 기반**을 구성하는 세 가지 핵심 모듈을 통합적으로 설명합니다:

1. **문항반응이론 (IRT)** - 학습자 능력 추정 및 적응형 문항 선택
2. **가우스-에르미트 구적법 (Quadrature)** - 고정밀 수치 적분
3. **FSRS (Free Spaced Repetition Scheduler)** - 간격 반복 스케줄링

이 세 모듈은 함께 작동하여 개인화된 학습 경험을 제공합니다.

---

## 1. 문항반응이론 (Item Response Theory, IRT)

> **코드 위치**: `src/core/irt.ts`

### 맥락 및 목적

IRT 모듈은 LOGOS 적응형 학습 시스템의 **심리측정학적 핵심**입니다. 학습자의 응답 패턴을 기반으로 숙련도를 추정하고, 해당 숙련도 수준에 가장 적합한 문항을 선택합니다.

**비즈니스 필요성**: 언어 학습 플랫폼은 개별 학습자에게 적응해야 합니다. IRT가 없으면:
- 모든 학습자에게 동일한 문항 제공 (숙련도 차이 무시)
- "정답률"과 같은 조잡한 지표에 의존 (문항 난이도 미고려)

IRT는 **학습자 능력과 문항 난이도를 동일한 척도에 배치**하여 도전 수준을 현재 숙련도에 정밀하게 매칭합니다.

**사용 시점**:
- 모든 학습자 응답 후: 세타(Theta, 능력) 재추정
- 다음 문항 선택 시: 정보 최대화로 문항 선택 안내
- 초기 보정 중: 새로운 어휘에 대한 난이도 매개변수 설정
- 분석 시: 시간에 따른 능력 궤적 표시

### 세 가지 IRT 모델

LOGOS는 복잡성이 증가하는 세 가지 IRT 모델을 구현합니다:

#### 1PL (라쉬 모델, Rasch Model)

```
P(정답) = 1 / (1 + e^(-(theta - b)))
```

**쉬운 설명**: 문항을 맞출 확률은 그 문항이 당신의 숙련도(theta)보다 얼마나 어려운지(b)에만 의존합니다.

**용도**: 변별력이 비교적 균일한 음운론적 문항.

#### 2PL 모델

```
P(정답) = 1 / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 1PL과 유사하지만 문항마다 다른 "예리함"(a)을 가질 수 있습니다.
- a = 2.0: 가파른 곡선 - 작은 숙련도 차이가 큰 확률 변화 야기
- a = 0.5: 완만한 곡선 - 큰 숙련도 차이도 작은 확률 변화만 표시

**용도**: 변별력이 다양한 어휘 및 통사 문항.

#### 3PL 모델

```
P(정답) = c + (1-c) / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 2PL과 유사하지만 추측을 고려합니다. 매개변수 c는 추측 하한선입니다. 4지선다 문제에서 무작위 추측도 25% 정답률을 제공합니다.

**용도**: 추측이 가능한 화용론적 문항과 객관식 문제.

### 세타(Theta) 추정 방법

#### 최대우도추정 (Maximum Likelihood Estimation, MLE)

관찰된 응답 패턴을 가장 확률적으로 만드는 세타 값을 찾습니다.

**작동 방식**:
1. theta = 0으로 시작
2. 우도 함수의 기울기(그래디언트) 계산
3. 뉴턴-랩슨(Newton-Raphson) 단계로 더 가파른 우도 방향 진행
4. 수렴까지 반복

**장점**: 불편 추정량, 효율적
**약점**: 극단적 패턴(전부 정답/오답)에서 발산

**사용 시기**: 혼합된 결과가 있는 5개 이상의 응답이 있을 때.

#### 사후기대치 추정 (Expected A Posteriori, EAP)

응답과 사전 믿음이 주어졌을 때 세타의 사후 분포 평균을 계산합니다.

**작동 방식**:
1. 사전 분포 정의 (일반적으로 정규분포, 평균=0, 표준편차=1)
2. 많은 세타 값에서 사전분포와 우도를 곱함 (구적법 사용)
3. 정규화하여 사후 분포 획득
4. 사후분포의 평균 반환

**장점**: 항상 유한함, 사전 지식 통합, 적은 응답으로도 안정적
**약점**: 사전분포 쪽으로 편향됨 (축소 추정)

**사용 시기**: 항상, 특히 학습 초기나 극단적 패턴에서. **LOGOS는 EAP를 기본값으로 사용.**

### 문항 선택 전략

#### 피셔 정보량 최대화 (Fisher Information Maximization)

세타에 대한 불확실성을 가장 많이 줄여줄 문항을 선택합니다.

```
정보량
     |
     |        *****
     |      **     **
     |    **         **
     |  **             **
     | *                 *
     |*                   *
     +-------------------------> Theta
        (theta = b에서 최대)
```

**공식**: Fisher Info = a^2 * P * (1-P)

**쉬운 설명**: 성공 여부가 가장 불확실한 문항(P가 0.5 근처)을 선택합니다.

#### 쿨백-라이블러 발산 선택 (Kullback-Leibler Divergence Selection)

피셔 정보량과 유사하지만 현재 세타 추정치의 **불확실성을 고려**합니다.

**사용 시기**: 세타의 표준오차가 높을 때 (학습 초기, 적은 응답).

---

## 2. 가우스-에르미트 구적법 (Gauss-Hermite Quadrature)

> **코드 위치**: `src/core/quadrature.ts`

### 맥락 및 목적

이 모듈은 베이지안 능력 추정을 위한 **고정밀 수치 적분**을 제공합니다. 기저 적분을 해석적으로 풀 수 없을 때 EAP 추정을 계산하는 문제를 해결합니다.

**사용자 필요**:
1. **정확성** - 잘못된 추정치는 좌절스러운 경험(너무 어려움)이나 시간 낭비(너무 쉬움)로 이어짐
2. **안정성** - 극단적 응답 패턴에서도 심하게 변동하지 않아야 함
3. **속도** - 학습 세션 중 실시간으로 계산되어야 함

### 왜 가우스-에르미트인가?

베이지안 IRT에서 항상 **정규 사전 분포에 대해 적분**합니다. 가우스-에르미트 구적법은 이 특정 케이스에 수학적으로 최적입니다.

**쉬운 설명**: 곡선 아래의 면적을 측정할 때, 등간격 막대 대신 특정 "마법의" 위치에 막대를 배치하면 훨씬 적은 막대로 더 정확한 답을 얻습니다. **21개의 가우스-에르미트 점이 종종 100개 이상의 균일 점을 능가합니다.**

### 수학적 기초

**표준 가우스-에르미트 적분:**
```
integral from -infinity to +infinity of f(x) * e^{-x^2} dx ≈ sum of w_i * f(x_i)
```

**정규 사전분포에 적응:**
```
integral of f(x) * phi(x; mu, sigma) dx ≈ (1/sqrt(pi)) * sum of w_i * f(mu + sigma*sqrt(2) * x_i)
```

### 정확도 vs 점의 수

| 점의 수 | 오차 차수 | 사용 사례 |
|---------|-----------|-----------|
| 5 | O(10^-6) | 빠른 추정, 매끄러운 사후분포 |
| 11 | O(10^-12) | 실시간 피드백 |
| 21 | O(10^-24) | 표준 세션 업데이트 |
| 41 | O(10^-48) | 연구 등급 정밀도 |

### RECOMMENDED_SETTINGS 프리셋

비디오 스트리밍처럼 세 가지 "품질 수준":
- **빠름 (11개 점)**: 빠른 연습 중 실시간 피드백용
- **표준 (21개 점)**: 일반 세션 업데이트용 (속도와 정확도의 균형)
- **정밀 (41개 점)**: 최종 점수, 보고서, 연구용

---

## 3. FSRS (Free Spaced Repetition Scheduler)

> **코드 위치**: `src/core/fsrs.ts`

### 맥락 및 목적

**FSRS 모듈은 언어 습득이 근본적으로 기억 문제이기 때문에 존재합니다.**

인간의 뇌는 망각 기계입니다:
- 24시간 내에 약 70%를 잊음
- 일주일 내에 90%를 잊음

하지만 기억 과학의 반직관적인 통찰이 있습니다: **거의 잊어버릴 뻔한 것을 성공적으로 회상하는 행위가 기억을 영구적으로 만듭니다.**

FSRS는 각 지식 조각에 대해 학습자가 **다음에 언제 복습해야 하는지 정확히 예측**합니다.

### FSRS 알고리즘의 두 변수 기억 모델

| 변수 | 설명 |
|------|------|
| **안정성 (S)** | 기억이 90% 회상 확률로 쇠퇴할 때까지의 기간 |
| **난이도 (D)** | 이 학습자에게 이 항목이 본질적으로 얼마나 어려운지 |

**핵심 공식**: `검색가능성 = e^(-t/S)` (t = 경과 일수, S = 안정성)

### 망각 곡선 시각화

```
회상 확률
   1.0 |*
       |  *
   0.9 |    *       <- 목표 유지율 (90%)
       |      *
   0.7 |        *
       |          *
   0.5 |            *
       |              *
   0.3 |                *
       |                  *
   0.1 |                    *   *   *
       +----------------------------> 시간 (일)
           S         2S        3S

S = 안정성 (일)
복습은 R이 90%로 떨어질 때 스케줄됨
```

### FSRS 평점 시스템 (1-4)

| 평점 | 이름 | LOGOS 변환 |
|------|------|------------|
| 1 | Again | 오답 |
| 2 | Hard | 단서와 함께 정답 |
| 3 | Good | 정답, 단서 없이, 느림 (>5초) |
| 4 | Easy | 정답, 단서 없이, 빠름 (<=5초) |

### 숙달 단계 (0-4)와의 관계

LOGOS는 5단계 숙달 모델을 사용합니다:

| 단계 | 이름 | 기준 |
|------|------|------|
| 0 | 미지 | 한 번도 접하지 않음 |
| 1 | 인식 | cueAssistedAccuracy >= 0.5 |
| 2 | 회상 | cueFreeAccuracy >= 0.6 OR cueAssistedAccuracy >= 0.8 |
| 3 | 통제 | cueFreeAccuracy >= 0.75 AND stability > 7일 |
| 4 | 자동 | cueFreeAccuracy >= 0.9 AND stability > 30일 AND gap < 0.1 |

**FSRS 매개변수는 안정성 요구사항을 통해 단계 전환에 직접적으로 정보를 제공합니다.**

### 스캐폴딩 갭 추적

LOGOS는 두 가지 정확도 지표를 추적합니다:
- **Cue-Free 정확도**: 힌트 없이의 성능
- **Cue-Assisted 정확도**: 힌트와 함께의 성능

차이가 **스캐폴딩 갭**입니다. 단서 레벨 선택:

| 조건 | 단서 레벨 |
|------|-----------|
| Gap < 0.1 AND 시도 > 3 | 단서 없음 |
| Gap < 0.2 AND 시도 > 2 | 최소 단서 |
| Gap < 0.3 | 보통 단서 |
| Gap >= 0.3 | 전체 단서 |

---

## 코드 의존성 관계도

```
+-------------------------------------------------------------+
|                    렌더러 (React UI)                          |
|   SessionView, QuestionCard - 능력 추정치, 진행 차트 표시      |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
|                   IPC 핸들러                                  |
|   session.ipc.ts, learning.ipc.ts                            |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
|                   서비스 계층                                 |
|   scoring-update.service.ts - IRT, FSRS 사용                 |
|   task-generation.service.ts - 적응형 문항 선택               |
|   state-priority.service.ts - 우선순위 계산                   |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
|               핵심 알고리즘 계층 (이 문서)                     |
|   +---------------+  +---------------+  +---------------+    |
|   |    IRT        |  |  Quadrature   |  |    FSRS       |    |
|   | (irt.ts)      |  | (quadrature.ts)|  | (fsrs.ts)     |    |
|   +-------+-------+  +-------+-------+  +---------------+    |
|           |                  |                               |
|           +------------------+                               |
|           |                                                  |
|   EAP 추정시 구적법 사용                                      |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
|                   데이터 계층                                 |
|   Prisma/SQLite - 세타 추정치, 문항 매개변수, FSRS 카드 저장   |
+-------------------------------------------------------------+
```

### 모듈 간 관계

| 모듈 | 의존성 | 피의존성 |
|------|--------|----------|
| **IRT** | `types.ts` | g2p-irt.ts, priority.ts, task-matching.ts, quadrature.ts, 서비스 계층 |
| **Quadrature** | 없음 (순수 수학) | irt.ts (EAP 추정 향상), 서비스 계층 |
| **FSRS** | 없음 (순수 TypeScript) | 세션 관리, 숙달 상태, 우선순위 시스템 |

### 데이터 흐름

```
사용자가 문제에 답함
       |
       v
응답 기록됨 (정답/오답, 응답 시간)
       |
       +----------------+----------------+
       |                                 |
       v                                 v
[IRT: estimateThetaEAP()]        [FSRS: schedule()]
       |                                 |
       | (Quadrature 사용)               |
       v                                 v
새 세타 추정치                    새 복습 일정
       |                                 |
       +----------------+----------------+
                        |
                        v
                [selectNextItem()]
                        |
                        v
                학습자에게 다음 문항 표시
```

---

## 기술 개념 요약 (쉬운 설명)

### IRT 관련

| 개념 | 기술적 정의 | 쉬운 설명 |
|------|-------------|-----------|
| **로짓 척도** | logit(p) = ln(p/(1-p)) | 확률을 비교 가능한 척도로 변환. 세타 1.0 vs 2.0은 2.0 vs 3.0과 같은 격차. |
| **표준오차 (SE)** | 세타 추정치의 표본분포 표준편차 | 추정치에 대한 확신 정도. SE가 낮으면 확신, 높으면 불확실. |
| **변별력 (a)** | ICC의 변곡점 기울기 | 문항이 얼마나 "진단적"인지. 높으면 숙련/미숙련 명확 구분. |
| **추측 매개변수 (c)** | ICC의 하한 점근선 | 추측의 하한선. 4지선다에서 25%. |

### 구적법 관련

| 개념 | 기술적 정의 | 쉬운 설명 |
|------|-------------|-----------|
| **수치 적분** | 가중 합으로 정적분 근사 | 곡선 아래 면적을 막대로 측정. |
| **사전 계산된 노드** | 에르미트 다항식의 근 | "마법의 위치"를 미리 계산해 저장. |

### FSRS 관련

| 개념 | 기술적 정의 | 쉬운 설명 |
|------|-------------|-----------|
| **안정성 (S)** | 90% 회상 확률까지의 일수 | 잊을 때까지의 일수. 높으면 깊이 학습됨. |
| **난이도 (D)** | 0-10 척도의 학습 난이도 | 이 항목이 이 학습자에게 얼마나 어려운지. |
| **검색가능성 (R)** | 현재 회상 확률 | 지금 얼마나 기억하고 있을 것 같은지. |

---

## 성능 특성

### IRT 함수

| 함수 | 복잡도 | 일반적 시간 |
|------|--------|-------------|
| probability2PL | O(1) | < 1ms |
| estimateThetaMLE | O(n * iterations) | 50개 문항에 < 5ms |
| estimateThetaEAP | O(n * quadPoints) | 41개 점에 < 10ms |
| selectNextItem | O(n) 문항 | < 1ms |
| calibrateItems | O(n * m * iterations) | 100-500ms |

### 구적법 함수

| 함수 | 목적 |
|------|------|
| getGaussHermiteNodes(n) | n개 점에 대한 사전 계산된 노드 획득 |
| createGaussHermiteRule(n) | 완전한 구적법 규칙 생성 |
| integrateNormal(f, mean, sd, rule) | 정규 가중치에 대해 적분 |
| computeEAP(likelihood, mean, sd, rule) | 사후 평균과 표준편차 계산 |

---

## 임계 경로 분석

**중요도 수준**: 임계 (핵심 알고리즘)

### IRT가 실패하면

- 모든 능력 추정치가 틀려짐
- 세타가 무한대 또는 NaN이 됨
- 학습 효율성이 크게 떨어짐

### 구적법이 실패하면

- 세타 추정치가 사전 평균(0)으로 폴백
- 시스템이 개인화 대신 무작위 난이도의 콘텐츠 제시

### FSRS가 실패하면

- 복습 스케줄이 최적이 아니게 됨
- 이미 아는 것을 과도하게 복습하거나 잊고 있는 것을 복습하지 않음

### 처리되는 엣지 케이스

- 전부 정답/오답인 응답 패턴 (MLE 발산 방지)
- 피셔 정보량이 0인 경우 (0으로 나누기 방지)
- 빈 응답 배열 (사전 평균 반환)
- 매개변수 범위 제한 (a: [0.2, 3.0], b: [-4.0, 4.0])

---

## 학술적 참고문헌

- Bock & Mislevy (1982): IRT를 위한 원래 EAP 공식화
- Bock & Aitkin (1981): EM 보정
- Chang & Ying (1996): KL 발산 선택
- Press et al. (2007): Numerical Recipes - 가우시안 구적법 알고리즘
- Abramowitz & Stegun (1972): 노드와 가중치에 대한 표준 표

---

## 변경 이력

### 2026-01-07 - 통합 문서 생성
- **변경 내용**: IRT, 구적법, FSRS 모듈을 하나의 통합 문서로 병합
- **이유**: 심리측정 모듈 전체를 한눈에 파악할 수 있도록 구조화
- **영향**: 한국어 사용자가 LOGOS의 심리측정학적 기반을 종합적으로 이해 가능

### 2026-01-07 - 한국어 문서 생성
- **변경 내용**: 영문 문서를 한국어로 번역 및 재구성
- **이유**: 한국어 사용자를 위한 기술 문서 제공
- **영향**: 접근성 향상

---

**네비게이션**: [이전: 기초 모듈](../00-foundation/) | [다음: 언어학 모듈](../02-linguistic/)

---

*이 문서는 다음 파일들을 미러링합니다: `src/core/irt.ts`, `src/core/quadrature.ts`, `src/core/fsrs.ts`*
