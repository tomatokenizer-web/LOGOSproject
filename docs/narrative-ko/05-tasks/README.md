# 과제 시스템 (Task System)

> **최종 업데이트**: 2026-01-07
> **코드 위치**: `src/core/tasks/`, `src/core/state/`, `src/core/register/`
> **상태**: 활성화
> **구현**: Gap 4.3, Gap 4.6

---

**[이전: 콘텐츠 시스템](../04-content/) | [다음: 서비스 레이어](../06-services/)**

---

## 개요

과제 시스템(Task System)은 LOGOS 언어 학습 플랫폼의 **교육학적 두뇌**입니다. 이 시스템은 "학습자에게 다음에 어떤 연습 문제를 줄 것인가?", "어떤 단어를 선택할 것인가?", "객관식 문제의 오답은 무엇으로 할 것인가?"라는 핵심 질문에 답합니다.

과제 시스템은 세 가지 핵심 모듈로 구성됩니다:

| 모듈 | 역할 | 위치 |
|------|------|------|
| **태스크 모듈** | 30개 태스크 유형 정의 및 선택 | `src/core/tasks/` |
| **상태 모듈** | 학습 상태 추적 및 검색 | `src/core/state/` |
| **레지스터 모듈** | 화용적 적합성 분석 | `src/core/register/` |

---

## 1. 과제 생성

### 컨텍스트 및 목적

과제 생성은 학습자의 현재 수준, 학습 목표, 이전 학습 이력을 고려하여 최적의 연습 문제를 만들어내는 과정입니다. 이 과정은 무작위가 아닌 **알고리즘 기반 선택**을 통해 학습 효율을 극대화합니다.

**비즈니스 요구사항**: 언어 학습 플랫폼에서는 다양한 유형의 연습 문제가 필요합니다. 독해, 빈칸 채우기, 오류 수정 등 각 유형은 서로 다른 인지 과정을 활성화합니다. 과제 생성 시스템은 이러한 다양성을 체계적으로 관리합니다.

### 30개 전통적 태스크 유형

LOGOS는 언어 교육학 문헌에서 검증된 30개의 전통적 태스크 유형을 체계화했습니다.

| 카테고리 | 개수 | 설명 | 예시 |
|----------|------|------|------|
| **수용적 (Receptive)** | 5 | 생성 없이 이해 | 독해, 청취 이해 |
| **생산적 (Productive)** | 5 | 능동적 언어 생성 | 에세이 작성, 받아쓰기, 자유 응답 |
| **변환적 (Transformative)** | 7 | 형태 간 변환 | 번역, 바꿔 쓰기, 태 변환 |
| **빈칸 채우기 (Fill-in)** | 4 | 갭 완성 연습 | 클로즈 삭제, 단어 은행 채우기 |
| **상호작용 (Interactive)** | 4 | 대화 및 응답 | 역할극, 질문 답변 |
| **분석적 (Analytical)** | 5 | 오류 감지 및 분석 | 오류 수정, 문법 식별 |

### 태스크 유형 메타데이터

각 태스크 유형에는 다음과 같은 풍부한 메타데이터가 포함됩니다:

- **인지 과정 (Cognitive Process)**: 인식, 회상, 이해, 적용, 분석, 종합, 평가, 자동화
- **숙달 범위 (Mastery Range)**: 이 태스크가 적합한 학습 단계 (0-4)
- **구성요소 초점 (Component Focus)**: 음운적, 형태적, 어휘적, 통사적, 화용적
- **난이도 및 인지 부하 (Cognitive Load)**: 1-5 척도로 측정되는 정신적 노력
- **응답 형식 (Response Format)**: 객관식, 타이핑, 오디오 녹음 등

### 최적 태스크 선택 알고리즘

`selectOptimalTaskType()` 함수는 다음 요소를 종합적으로 고려합니다:

1. **학습자의 현재 숙달 단계**: 초보자에게 에세이 작성을 주지 않음
2. **목표 스킬**: 어떤 언어적 구성요소를 연습할 것인지
3. **다양성 요구**: 같은 유형의 연습 반복 방지
4. **특징 벡터 매칭**: 단어의 언어적 특성에 맞는 태스크 선택

**폴백 메커니즘**: 점수 계산이 실패할 경우 `cloze_deletion`(빈칸 채우기)으로 기본값을 사용하여 시스템이 항상 무언가를 생성할 수 있도록 보장합니다.

---

## 2. 제약 해결

### 컨텍스트 및 목적

**제약조건 솔버(Task Constraint Solver)**는 "학습자가 연습해야 하는 것"과 "그 필요에 맞는 콘텐츠" 사이의 다리 역할을 합니다. 연습 문제에 어떤 어휘 항목이 나타날지 선택하는 것은 무작위가 아닌, 여러 제약조건을 동시에 만족하는 최적해를 찾는 과정입니다.

**비유**: 매칭 서비스와 같습니다. 근처에 살고, 취미가 같고, 연령대가 맞고, 주말에 시간이 있는 사람을 찾는 것처럼, 여러 조건을 한 번에 만족해야 합니다.

### 제약조건 유형

#### 하드 제약조건 (Hard Constraints)
즉시 거부를 유발하는 절대적 조건:
- **숙달 범위**: 학습자 수준에 맞지 않는 항목 제외
- **도메인 요구사항**: 필수 도메인(의료, 비즈니스 등)에 속하지 않는 항목 제외
- **제외 목록**: 최근 사용된 항목 방지

#### 소프트 제약조건 (Soft Constraints)
점수에 영향을 주지만 실격시키지 않는 조건:
- **난이도 적합성**: 목표 난이도와의 근접성
- **최신성**: 최근/비최근 항목에 대한 선호도
- **복습 예정**: 간격 반복 스케줄에 따른 복습 항목 우선

### 가중 점수 공식

각 후보 객체는 0-100점의 복합 점수를 받습니다:

| 점수 요소 | 배점 | 설명 |
|-----------|------|------|
| `difficultyFit` | 0-25 | 객체 난이도가 목표와 얼마나 잘 맞는지 |
| `masteryFit` | 0-25 | 학습자의 숙달 단계와의 정렬 |
| `componentMatch` | 0-20 | 객체가 목표 구성요소를 연습하는지 |
| `domainFit` | 0-15 | 필수 도메인과의 중복 |
| `recencyScore` | 0-10 | 최근/비최근 항목에 대한 선호도 |
| `dueScore` | 0-5 | 간격 반복 복습 예정 항목에 대한 보너스 |

### 연어 보존

`requireCollocations` 옵션이 활성화되면 솔버는 선택된 객체가 최소 하나의 자연스러운 단어 쌍을 포함하도록 보장합니다. 예를 들어 "make decision", "take action"과 같은 연어 관계가 함께 선택됩니다.

---

## 3. 오답지 생성

### 컨텍스트 및 목적

**오답 생성기(Distractor Generator)**는 객관식 문제에서 그럴듯하지만 틀린 선택지를 생성합니다. 무작위 선택 대신 언어학적 관계를 활용하여 학습자의 진정한 지식을 테스트합니다.

**교육학적 통찰**: 학습자가 오답을 선택하면, 선택한 오답의 유형이 무엇을 오해하는지 드러내어 타겟 피드백을 가능하게 합니다.

### 7가지 오답 생성 전략

| 전략 | 설명 | 예시 |
|------|------|------|
| `phonological_similar` | 비슷하게 들리는 단어 | "affect" vs "effect" |
| `orthographic_similar` | 비슷한 철자 (레벤슈타인 거리) | "there" vs "their" |
| `semantic_related` | 같은 개념 필드 | "apple" vs "orange" |
| `morphological_variant` | 같은 어근의 다른 형태 | "run" vs "running" |
| `common_confusion` | L1 간섭 패턴 | "make" vs "do" (스페인어 화자) |
| `translation_false_friend` | 언어 간 거짓 동족어 | "actual" (스페인어: 현재의) |
| `random_same_pos` | 품사 매칭 폴백 | 같은 품사의 무작위 단어 |

### 그럴듯함 점수 (Plausibility Score)

각 오답에는 0-1 범위의 그럴듯함 점수가 부여됩니다:

- **높은 점수 (0.7-1.0)**: 자료를 모르는 사람이 선택할 가능성 높음 → 어려운 문제
- **중간 점수 (0.4-0.7)**: 적절한 난이도
- **낮은 점수 (0.0-0.4)**: 쉽게 제거 가능 → 쉬운 문제

### L1별 혼동 패턴

시스템은 특정 모국어 화자의 전형적인 오류 패턴을 알고 있습니다:

| L1 | 일반적 혼동 | 이유 |
|----|-------------|------|
| 스페인어 | make/do | 스페인어 "hacer"가 둘 다를 의미 |
| 중국어 | he/she | 중국어에는 성별 대명사가 없음 |
| 일본어 | l/r 발음 | 일본어에 l/r 구분 없음 |
| 한국어 | a/the | 한국어에 관사 없음 |

---

## 4. 레지스터 분석

### 컨텍스트 및 목적

**레지스터 분석**은 언어의 **화용적 능력(pragmatic competence)**을 모델링합니다. 문장은 문법적으로 완벽하면서도 사회적으로 어색할 수 있습니다. 예를 들어, 비즈니스 이메일에서 캐주얼한 속어를 사용하거나, 친구와 대화할 때 지나치게 격식적인 언어를 사용하는 경우입니다.

### 레지스터 정의

**레지스터(Register)**는 특정 사회적 상황에서 사용되는 언어 변이형입니다.

#### 격식성 수준 (Formality Level)

| 수준 | 수치 범위 | 설명 | 예시 |
|------|-----------|------|------|
| `frozen` | 0.9-1.0 | 가장 격식적, 의식적 | 법률 문서, 선서문 |
| `formal` | 0.7-0.9 | 학술, 전문 글쓰기 | 연구 논문, 공식 서한 |
| `consultative` | 0.5-0.7 | 전문적 대화 | 직장 미팅, 상담 |
| `casual` | 0.3-0.5 | 친구, 동료 | 일상 대화 |
| `intimate` | 0.0-0.3 | 가까운 가족, 파트너 | 사적 대화 |

#### 8개 사전 구축 레지스터

1. `academic_formal`: 연구 논문, 저널
2. `business_formal`: 보고서, 제안서, 공식 서신
3. `legal_frozen`: 계약서, 법령
4. `professional_consultative`: 직장 대화
5. `medical_professional`: 의료 커뮤니케이션
6. `casual_conversation`: 친구와의 일상 대화
7. `social_media_informal`: Twitter, Instagram, 문자
8. `news_journalistic`: 뉴스 보도, 보도자료

### 레지스터 적합성 분석

#### 다중 구성요소 점수 시스템 (100점 만점)

| 구성요소 | 배점 | 설명 |
|----------|------|------|
| 격식성 적합도 | 0-40 | 단어 격식성이 레지스터 격식성과 일치하는가? |
| 장르 적합도 | 0-25 | 이 단어가 이 레지스터에서 전형적인가? |
| 연어 적합도 | 0-20 | 단어가 레지스터 특정 연어를 가지는가? |
| 빈도 적합도 | 0-15 | 이 단어가 이 레지스터에서 얼마나 자주 나타나는가? |

이 분해는 뉘앙스 있는 피드백을 가능하게 합니다: "당신의 단어 선택은 격식적으로는 적합하지만 장르적으로는 비전형적입니다."

### 레지스터 언어적 특성

| 특성 | 학술 | 소셜 미디어 | 법률 |
|------|------|-------------|------|
| 평균 문장 길이 | 25단어 | 6단어 | 30단어 |
| 수동태 비율 | 25% | 5% | 45% |
| 축약형 비율 | 5% | 85% | 0% |
| 전문 용어 밀도 | 20% | 2% | 35% |

---

## 5. 상태 관리

### 컨텍스트 및 목적

**상태 모듈(State Module)**은 학습자와 언어 컴포넌트 간의 관계에 대해 시스템이 알아야 하는 모든 것을 추적합니다. 원시 노출 횟수부터 자동화 수준 및 전이 효과와 같은 정교한 인지 메트릭까지 포괄합니다.

이는 Gap 4.3 "Component-Object State Dictionary"를 직접 구현합니다.

### 핵심 상태 구조

#### 언어 컴포넌트 (Language Component)

학습 항목을 다섯 도메인으로 분류:

| 도메인 | 설명 | 예시 |
|--------|------|------|
| `g2p` | 자소-음소 대응 | 발음 규칙 |
| `morphology` | 형태론 | 접사, 굴절 |
| `lexicon` | 어휘 | 단어 의미 |
| `grammar` | 문법 | 통사 구조 |
| `pragmatics` | 화용론 | 사회적 적합성 |

#### 작업 단계 (Task Phase)

| 단계 | 목적 | 메트릭 |
|------|------|--------|
| `learning` | 초기 소개 | 노출 횟수, 최초 이해도 |
| `training` | 의도적 연습 | 정확도, 반응 시간 |
| `assessment` | 평가 | 능력 추정, 난이도 보정 |

#### 노출 패턴 (Exposure Pattern)

각 학습 상호작용에 대해 기록:
- 타임스탬프
- 작업 유형
- 양식 (시각/청각/혼합)
- 성공 여부
- 응답 시간
- 스캐폴딩 수준

### 인지 유도 메트릭

**CognitiveInduction**은 명시적에서 암시적 지식으로의 전환을 추적합니다:

| 메트릭 | 설명 | 측정 방법 |
|--------|------|-----------|
| **자동화 수준** | 지식이 얼마나 자동화되었는지 | 반응 시간 감소 추이 |
| **사용 공간 확장** | 마스터한 맥락의 다양성 | 다양한 컨텍스트에서의 성공률 |
| **절차적 유창성** | 실시간 사용의 속도/정확도 | 시간 제한 하의 정확도 |
| **스캐폴딩 갭** | 단서 보조 vs 단서 없는 정확도 차이 | 존재하지만 내재화되지 않은 지식 |

### IRT 메트릭

**문항 반응 이론(Item Response Theory)** 매개변수:

| 매개변수 | 설명 | 범위 |
|----------|------|------|
| `theta` | 학습자 능력 추정치 | [-3, 3] |
| `difficulty` | 항목 난이도 보정 | [-3, 3] |
| `discrimination` | 변별 지수 | [0, 3] |
| `standardError` | 추정의 불확실성 | [0, 1] |

### 전이 효과

**TransferEffects**는 한 항목의 학습이 다른 항목에 어떻게 영향을 미치는지 매핑:

| 전이 유형 | 설명 | 예시 |
|-----------|------|------|
| **긍정적 전이** | 학습이 다른 항목을 돕는 경우 | "un-"을 배우면 "undo", "unfair"에 도움 |
| **부정적 간섭** | 학습이 다른 항목을 방해하는 경우 | 언어 간 거짓 친구 |
| **교차 컴포넌트 전이** | 한 도메인이 다른 도메인을 돕는 경우 | 어휘 지식이 문법 습득에 기여 |

### 검색 엔진

**ComponentSearchEngine**은 수천 개의 학습 항목에 대한 효율적인 쿼리를 제공합니다.

#### 삼중 인덱싱 전략

1. **기본 인덱스**: objectId → 상태 (O(1) 조회)
2. **컴포넌트 인덱스**: 언어 컴포넌트 → objectId 집합
3. **콘텐츠 인덱스**: 토큰화된 단어 → objectId 집합

#### 검색 필터 옵션

- 컴포넌트 유형
- 텍스트 쿼리
- 최소 우선순위
- 마스터리 단계
- 자동화 수준 범위
- 노출 최근성
- 복습 상태
- 도메인 태그

#### 정렬 옵션

| 옵션 | 설명 |
|------|------|
| `priority` | 복합 우선순위 점수 |
| `frequency` | 코퍼스 빈도 |
| `mastery` | 숙달 단계 |
| `recency` | 마지막 노출 시간 |
| `alphabetical` | 알파벳순 |
| `automation` | 자동화 수준 |
| `bottleneck` | 병목 점수 (다른 학습을 차단하는 정도) |

### 우선순위 계산

`calculateEffectivePriority()` 함수는 다음 요소를 종합하여 단일 우선순위 점수를 계산:

1. **목표 컨텍스트**: 현재 학습 목표와의 관련성
2. **복습 긴급성**: FSRS 스케줄에 따른 복습 필요성
3. **자동화 필요성**: 아직 자동화되지 않은 항목
4. **전이 가치**: 다른 항목 학습에 도움이 되는 정도

---

## 시스템 아키텍처

### 계층 구조

```
+--------------------------------------------------+
|  RENDERER (UI 레이어)                             |
|  연습 문제 표시를 위한 React 컴포넌트              |
+--------------------------------------------------+
                        |
                        v
+--------------------------------------------------+
|  CORE (알고리즘 레이어) <-- 과제 시스템 위치        |
|  - tasks/ (태스크 유형, 제약 해결, 오답 생성)       |
|  - state/ (상태 추적, 검색 엔진)                   |
|  - register/ (레지스터 분석)                       |
+--------------------------------------------------+
                        |
                        v
+--------------------------------------------------+
|  MAIN (데이터 레이어)                             |
|  데이터베이스, IPC 핸들러, 서비스                  |
+--------------------------------------------------+
```

### 데이터 흐름

```
1. 학습 세션 시작
        |
        v
2. 상태 검색 엔진: 복습 필요 항목 조회
        |
        v
3. 제약 해결기: 적합한 객체 선택
        |
        v
4. 태스크 선택기: 최적 태스크 유형 결정
        |
        v
5. 오답 생성기: MCQ 선택지 생성 (필요시)
        |
        v
6. 레지스터 분석: 화용적 적합성 검증
        |
        v
7. UI 렌더링: 연습 문제 표시
        |
        v
8. 응답 수집 → 상태 업데이트
```

---

## 기술 개념 설명

### 배럴 내보내기 (Barrel Export)

**기술적**: 단일 `index.ts` 파일이 여러 내부 파일의 심볼을 다시 내보내어 통합된 공개 API를 만드는 모듈 패턴.

**쉬운 설명**: 백화점 1층과 같습니다. 고객이 신발과 전자제품을 파는 층을 알 필요 없이 입구에 안내판이 있어 모든 것을 가리킵니다. 내부 재구성이 모든 고객의 머릿속 지도를 업데이트할 필요가 없습니다.

### 제약조건 만족 (Constraint Satisfaction)

**기술적**: 점수화와 제거를 사용하여 여러 제약조건을 동시에 만족하는 값을 찾는 것.

**쉬운 설명**: 매칭 서비스처럼 근처에 살고, 취미가 같고, 연령대가 맞고, 주말에 시간이 있는 사람을 찾습니다. 단일 기준만으로는 충분하지 않고 여러 개를 한 번에 만족해야 합니다.

### 인지 부하 (Cognitive Load)

**기술적**: 작업 기억 요구에 따라 1-5 척도로 측정되는 태스크 완료에 필요한 정신적 노력.

**쉬운 설명**: 물리적 무게와 같습니다. 어떤 연습은 가볍고(인식 태스크), 다른 것들은 무거운 리프팅입니다(에세이 작성). 막 훈련을 시작한 사람에게 300파운드 데드리프트를 요청하지 않습니다.

### 지수 이동 평균 (Exponential Moving Average)

**기술적**: 최근 데이터에 더 높은 가중치를 부여하면서 과거 데이터를 점진적으로 감쇠시키는 평활화 기법.

**쉬운 설명**: 최근 시험 점수가 6개월 전 점수보다 현재 실력을 더 잘 반영한다는 원리입니다. 과거를 완전히 무시하지 않지만, 최근 성과에 더 주목합니다.

### 문항 반응 이론 (Item Response Theory)

**기술적**: 학습자의 잠재 능력과 문항의 특성(난이도, 변별도)을 동시에 추정하는 심리측정 모델.

**쉬운 설명**: 시험 문제가 너무 쉬우면 누구나 맞추고, 너무 어려우면 아무도 못 맞춥니다. IRT는 학습자의 실력과 문제의 난이도를 함께 계산하여 "이 학습자에게 이 문제가 적절한가?"를 판단합니다.

---

## 관련 문서

- [콘텐츠 시스템](../04-content/) - 교육학적 의도 및 콘텐츠 선택
- [서비스 레이어](../06-services/) - 비즈니스 로직 및 외부 연동
- [알고리즘 기초](../../ALGORITHMIC-FOUNDATIONS.md) - IRT, FSRS, PMI 상세 설명

---

## 변경 이력

### 2026-01-07 - 통합 문서 생성
- **변경 내용**: 태스크, 상태, 레지스터 모듈 문서를 단일 문서로 통합
- **이유**: 과제 시스템의 전체 흐름을 한눈에 파악할 수 있도록
- **영향**: 신규 개발자 온보딩 시간 단축

### 2026-01-04 - Gap 4.3, Gap 4.6 초기 구현
- **변경 내용**: Component-Object State Dictionary 및 전통적 태스크 유형 라이브러리 구현
- **이유**: 적응형 학습 시스템의 핵심 인프라 필요
- **영향**: 전체 애플리케이션에서 적응형 태스크 선택 가능

---

**[이전: 콘텐츠 시스템](../04-content/) | [다음: 서비스 레이어](../06-services/)**
