# 핵심 숙달 모듈 (Core Mastery Modules)

> **최종 업데이트**: 2026-01-05
> **상태**: 활성

이 문서는 LOGOS의 핵심 숙달 알고리즘을 구성하는 세 가지 모듈에 대한 종합 가이드입니다.

---

## 단계 임계값 모듈 (Stage Thresholds Module)

> **코드 위치**: `src/core/stage-thresholds.ts`

### 맥락 및 목적

이 모듈은 LOGOS에서 **학습자가 숙달 단계를 언제 진행하는지에 대한 기준**을 정의하고 관리합니다. 적응형 학습에서 핵심적인 문제를 해결합니다: 누군가가 다음 단계로 넘어갈 만큼 충분히 "학습"했는지 어떻게 판단할 것인가?

**비즈니스/사용자 요구**: 언어 학습자는 기술 수준("이 단어를 처음 봄"에서 "원어민처럼 자동으로 사용")을 통해 진행해야 하며, 이는 공정하고 과학적으로 근거가 있으며 개인의 학습 속도에 맞춰 적응해야 합니다. 적절한 임계값이 없으면 학습자가 너무 빨리 진행하거나(지식 망각으로 이어짐) 너무 느리게 진행하여(좌절감과 이탈 유발) 문제가 발생합니다.

**사용 시점**: 학습자가 연습 과제를 완료할 때마다 이 모듈이 참조됩니다. 시스템은 학습자의 성과 지표가 다음 숙달 단계로 진행하는 데 필요한 임계값을 충족하는지 확인합니다. A/B 테스트 중에도 최적의 학습 매개변수를 찾기 위해 다양한 임계값 구성을 실험하는 데 사용됩니다.

### 해결하는 문제

언어 숙달은 이진법(단어를 알거나 모르거나)이 아닙니다. LOGOS는 숙련도를 5단계 진행으로 모델링합니다:

| 단계 | 이름 | 의미 |
|------|------|------|
| 0 | 신규/미지(New/Unknown) | 이 항목을 본 적 없음 |
| 1 | 인식(Recognition) | 힌트/단서로 식별 가능 |
| 2 | 회상(Recall) | 노력하면 기억 가능 |
| 3 | 통제된 생산(Controlled Production) | 집중하면 생산 가능 |
| 4 | 자동(Automatic) | 유창하고 빠르며 단서 없이 접근 가능 |

문제는: **"충분히 좋음"을 정의하는 숫자는 무엇인가?** 75% 정확도가 필요한가 90%가 필요한가? 그 정확도를 7일간 유지해야 하는가 30일간 유지해야 하는가? 이 모듈은 이러한 질문에 대해 구성 가능하고 검증된 답변을 제공합니다.

### 핵심 개념 (기술적 + 일반 설명)

#### 단계 임계값 (Stage Thresholds)

**기술적**: 각 숙달 단계 전환에 대한 최소 성과 요구 사항을 정의하는 숫자 매개변수를 포함하는 `StageThresholds` 인터페이스.

**일반 설명**: 단계 임계값은 무술에서 벨트를 획득하기 위한 요구 사항과 같습니다. 진급하기 전에 특정 일관성 수준에서 특정 기술을 시연해야 합니다. 이러한 임계값은 "시연"과 "일관성"이 숫자로 정확히 무엇을 의미하는지 정의합니다.

**사용 이유**: 명시적인 임계값 없이는 단계 전환이 임의적이거나 일관성이 없습니다. 임계값은 기술 습득 연구(Anderson, 1982; DeKeyser, 2007)에 기반한 과학적 엄격성을 제공합니다.

#### 단서 없는 정확도 vs 단서 보조 정확도 (Cue-Free vs Cue-Assisted Accuracy)

**기술적**: 스캐폴딩(scaffolding) 없이 수행한 성과(`cueFreeAccuracy`)와 힌트, 부분 답변 또는 맥락 단서와 함께 수행한 성과(`cueAssistedAccuracy`)를 추적하는 두 개의 별도 정확도 지표.

**일반 설명**: 자전거 타기를 배운다고 상상해 보세요. 단서 보조 정확도는 보조 바퀴로 타는 것과 같습니다 - 도움을 받아 할 수 있습니다. 단서 없는 정확도는 어떤 도움도 없이 타는 것입니다. 진정한 숙달(4단계)은 높은 단서 없는 정확도와 두 점수 사이의 작은 격차를 요구하여, 더 이상 보조 바퀴에 의존하지 않음을 증명합니다.

**사용 이유**: 이러한 지표 간의 격차는 **스캐폴딩 의존성(scaffolding dependency)**을 드러냅니다 - 학습자가 독립적으로 수행할 수 있는지 아니면 여전히 도움이 필요한지. 4단계(자동)는 특별히 이 격차가 임계값(기본값: 10%) 미만이어야 합니다.

#### 안정성 (Stability)

**기술적**: 학습자가 임계값 이상의 성과를 유지한 기간을 일 단위로 측정하는 시간 기반 지표.

**일반 설명**: 신입 직원이 첫날뿐만 아니라 몇 주에 걸쳐 일관되게 잘 수행할 수 있는지 확인하는 것과 같습니다. 안정성은 지식이 일시적이지 않음을 보장합니다.

**사용 이유**: 기억 연구에 따르면 단기적인 성공이 장기적인 유지를 보장하지 않습니다. 안정성 요구 사항(3단계 7일, 4단계 30일)은 지속적인 학습을 보장합니다.

#### A/B 테스트 인프라 (A/B Testing Infrastructure)

**기술적**: 일관된 그룹 할당을 위한 결정론적 사용자 해싱과 분석을 위한 지표 수집이 있는 `ABTest`, `ABTestGroup`, `TestAssignment` 유형 시스템.

**일반 설명**: 일부 환자가 신약을 받고 다른 환자가 위약을 받는 제약 시험처럼, A/B 테스트를 통해 LOGOS는 다른 사용자 그룹에 다른 임계값 구성을 시도하여 어떤 임계값이 최상의 학습 결과를 생성하는지 과학적으로 결정할 수 있습니다.

**사용 이유**: "최적" 임계값은 확실하게 알려져 있지 않습니다. A/B 테스트는 경험적 검증을 가능하게 합니다 - 90% 정확도를 요구하면 85%를 요구하는 것보다 30일 유지율이 더 좋은가? 이 시스템을 통해 알아낼 수 있습니다.

#### 임계값 레지스트리 (Threshold Registry)

**기술적**: 구성의 런타임 캐시를 유지하고, A/B 테스트 할당을 관리하며, 지표 분석을 위해 단계 전환 이벤트를 기록하는 싱글톤 클래스(`ThresholdRegistry`).

**일반 설명**: 레지스트리는 모든 다른 임계값 "레시피"를 추적하고, 어떤 사용자가 어떤 실험 그룹에 있는지 알고, 누군가가 레벨을 올릴 때마다 연구자가 나중에 데이터를 분석할 수 있도록 기록하는 사서와 같습니다.

**사용 이유**: 임계값 관리를 중앙 집중화하여 코드 변경 없이 구성 간 런타임 전환을 가능하게 합니다.

### 마이크로스케일: 직접적인 관계

#### 의존성 (이 모듈에 필요한 것)

- `src/core/types.ts`: `MasteryStage`, `StageThresholds`, `CueLevel` - 이 모듈이 기반으로 하는 기본 타입 정의. 숫자 단계 타입(0-4), 임계값 인터페이스 구조, 단서 수준 정의를 제공합니다.

#### 종속 항목 (이 모듈을 필요로 하는 것)

- **점수/업데이트 서비스** (`src/main/services/scoring-update.service.ts`): 이 서비스는 현재 자체 로컬 `STAGE_THRESHOLDS` 상수를 정의하지만, 이상적으로는 이 모듈에서 구성 가능한 임계값을 소비해야 하는 단계 전환 로직을 구현합니다. 이는 향후 통합 지점을 나타냅니다.

- **학습 세션 흐름**: 학습자가 단계를 진행해야 하는지 확인해야 하는 모든 컴포넌트가 이 모듈에서 `checkStageTransition()`을 호출합니다.

- **분석/연구 도구**: 전환 로깅 및 지표 함수(`logTransition`, `getTransitionMetrics`, `exportTransitionLog`)는 연구 분석 파이프라인으로 데이터 내보내기를 위해 설계되었습니다.

#### 데이터 흐름

```
사용자가 과제 완료
       |
       v
사용자의 임계값 구성 가져오기 (thresholdRegistry.getConfigForUser를 통해)
       |
       v
[A/B 테스트 확인: 사용자가 실험 중인가? → 그룹에 할당 → 그룹의 구성 가져오기]
       |
       v
checkStageTransition(currentStage, metrics, config)
       |
       v
지표를 config.thresholds와 비교
       |
       v
반환: { newStage, transitioned, reason }
       |
       v
[전환된 경우: 지표 수집을 위해 logTransition()]
```

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 모듈은 LOGOS의 3계층 아키텍처에서 **핵심 알고리즘 계층(Core Algorithm Layer)**에 위치합니다:

- **계층 1 (프레젠테이션)**: 숙달 단계와 진행 막대를 표시하는 React UI 컴포넌트
- **계층 2 (핵심 알고리즘)**: **이 모듈** - 단계 전환을 결정하는 순수 로직
- **계층 3 (데이터/서비스)**: 숙달 상태를 유지하는 데이터베이스 리포지토리, Electron IPC 핸들러

이 모듈은 **프레임워크에 구애받지 않습니다** - Electron, React 또는 데이터베이스 코드가 포함되어 있지 않습니다. 모든 컨텍스트에서 호출할 수 있는 순수 함수를 내보냅니다.

#### 큰 그림 영향

단계 임계값 시스템은 LOGOS의 **적응형 학습 엔진**의 기본입니다. 이는 다음을 결정합니다:

1. **학습 속도**: 더 엄격한 임계값 = 더 느리지만 더 철저한 진행. 관대한 임계값 = 더 빠르지만 잠재적으로 얕은 학습.

2. **사용자 경험**: 단계 전환은 심리적 보상을 제공하는 "성취 순간"입니다. 너무 어려운 임계값은 좌절을 유발하고; 너무 쉬우면 관심을 잃게 됩니다.

3. **과학적 타당성**: LOGOS는 연구에 기반한다고 주장합니다. A/B 테스트 인프라는 학습 결과의 경험적 검증을 허용하여 출판 품질의 연구를 가능하게 합니다.

4. **개인화**: 다양한 구성(보수적, 공격적, 연구)을 통해 다양한 사용자 요구와 컨텍스트에 맞게 조정할 수 있습니다.

#### 중요 경로 분석

**중요도 수준**: 높음

**실패 시**:
- 단계 전환이 불가능하거나 무작위가 됨
- 사용자가 숙달 단계를 통해 진행할 수 없음
- A/B 테스트가 잘못된 데이터를 생성
- 학습 진행 지표가 무의미해짐

**실패 모드**:
- 유효하지 않은 임계값(예: 3단계 요구 사항이 4단계보다 높음) - `validateThresholds()`에 의해 방지됨
- A/B 테스트 그룹 비율이 1로 합산되지 않음 - `registerABTest()`의 검증으로 방지됨
- 사용자가 존재하지 않는 구성에 할당됨 - 구성 존재 확인으로 방지됨

**복구**:
- 사용자 정의 구성이 유효하지 않으면 내장된 'default' 구성으로 대체
- 메모리 고갈을 방지하기 위해 10,000개 이벤트 로그 제한 유지

### 사전 정의된 구성

이 모듈은 다양한 학습 컨텍스트를 위해 설계된 네 가지 내장 임계값 구성을 제공합니다:

#### 기본 구성 (Default Configuration)
엄격함과 달성 가능성의 균형을 맞춘 프로덕션 표준. 기술 습득 이론(Anderson, Segalowitz)에 기반.

| 매개변수 | 값 | 의미 |
|----------|-----|------|
| stage4CueFreeAccuracy | 90% | 도움 없이 10개 중 9개 맞춰야 함 |
| stage4Stability | 30일 | 한 달 동안 성과를 유지해야 함 |
| stage4MaxGap | 10% | 단서 보조가 단서 없는 것보다 10%만 더 좋을 수 있음 |

#### 보수적 구성 (Conservative Configuration)
진급 전 철저한 숙달을 원하는 사용자용(예: 의학 용어를 배우는 의료 전문가).

- 4단계 정확도: 95%
- 4단계 안정성: 45일
- 모든 임계값 약 10% 상향

#### 공격적 구성 (Aggressive Configuration)
빠른 학습자 또는 시간 압박 상황용(예: 생존 문구를 배우는 관광객).

- 4단계 정확도: 85%
- 4단계 안정성: 21일
- 더 빠른 진행을 위해 모든 임계값 하향

#### 연구 구성 (Research Configuration)
통계적 타당성이 가장 중요한 학술 연구를 위한 가장 엄격한 기준.

- 4단계 정확도: 95%
- 4단계 안정성: 60일
- 연구 분석을 위해 숙달 단계 간 명확한 분리 보장

### 주요 함수 설명

#### checkStageTransition()

**하는 일**: 학습자의 현재 단계와 성과 지표가 주어지면, 진급해야 하는지(또는 현재 단계에 머물러야 하는지) 결정합니다.

**작동 방식**:
1. 현재 단계의 임계값을 검색
2. 각 단계 전환(0→1, 1→2, 2→3, 3→4)에 대해 특정 기준 확인:
   - 0→1단계: 단서로 인식 가능(50% 단서 보조 정확도)
   - 1→2단계: 단서 없이 회상 시작(60% 단서 없는 OR 80% 단서 보조)
   - 2→3단계: 일관된 단서 없는 성과(75% 단서 없는 + 7일 안정성)
   - 3→4단계: 진정한 숙달(90% 단서 없는 + 30일 안정성 + <10% 스캐폴딩 격차)
3. 새 단계와 결정에 대한 사람이 읽을 수 있는 이유 반환

#### calculateStageProgress()

**하는 일**: 학습자가 다음 단계 전환에 얼마나 가까운지 보여줍니다.

**일반 설명**: 다음 레벨에 가까워질수록 채워지는 진행 막대와 같습니다. 또한 아직 충족하지 못한 특정 "차단 요소" - 요구 사항을 나열합니다.

#### getRecommendedCueLevel()

**하는 일**: 단서 없는 정확도와 단서 보조 정확도 사이의 격차에 따라 제공할 스캐폴딩/도움의 양을 제안합니다.

**일반 설명**: 누군가가 힌트 없이보다 힌트와 함께 훨씬 더 잘한다면, 시스템은 더 많은 힌트를 제공하도록 권장합니다. 격차가 좁아지면 힌트가 점진적으로 제거됩니다(보조 바퀴를 점차 떼는 것처럼).

### 학술적 기반

이 모듈의 설계는 동료 검토 연구에 기반합니다:

- **Anderson, J.R. (1982)**: 인지 기술 습득 - 선언적 지식에서 절차적 지식으로의 기술 단계 프레임워크

- **DeKeyser, R.M. (2007)**: 기술 습득 이론 - 5단계 숙달 모델을 지원하는 제2언어 학습에 대한 적용

- **Segalowitz, N. (2010)**: 제2언어 유창성의 인지적 기반 - 자동성 연구 및 단서 없는 성과 측정의 중요성

안정성 요구 사항과 정확도 임계값은 간격 반복이 며칠이 아닌 몇 주에 걸쳐 지속적인 유지를 생성한다는 기억 연구에 기반하여 경험적으로 보정되었습니다.

---

## 과제 매칭 모듈 (Task Matching Module) - z(w) 벡터 시스템

> **코드 위치**: `src/core/task-matching.ts`

### 맥락 및 목적

이 모듈은 각 단어의 언어적 특성에 따라 어휘 단어를 최적의 연습 과제 유형에 매칭하는 정교한 알고리즘을 구현합니다. 다른 단어들이 다른 유형의 연습에서 이점을 얻는다는 것을 인식하여 "모든 것에 맞는" 언어 학습의 문제를 해결합니다.

**비즈니스/사용자 요구**: 학습자가 어휘를 연습할 때 일반적인 플래시카드 훈련만 해서는 안 됩니다. 복잡한 발음을 가진 단어는 듣기/받아쓰기 연습이 필요합니다. 풍부한 연어(collocation)를 가진 단어는 맥락 연습이 필요합니다. 많은 관련 형태를 가진 단어는 단어 가족 연습이 필요합니다. 이러한 개인화는 학습 효율성과 유지력을 극적으로 향상시킵니다.

**사용 시점**: 시스템이 어휘 항목에 대해 어떤 유형의 연습을 제시할지 결정해야 할 때마다 이 모듈이 호출됩니다. 학습 세션 중에 과제 생성 서비스에 의해 호출되어 각 단어에 대해 가장 교육적으로 적절한 과제 형식을 선택합니다.

**학술적 기반**: 이 접근 방식은 Nation(2001), Laufer & Nation(2012), Schmitt(2010)의 어휘 습득 연구에 기반하며, 다양한 어휘 지식 차원(형태, 의미, 사용)에는 다양한 교육 접근 방식이 필요하다는 것을 확립합니다.

### 마이크로스케일: 직접적인 관계

#### 의존성 (이 모듈에 필요한 것)

- `src/core/types.ts`: 다음을 포함한 타입 정의 임포트:
  - `TaskType` - 15가지 다른 과제 유형(recognition, recall_cued, collocation 등)
  - `TaskFormat` - 프레젠테이션 형식(mcq, fill_blank, free_response 등)
  - `TaskModality` - 입출력 채널(visual, auditory, mixed)
  - `MasteryStage` - 학습자의 현재 숙련도 수준(0-4)
  - `LanguageObjectType` - 어휘 항목 분류(LEX, MWE, TERM 등)

#### 종속 항목 (이 모듈을 필요로 하는 것)

- `src/main/services/task-generation.service.ts`: 주요 소비자 - 이 모듈을 사용하여 각 어휘 항목에 대해 어떤 과제 유형을 생성할지 결정
- 향후 통합: 세션 오케스트레이션이 다양한 연습 세션을 구축하기 위해 배치 추천 사용
- 향후 통합: 콘텐츠 생성 파이프라인이 오디오/비주얼 콘텐츠 생성을 위해 모달리티 선호도 사용

#### 데이터 흐름

```
단어의 언어 데이터(빈도, 형태론, 음운론 등)
    |
    v
extractZVector() - 원시 지표를 0-1 스케일로 정규화
    |
    v
ZVector: { frequency, relationalDensity, domainRelevance, morphological, phonological, pragmatic }
    |
    v
calculateTaskSuitability() - 사용자의 숙달 단계에 대해 친화도 행렬 적용
    |
    v
TaskSuitabilityMap: { recognition: 0.7, collocation: 0.95, word_formation: 0.3, ... }
    |
    v
recommendTask() - 형식/모달리티와 함께 가장 높은 점수의 과제 선택
    |
    v
TaskRecommendation: { taskType, taskFormat, modality, suitability, reason, alternatives }
```

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 모듈은 LOGOS의 3계층 아키텍처에서 **핵심 알고리즘 계층(Core Algorithms Layer)** (계층 1)에 위치합니다:

- **계층 3**: UI/렌더러(사용자에게 과제 표시)
- **계층 2**: 서비스/IPC(task-generation.service.ts가 과제 생성 조율)
- **계층 1**: 핵심 알고리즘(이 모듈 - 순수 계산, I/O 없음)

이것은 데이터베이스 액세스나 외부 의존성이 없는 **순수 계산 모듈**입니다. 데이터를 받고, 계산을 수행하고, 결과를 반환합니다. 이 설계는 다음을 보장합니다:
- 테스트 가능성(모의 데이터로 유닛 테스트하기 쉬움)
- 이식성(브라우저나 서버에서 실행 가능)
- 예측 가능성(동일한 입력은 항상 동일한 출력 생성)

#### 큰 그림 영향

z(w) 벡터 과제 매칭 시스템은 LOGOS의 **적응형 학습 철학**의 핵심입니다. 이는 다음을 가능하게 합니다:

1. **개인화된 학습 경로**: 각 단어가 일반적인 훈련이 아닌 필요한 연습 유형을 얻음
2. **효율적인 시간 사용**: 학습자가 실제 지식 격차를 다루는 연습에 시간을 사용
3. **자연스러운 진행**: 숙달이 증가함에 따라 과제 유형이 인식에서 생산으로 자동 전환
4. **참여**: 과제 유형의 다양성이 지루함을 방지하고 동기 부여 유지

**시스템 의존성**:
- **업스트림**: 어휘 강화 파이프라인에서 정확한 z(w) 벡터 데이터 필요(빈도, 형태론 등)
- **다운스트림**: 과제 생성 서비스가 이러한 추천 없이는 최적의 과제를 선택할 수 없음
- **병렬**: FSRS 스케줄링(연습 시기 결정) 및 IRT(능력 측정)와 함께 작동

#### 중요 경로 분석

**중요도 수준**: 높음

- **완전히 실패 시**: 시스템이 일반적인 과제 선택으로 대체되어 개인화 이점을 잃음. 학습 효율성이 떨어지지만 앱은 기능적으로 유지됨.
- **실패 모드**: 가장 가능성 있는 실패는 새 단어에 대한 z(w) 데이터 누락 - 모든 점수를 0.5(중립)로 기본 설정하여 처리.
- **우아한 저하**: 추천이 실패하면 `recommendTask()`가 안전한 기본값(MCQ 형식의 인식 과제) 반환.

### 기술 개념 (일반 설명)

#### z(w) 벡터

**기술적**: 단어의 언어적 특성을 나타내는 6차원 벡터: 빈도(F), 관계 밀도(R), 도메인 관련성(D), 형태적 복잡성(M), 음운적 어려움(P), 화용적 민감성(PRAG). 각 차원은 0-1 스케일로 정규화됩니다.

**일반 설명**: 각 단어에 대한 "성격 프로필"로 생각하세요. 사람들에게 다양한 강점과 약점이 있는 것처럼, 단어에도 다양한 학습 과제가 있습니다. 한 단어는 흔하지만 발음하기 어려울 수 있습니다(높은 F, 높은 P). 다른 단어는 드물지만 철자하기 쉬울 수 있습니다(낮은 F, 낮은 P). z(w) 벡터는 단어를 어떻게 연습해야 하는지 결정하는 이러한 6가지 핵심 차원을 캡처합니다.

**사용 이유**: 모든 단어를 동일하게 취급하는 대신, 각 단어의 특정 과제에 연습 활동을 매칭할 수 있습니다.

#### 과제 친화도 행렬 (Task Affinity Matrix)

**기술적**: z(w) 구성 요소에서 과제 유형으로의 가중 매핑으로, 각 셀은 특정 과제 유형이 해당 z(w) 차원의 높은 값에서 얼마나 이점을 얻는지 나타냅니다. 예: `collocation` 과제는 `relationalDensity`에 대해 0.95 친화도를 갖습니다. 자연스러운 단어 파트너가 많은 단어가 연어 연습에서 가장 이점을 얻기 때문입니다.

**일반 설명**: 매칭 테이블과 같습니다. 단어가 "다른 단어와 친구가 되기를 잘함"(높은 관계 밀도)이면, 테이블은 "이 단어는 연어 연습을 해야 함"이라고 말합니다. 단어가 "발음하기 어려움"(높은 음운적 어려움)이면, 테이블은 "이 단어는 발음 연습이 필요함"이라고 말합니다.

**사용 이유**: 어떤 연습 유형이 어떤 유형의 단어에 가장 적합한지에 대한 전문 언어학 지식을 인코딩합니다.

#### 숙달 단계 제약 (Mastery Stage Constraints)

**기술적**: 숙달 단계(0-4)에서 사용 가능한 과제 유형으로의 매핑으로, 학습자가 회상하기 전에 인식해야 하고, 생산하기 전에 회상해야 한다는 교육적 원칙을 구현합니다.

**일반 설명**: 운전을 배우는 것처럼 - 고속도로 합류로 시작할 수 없습니다. 먼저 교통 표지판을 인식하는 것을 배우고(0-1단계), 그다음 조용한 주차장에서 평행 주차(2-3단계), 그다음 고속도로 운전(4단계). 마찬가지로, 0단계 학습자는 인식 과제(객관식)만 할 수 있고, 4단계 학습자는 레지스터 전환과 빠른 응답을 할 수 있습니다.

**사용 이유**: 너무 고급인 과제로 인한 좌절과 너무 쉬운 과제로 인한 지루함을 방지합니다.

#### 다양성 강제가 있는 배치 추천 (Batch Recommendation with Variety Enforcement)

**기술적**: `recommendTaskBatch()` 함수는 과제 유형 수를 추적하고 유형이 너무 자주 나타나면 대안으로 대체하면서(configurable via `maxPerType` 매개변수) 여러 단어에 대한 추천을 생성합니다.

**일반 설명**: 계속 주문해도 같은 요리를 연속으로 세 번 제공하지 않는 레스토랑과 같습니다. 알고리즘이 계속 "연어" 과제를 추천하면, 결국 연습을 다양하고 흥미롭게 유지하기 위해 다음으로 좋은 과제 유형으로 전환합니다.

**사용 이유**: 단조로운 연습은 참여를 저하시킵니다. 다양성은 주의를 유지하고 여러 인지 경로를 연습합니다.

#### 지배적 구성 요소 감지 (Dominant Component Detection)

**기술적**: `getDominantComponent()` 함수는 단어에 대해 어떤 z(w) 차원이 가장 높은 값을 갖는지 식별하여 주요 모달리티를 결정하고 사람이 읽을 수 있는 추천 이유를 생성하는 데 사용됩니다.

**일반 설명**: 단어의 "주요 과제"를 찾습니다. 음운 점수가 가장 높으면 단어의 주요 과제는 발음입니다. 이는 "이 단어를 오디오로 연습해야 하나 텍스트로 연습해야 하나?"와 같은 결정을 안내합니다.

**사용 이유**: 시스템이 단어의 주요 특성 관점에서 추천을 설명할 수 있게 합니다.

### 주요 함수 설명

#### `calculateTaskSuitability(zVector, masteryStage)`

**하는 일**: 단어의 z(w) 프로필과 학습자의 현재 숙달 단계를 받아, 각각이 얼마나 적합한지 나타내는 모든 15개 과제 유형에 대한 점수를 반환합니다.

**알고리즘**:
1. 각 과제 유형에 대해 각 z(w) 구성 요소에 친화도 점수를 곱함
2. 이러한 가중 값을 합산
3. 총 친화도 가중치로 정규화
4. 과제가 학습자의 숙달 단계에서 사용 불가능하면 90% 페널티 적용

**출력 예시**:
```
{ recognition: 0.52, recall_cued: 0.48, collocation: 0.81, word_formation: 0.22, ... }
```

#### `recommendTask(profile)`

**하는 일**: 완전한 단어 프로필이 주어지면, 형식, 모달리티, 설명과 함께 단일 최고의 과제 추천을 반환합니다.

**결정 과정**:
1. 모든 과제 유형에 대한 적합성 점수 계산
2. 0.1 미만 점수의 과제 필터링(본질적으로 사용 불가)
3. 가장 높은 점수의 과제 선택
4. 지배적 z(w) 구성 요소에 따라 모달리티 선택
5. 사람이 읽을 수 있는 이유 생성
6. 대안(2번째, 3번째, 4번째 최고 옵션)과 함께 패키징

#### `extractZVector(object, targetDomain?)`

**하는 일**: 원시 데이터베이스 필드를 정규화된 z(w) 벡터로 변환합니다. 누락된 데이터는 0.5(중립)로 기본 설정하여 처리합니다.

**정규화**: 모든 입력 지표는 이미 0-1 정규화되어 있어야 합니다. 도메인 관련성은 제공된 경우 JSON 분포 객체에서 추출됩니다.

### 설계 결정 및 근거

#### 왜 6차원인가?

z(w) 벡터 차원은 확립된 어휘 습득 연구에 기반하여 선택되었습니다:
- **빈도(Frequency)**: 고빈도 단어는 자동성이 필요; 저빈도 단어는 명시적 교육이 필요
- **관계 밀도(Relational Density)**: 풍부하게 연어하는 단어는 맥락적 연습이 필요
- **도메인 관련성(Domain Relevance)**: 기술 용어는 도메인별 맥락이 필요
- **형태적(Morphological)**: 많은 형태를 가진 단어(run, ran, running)는 단어 가족 연습이 필요
- **음운적(Phonological)**: 어려운 소리를 가진 단어는 발음 집중이 필요
- **화용적(Pragmatic)**: 레지스터에 민감한 단어는 적절성 연습이 필요

#### 왜 0-1 정규화인가?

모든 차원을 동일한 스케일로 정규화하면 다음이 가능합니다:
- 차원 간 공정한 비교
- 친화도 행렬에서 간단한 가중 평균
- 일관된 해석(0.8은 모든 차원에서 "높음")

#### 왜 0.5로 기본 설정하는가?

데이터가 누락되면 0.5(중립)가 0(부재)보다 안전합니다:
- 어떤 과제 유형도 인위적으로 억제하지 않음
- 누락되지 않은 데이터가 추천을 주도하게 함
- 자주 누락되는 지표와 상관관계가 있는 과제에 대한 편향을 피함

### 참고 문헌

- Nation, I.S.P. (2001). *Learning Vocabulary in Another Language*. Cambridge University Press.
- Laufer, B. & Nation, P. (2012). Vocabulary. In Gass & Mackey (Eds.), *The Routledge Handbook of Second Language Acquisition*.
- Schmitt, N. (2010). *Researching Vocabulary: A Vocabulary Research Manual*. Palgrave Macmillan.

---

## 응답 타이밍 모듈 (Response Timing Module)

> **코드 위치**: `src/core/response-timing.ts`

### 맥락 및 목적

이 모듈은 원시 응답 시간을 의미 있는 학습 신호로 변환합니다. 사용자가 어휘 질문에 답할 때, 응답하는 데 걸리는 시간은 단순한 정확성을 훨씬 넘어서는 인지 처리에 대한 중요한 정보를 드러냅니다.

**비즈니스/사용자 요구**: 언어 학습 애플리케이션은 일반적으로 답이 맞는지 틀린지만 추적합니다. 하지만 10초 걸린 정답은 800밀리초 걸린 답과 매우 다른 지식을 나타냅니다. LOGOS는 다음을 구별해야 합니다:
- **자동 지식(Automatic knowledge)**: 깊은 학습을 나타내는 빠르고 유창한 응답
- **노력적 검색(Effortful retrieval)**: 취약한 기억 흔적을 시사하는 느리지만 정확한 응답
- **운 좋은 추측(Lucky guesses)**: 객관식 질문에서 의심스러울 정도로 빠른 응답
- **게이밍 행동(Gaming behavior)**: 사용자가 시스템을 속이려 한다는 것을 시사하는 로봇 같은 패턴

응답 타이밍 모듈은 원시 밀리초 측정과 간격 반복 알고리즘(FSRS)을 구동하는 교육적으로 의미 있는 분류 사이의 격차를 연결합니다.

**사용 시점**: 사용자가 학습 과제를 완료할 때마다. 응답 시간이 캡처되고, 연구에 기반한 임계값에 대해 분석되고, 항목이 다음에 검토될 시기에 영향을 미치는 FSRS 등급으로 변환됩니다.

### 마이크로스케일: 직접적인 관계

#### 의존성 (이 모듈에 필요한 것)

- `src/core/types.ts`: 기본 타입 정의 임포트
  - `TaskFormat`: 과제의 프레젠테이션 형식(mcq, fill_blank, free_response, matching, ordering, dictation)
  - `TaskType`: 과제의 인지 유형(recognition, recall, production, timed)
  - `MasteryStage`: 사용자가 항목을 얼마나 잘 알고 있는지 나타내는 0-4 진행 스케일
  - `FSRSRating`: FSRS 스케줄링 알고리즘에서 사용하는 1-4 등급 스케일

#### 종속 항목 (이 모듈을 필요로 하는 것)

현재 이 모듈은 다음에서 소비되도록 설계되었습니다:

- `src/main/services/scoring-update.service.ts`: 사용자 응답을 처리하고 숙달 상태를 업데이트하는 서비스. 응답이 제출되면 이 서비스는 `calculateFSRSRatingWithTiming()`을 사용하여 응답 시간을 적절한 FSRS 등급으로 변환할 수 있습니다.

- `src/main/ipc/learning.ipc.ts`와의 향후 통합: IPC 핸들러가 렌더러 프로세스에서 학습 응답을 처리할 때 이 모듈을 호출합니다.

- `src/renderer/components/session/*`과의 향후 통합: 세션 컴포넌트가 유창성 지표를 사용하여 진행 표시기를 표시할 수 있습니다.

#### 데이터 흐름

```
사용자가 과제 완료
        |
        v
응답 시간 (ms) 캡처
        |
        v
getTaskCategory()가 과제 유형 결정
        |
        v
getAdjustedThresholds()가 개인화된 임계값 계산
  - 과제 카테고리 기반(인식 vs 생산)
  - 숙달 단계에 맞게 조정(초보자에게 관대)
  - 단어 길이에 맞게 조정(긴 단어 = 더 많은 시간)
        |
        v
analyzeResponseTime()이 응답 분류
  - too_fast / fast / good / slow / very_slow
  - 자동성 감지
  - 잠재적 추측 플래그
        |
        v
calculateFSRSRatingWithTiming()이 FSRS 등급(1-4) 생성
        |
        v
FSRS 알고리즘이 등급을 사용하여 다음 검토 스케줄
```

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 모듈은 LOGOS 아키텍처의 **핵심 알고리즘 계층(Core Algorithm Layer)**에 위치합니다:

```
계층 1: 렌더러(React UI) - 사용자가 과제를 보고 응답 입력
    |
계층 2: IPC 브릿지 - 응답이 메인 프로세스로 전송
    |
계층 3: 서비스 - scoring-update.service가 조율
    |
계층 4: 핵심 알고리즘 - 이 모듈이 여기에 위치
    |              irt.ts, fsrs.ts, pmi.ts와 함께
    |
계층 5: 데이터베이스 - 숙달 상태 저장
```

응답 타이밍 모듈은 부작용이 없는 **순수 함수 라이브러리**입니다. 입력(응답 시간, 과제 유형, 숙달 단계)을 받고 출력(분석, 등급)을 반환합니다. 이는 높은 테스트 가능성과 이식성을 보장합니다.

#### 큰 그림 영향

응답 타이밍은 FSRS 알고리즘이 속지 않도록 하는 **품질 신호**입니다. 이것이 없으면:

- 모든 MCQ에서 정확하게 추측하는 사용자가 실제로 자료를 알고 있는 것처럼 진행됨
- 30초 동안 고군분투하다가 결국 정답을 맞힌 사용자가 즉시 답한 사람과 같은 스케줄링을 받음
- 지식이 자동화되었을 때(언어 학습의 궁극적 목표)를 감지할 방법이 없음

이 모듈은 LOGOS가 제2언어 습득 연구의 개념인 **자동성 추적(automaticity tracking)**을 구현할 수 있게 합니다. 노력적 검색에서 자동적 접근으로의 전환은 진정한 언어 숙련도의 특징입니다.

**시스템 의존성**:

| 컴포넌트 | 의존성 유형 | 응답 타이밍 실패 시 영향 |
|----------|------------|-------------------------|
| FSRS 스케줄링 | 직접 | 최적이 아닌 복습 간격 |
| 숙달 단계 감지 | 간접 | 4단계(자동) 신뢰성 저하 |
| 세션 분석 | 직접 | 유창성 지표 사용 불가 |
| 안티-게이밍 감지 | 중요 | 부정행위 감지 불가 |

#### 중요 경로 분석

**중요도 수준**: 중상

- **완전히 실패 시**: FSRS가 정확성만의 등급으로 대체, 학습은 계속되지만 최적이 아님
- **임계값이 잘못 보정된 경우**: 사용자가 자동 또는 고군분투로 잘못 분류될 수 있음
- **우아한 저하**: 모든 함수에 합리적인 기본값이 있고 엣지 케이스 처리

### 기술 개념 (일반 설명)

#### 어휘 결정 과제 임계값 (Lexical Decision Task Thresholds)

**기술적**: 참가자가 문자열이 실제 단어인지 빠르게 결정해야 하는 어휘 결정 과제(LDT)에 대한 심리언어학 연구에서 도출된 응답 시간 임계값.

**일반 설명**: 과학자들은 수십 년 동안 사람들이 얼마나 빨리 단어를 인식하는지 측정해 왔습니다. 원어민 영어 화자는 일반적으로 고빈도 단어를 400-600밀리초에 인식합니다. 제2언어 학습자는 숙련도에 따라 일반적으로 600-1500ms가 더 걸립니다. 이러한 연구 결과가 LOGOS의 "얼마나 빨라야 충분히 빠른가" 판단의 기초를 형성합니다.

**사용 이유**: 임의의 임계값을 발명하는 대신, 동료 검토 연구(Yap & Balota, 2015; Harrington, 2006; Segalowitz & Hulstijn, 2005)에서 경험적으로 검증된 타이밍 벤치마크를 사용합니다.

#### 과제 카테고리 (Task Categories)

**기술적**: 과제 형식을 인지 처리 카테고리로 그룹화하는 분류 시스템: 인식(recognition, 식별), 회상(recall, 검색), 생산(production, 생성), 시간제한(timed, 유창성 중심).

**일반 설명**:
- **인식 과제**(객관식 같은)는 군중 속에서 친구의 얼굴을 인식하는 것과 같음 - 보는 것을 아는 것과 매칭하면 됨
- **회상 과제**(빈칸 채우기 같은)는 친구를 볼 때 그 친구의 이름을 기억하는 것과 같음 - 정보를 검색해야 함
- **생산 과제**(문장 쓰기 같은)는 친구를 누군가에게 소개하는 것과 같음 - 처음부터 언어를 생성해야 함
- **시간제한 과제**는 지식이 자동적인지 테스트하도록 특별히 설계됨

**사용 이유**: 다른 인지 과정은 근본적으로 다른 시간 프로필을 갖습니다. 사용자가 500ms에 문장을 쓰기를 기대하는 것은 불합리합니다; 15초에 단어를 인식하기를 기대하는 것은 문제를 시사합니다.

#### 숙달 단계 수정자 (Mastery Stage Modifiers)

**기술적**: 학습자의 항목에 대한 현재 숙달 단계에 따라 기본 임계값에 적용되는 곱셈 조정 인자(0.8 ~ 2.0).

**일반 설명**: 초보자에게 더 여유를 줍니다. 어제 막 단어를 배웠다면, 몇 달 동안 알고 있던 단어만큼 빨리 응답할 것을 기대하지 않습니다. 수정자는:
- 0단계(신규): 2배 더 많은 시간 허용
- 1단계(인식): 1.5배 더 많은 시간
- 2단계(회상): 1.2배 더 많은 시간
- 3단계(통제): 정상 시간
- 4단계(자동): 0.8배 시간(더 빠른 응답 기대)

**사용 이유**: 공정한 평가는 학습 단계를 고려해야 합니다. 잘 알려진 단어에 "느린" 2초 응답은 새로 소개된 단어에는 "좋은" 것일 수 있습니다.

#### 자동성 감지 (Automaticity Detection)

**기술적**: 응답 시간이 카테고리별 임계값(인식 1000ms, 회상 2000ms, 생산 4000ms) 미만인지와 정확성이 결합된 불리언 분류.

**일반 설명**: 진정한 언어 유창성은 생각할 필요가 없다는 것을 의미합니다. "the cat sat on the"를 읽을 때 다음 단어가 "mat"이나 "floor" 같은 것이어야 한다는 것을 즉시 알 수 있습니다 - 의식적으로 기억을 검색하지 않습니다. 자동성 감지는 응답이 이러한 무의식적이고 유창한 처리를 시사할 만큼 충분히 빠르게 일어나는 때를 식별합니다.

**사용 이유**: 4단계 숙달(자동)은 학습자가 지식에 빠르고 쉬운 접근을 시연할 때만 부여되어야 합니다. 이는 누군가가 어휘를 알지만 실제로 실시간 대화에서 사용할 수 없는 "종이 유창성(paper fluency)"을 방지합니다.

#### 변동 계수 (Coefficient of Variation)

**기술적**: 표준 편차 대 평균의 비율(CV = sigma / mu)로, 유창성 지표에서 응답 시간 일관성을 측정하는 데 사용됩니다.

**일반 설명**: 10개의 질문에 [800, 850, 790, 810, 820, 805, 795, 830, 815, 785] 밀리초의 시간으로 응답하면, 응답이 매우 일관적입니다. 시간이 [500, 2000, 800, 3500, 400, 1900, 600, 2800, 450, 1700]이면, 전혀 일관적이지 않습니다. 변동 계수는 이 일관성을 캡처합니다 - 낮은 숫자는 더 일관적(따라서 더 자동적)인 응답을 의미합니다.

**사용 이유**: 자동 지식은 속도뿐만 아니라 일관성으로도 특징지어집니다. 낮은 CV는 지식에 대한 안정적이고 신뢰할 수 있는 접근을 나타냅니다.

#### 추측 감지 (Guessing Detection)

**기술적**: "빠른" 임계값 미만의 응답 시간 AND (과제가 인식 유형 OR 응답이 틀림)에 기반한 휴리스틱 분류.

**일반 설명**: 누군가가 객관식 질문에 300ms에 답하고 맞추면, 실제로 답을 알고 있을 수도 있고 - 무작위로 클릭해서 운 좋게 맞았을 수도 있습니다. 4지선다 MCQ에서 무작위 추측은 25%의 정답 확률을 제공합니다. 의심스럽게 빠른 응답에 플래그를 달아 시스템이 운 좋은 추측에 높은 등급을 보상하지 않도록 합니다.

**사용 이유**: 간격 반복 시스템의 게이밍을 방지합니다. 추측이 보상되면, 사용자는 실제로 배우지 않고 항목을 진행시킬 수 있고, 언어를 생산하라고 요청받을 때 치명적으로 실패합니다.

#### 봇/부정행위 패턴 감지 (Bot/Cheating Pattern Detection)

**기술적**: 비인간적이거나 게이밍 행동을 식별하기 위한 응답 시퀀스의 다중 패턴 분석: 균일한 타이밍(로봇), 모두 빠르고 높은 정확도(봇), 모두 빠르고 낮은 정확도(무작위 클릭).

**일반 설명**:
- **로봇 타이밍**: 인간의 응답 시간은 자연스럽게 다릅니다. 누군가가 10개의 질문에 정확히 1000ms로 연속 응답하면, 뭔가 이상합니다.
- **봇 패턴**: 매우 높은 정확도와 함께 극도로 빠른 응답은 자동화 또는 답을 찾아보는 것을 시사합니다.
- **무작위 클릭**: 매우 낮은 정확도와 함께 극도로 빠른 응답은 사용자가 시도하지 않고 그냥 클릭하고 있음을 시사합니다.

**사용 이유**: 학습 데이터의 무결성을 보호합니다. 사용자가 시스템을 게이밍하면, 그들의 숙달 기록은 의미가 없어지고, 전체 적응 시스템이 무너집니다.

### 학술적 기반

이 모듈은 확립된 심리언어학 연구에 기반합니다:

| 연구 분야 | 주요 발견 | LOGOS 사용 방법 |
|-----------|----------|-----------------|
| 어휘 결정 과제 | 원어민 화자: 고빈도 단어에 400-600ms | 인식 과제의 기본 임계값 |
| L2 처리 | 숙련된 L2 화자: 600-900ms | 학습자를 위한 조정된 임계값 |
| 자동성 이론 | <1000ms 인식은 자동 접근을 나타냄 | 4단계 게이팅 기준 |
| 생산 vs 인식 | 생산은 인식보다 1.5-3배 더 오래 걸림 | 과제 카테고리별 다른 임계값 |

**주요 인용**:
- Yap, M.J. & Balota, D.A. (2015). Visual word recognition. Oxford Handbook of Reading.
- Harrington, M. (2006). The lexical decision task as a measure of L2 lexical proficiency. EUROSLA Yearbook.
- Segalowitz, N. & Hulstijn, J. (2005). Automaticity in bilingualism and second language learning.

---

## 변경 이력

### 2026-01-07 - 한국어 번역 문서 생성
- **변경 내용**: 세 가지 핵심 모듈의 한국어 번역 문서 생성
- **이유**: 한국어 사용자를 위한 문서 접근성 향상
- **영향**: 비영어권 개발자와 이해관계자의 시스템 이해 지원

### 2026-01-05 - 원본 문서 생성
- **변경 내용**: stage-thresholds, task-matching, response-timing 모듈의 초기 내러티브 문서화
- **이유**: 섀도우 문서화 시스템 구현
- **영향**: 새로운 개발자와 비기술 이해관계자가 모듈 목적을 이해할 수 있게 함
