# 핵심 서비스 계층 (Core Services)

> **최종 수정**: 2026-01-06
> **원본 위치**: `src/main/services/`

---

## 서비스 인덱스 (Services Index)

> **코드 위치**: `src/main/services/index.ts`

### 존재 이유

LOGOS는 문항반응이론(IRT), 간격반복(FSRS), 점별상호정보(PMI), Claude AI 등 여러 알고리즘을 사용하는 적응형 학습 엔진이다. 이 인덱스 파일은 모든 서비스 기능을 단일 진입점에서 조직하고 재내보내기(re-export)하는 **중앙 허브** 역할을 한다.

**비즈니스 영향**: 개발 속도 향상. 새 기능 구축 시 이 파일만 참조하면 사용 가능한 서비스, 타입, 함수를 파악할 수 있다.

### 핵심 개념

**3계층 학습 파이프라인(Three-Layer Learning Pipeline)**:
1. **계층 1 (상태+우선순위)**: 학습자 능력(theta) 계산, 다음 학습 항목 결정
2. **계층 2 (과제 생성)**: 숙달 수준과 학습 모드에 맞는 연습 생성
3. **계층 3 (채점+업데이트)**: 응답 평가, 숙달 상태 갱신

**유창성 vs 다양성 균형(Fluency vs Versatility)**:
- 유창성 과제: 빠른 자동 회상 훈련 (예: 반복 스케일 연습)
- 다양성 과제: 새 맥락에 전이/적용 훈련 (예: 새로운 곡 학습)

**코퍼스 파이프라인(Corpus Pipeline)**: Wikipedia, Wiktionary, PubMed 등에서 어휘를 가져와 중복 제거, 언어적 지표(PMI, 형태론적 복잡도) 계산 후 DB에 저장.

**오프라인 큐(Offline Queue)**: Claude API 호출이 필요한 작업을 큐에 저장, 연결 가능 시 실행. 지수 백오프로 재시도.

### 설계 결정

| 결정 | 이유 |
|------|------|
| 타입과 함수를 함께 내보내기 | 소비자가 단일 소스에서 모든 것을 가져올 수 있음 |
| 파이프라인 계층별 구성 | 아키텍처가 코드에서 바로 보임 (알파벳순 대신) |
| 모든 것 재내보내기 | 단순성과 발견 가능성 (비공개는 소스 파일에서 처리) |
| 코퍼스 모듈 분리 (Registry, Filter, Pipeline) | 단일 책임 원칙 |

### 재내보내기 서비스 모듈

| 모듈 | 목적 |
|------|------|
| `state-priority.service` | 계층 1: 학습자 상태 및 항목 우선순위 |
| `task-generation.service` | 계층 2: 학습 과제 생성 |
| `scoring-update.service` | 계층 3: 응답 평가 및 숙달 갱신 |
| `fluency-versatility.service` | 3.4단계: 훈련 모드 균형 |
| `pmi.service` | 어휘 관계 분석 |
| `corpus-sources/*` | 코퍼스 소스 카탈로그, 필터링, 파이프라인 |
| `offline-queue.service` | 오프라인 작업 큐잉 |
| `claude.service` | Claude AI 통합 |

---

## 과제 생성 서비스 (Task Generation Service) - 계층 2

> **코드 위치**: `src/main/services/task-generation.service.ts`
> **단계**: 3.2

### 맥락 및 목적

계층 1이 **무엇을** 가르칠지 결정하면, 계층 2는 **어떻게** 가르칠지 결정한다. 학습 큐 항목을 학습자가 실제로 보고 응답하는 구체적 과제로 변환한다.

**비즈니스 필요**: 같은 플래시카드 형식 반복은 비효과적. 숙달 단계에 맞는 적응형 과제 형식, 필요시 힌트 제공, 역량 성장에 따른 지원 축소가 필요.

### 데이터 흐름

```
LearningQueueItem (계층 1에서)
        |
        v
generateTaskSpec() - 형식, 힌트 수준, 난이도 결정
        |
        v
generateTask() - 프롬프트, 옵션, 힌트로 전체 과제 생성
        |
        v
cacheTask() - 향후 조회용 저장
        |
        v
GeneratedTask (UI 계층으로)
```

### 기술 개념

**과제 형식 진행(Task Format Progression)**: 숙달 단계 0-4에 따라 난이도 증가:
- MCQ(선다형) -> 빈칸채우기 -> 매칭 -> 순서배열 -> 자유응답

**힌트 수준 시스템(Cue Level System) - Gap 2.4 알고리즘**: 0-3 정수 척도로 비계(scaffolding) 강도 표현. 힌트 있을 때와 없을 때 정확도 차이(scaffolding gap)에서 계산.

| 수준 | 학습자가 보는 것 |
|------|-----------------|
| 0 | 힌트 없음 - 완전 회상 필요 |
| 1 | 최소 힌트: "A로 시작" |
| 2 | 중간 힌트: "7글자, App..." |
| 3 | 완전 비계: "App____" (절반 노출) |

**유창성 vs 다양성 과제**: 유창성 과제는 고-PMI(자주 공기하는) 단어쌍 강화, 다양성 과제는 새로운 조합 도입.

**IRT 기반 난이도 계산**: `IRT 난이도 + 형식 수정자 + 힌트 수정자`. 형식 수정자는 산출 과제에서 증가, 힌트 수정자는 힌트 제공 시 감소.

**과제 캐싱**: `CachedTask` 테이블에 복합 키(objectId + taskType + taskFormat)와 만료 타임스탬프로 저장. 24시간 후 "신선하지 않음"으로 간주.

**MCQ 오답지 생성**: 동일 목표 내 같은 유형의 언어 객체를 빈도순 조회, 셔플 후 선택. 그럴듯한 오답으로 사고 유도.

### 설정 옵션

| 옵션 | 타입 | 기본값 | 효과 |
|------|------|--------|------|
| `preferredModality` | 'visual'/'auditory'/'mixed' | 'visual' | 과제 내용 표시 모드 |
| `maxCueLevel` | 0-3 | 3 | 알고리즘이 제안해도 비계 상한 |
| `fluencyRatio` | 0-1 | 0.6 | 유창성 vs 다양성 과제 비율 |
| `difficultyAdjustment` | -1~1 | 0 | IRT 난이도 수동 오프셋 |

---

## 채점+업데이트 서비스 (Scoring + Update Service) - 계층 3

> **코드 위치**: `src/main/services/scoring-update.service.ts`
> **단계**: 3.3

### 맥락 및 목적

핵심 질문 답변: *"학습자가 어떻게 했고, 결과로 무엇이 바뀌어야 하는가?"*

적응형 학습 루프를 완성하는 **피드백 처리기**. 응답 포착, 정확성 평가, 모든 숙달 추적 시스템 갱신, 미래 학습을 주도하는 우선순위 계산에 업데이트 피드백.

**비즈니스 필요**: 정확한 응답 평가와 체계적 숙달 갱신 없이는 적응 불가. 동사 활용에 어려움 겪는 학습자가 계속 같은 비효과적 과제를 받거나, 어휘를 숙달한 학습자가 이미 아는 자료를 복습하게 됨.

### 데이터 흐름

```
사용자 응답 (텍스트)
        |
        v
evaluateResponse() --> 예상 답과 비교
        |
        +-- 정확히 일치? --> correct: true, partialCredit: 1.0
        +-- 90%+ 유사? --> correct: true, partialCredit: 0.95
        +-- 70%+ 유사? --> correct: false, partialCredit: 0.7
        +-- 그 외 --> analyzeError() --> 오류 유형 분류
        |
        v
recordResponse() --> 세션 이력에 저장
        |
        v
recordExposure() --> 정확도 지표(EMA) 갱신
        |
        v
determineStageTransition() --> 승급/강등 임계값 확인
        |
        v
calculateFSRSUpdate() --> 새 안정성, 난이도, 다음 복습 계산
        |
        v
calculateEffectivePriority() --> 항목 우선순위 재계산
        |
        v
calculateThetaContribution() --> IRT 능력 갱신 (학습 모드 제외)
        |
        v
createErrorAnalysis() --> (오답 시) 오류 분류 및 저장
        |
        v
ResponseOutcome --> 호출자에게 반환
```

### 기술 개념

**부분 점수 응답 평가**: 텍스트 정규화(소문자, 공백 제거, 구두점 제거) 후 레벤슈타인(Levenshtein) 기반 유사도 계산. 설정된 임계값에 따라 부분 점수 부여.

**레벤슈타인 거리**: 한 문자열을 다른 문자열로 변환하는 데 필요한 최소 단일 문자 편집(삽입, 삭제, 치환) 수. 유사도 = `1 - (거리 / 최대길이)`.

**오류 유형 분석**:
- `spelling`: 같은 길이, 몇 문자 차이 - 철자 오류
- `typo`: 길이 1-2 차이 - 오타
- `wrong_word`: 크게 다름 - 잘못된 단어

**단계 전환 임계값(Gap 1.2)**:

| 현재 단계 | 단계명 | 승급 조건 | 강등 조건 |
|-----------|--------|-----------|-----------|
| 0 | Unknown | 50% | (해당없음) |
| 1 | Recognized | 60% | 30% |
| 2 | Recall | 75% | 40% |
| 3 | Controlled | 90% | 60% |
| 4 | Automatic | (해당없음) | 80% |

**FSRS 알고리즘(간격 반복)**: 항목당 난이도(D)와 안정성(S) 파라미터 추적. 정답과 응답 시간에서 등급(1-4) 도출. 성공 시 안정성 지수적 증가, 실패 시 부분 리셋.

| 등급 | 의미 | 트리거 | 효과 |
|------|------|--------|------|
| 1 (Again) | 잊음 | 오답 | 안정성 20%로 리셋, 난이도 증가 |
| 2 (Hard) | 어렵게 기억 | 정답, >10초 | 안정성 1.5x 천천히 증가 |
| 3 (Good) | 정상적으로 기억 | 정답, 5-10초 | 안정성 2.0x 정상 증가 |
| 4 (Easy) | 쉽게 기억 | 정답, <5초 | 안정성 2.5x 빠르게 증가, 난이도 감소 |

**세타 기여(IRT 기반 능력 갱신)**: 각 응답이 항목 변별도에 비례하고 극단적 난이도에 반비례하여 세타에 기여. 구성요소별 세타값(어휘, 형태론, 음운론, 통사론, 화용론) 및 전역 세타에 매핑.

| 모드 | 세타 갱신 동작 | 근거 |
|------|---------------|------|
| Learning | 동결 (갱신 없음) | 힌트 응답이 능력 추정 편향 |
| Training | 50% 가중치 | 응답에 부분적 신뢰 |
| Evaluation | 100% 가중치 | 힌트 없는 응답은 신뢰할 수 있는 지표 |

**지수이동평균(EMA) 정확도**: `새_정확도 = 이전_정확도 * 0.8 + 새_값 * 0.2`. 최근 응답에 더 높은 가중치.

### 처리 파이프라인 상세

`processResponse()` 함수는 12개 조율된 단계 실행:

| 단계 | 작업 |
|------|------|
| 1-3 | 응답 평가, 언어객체+숙달상태 조회, 유효 힌트 수준 계산 |
| 4-6 | 응답 기록, 노출 기록, 갱신된 숙달상태 조회 |
| 7-9 | 단계 전환 결정, FSRS 갱신, 우선순위 갱신 |
| 10-12 | 과제 유형 기록, 세타 기여 계산, 오류 분석 생성 |

---

## 상태+우선순위 서비스 (State + Priority Service) - 계층 1

> **코드 위치**: `src/main/services/state-priority.service.ts`
> **단계**: 3.1

### 맥락 및 목적

**학습 스케줄러의 두뇌**. 근본적 질문 답변: *"학습자가 다음에 무엇을 공부해야 하고, 왜?"*

효과적 학습에 필요한 이해:
1. 학습자 현재 위치 (언어 구성요소별 능력 프로필)
2. 최대 학습을 생산할 자료 (근접발달영역 내 항목)
3. 진행을 막는 것 (연쇄 실패 유발 병목 구성요소)
4. 긴급히 복습 필요한 것 (곧 잊혀질 항목)

**비즈니스 필요**: 지능적 우선순위 없이 학습자는 너무 쉬운(지루함, 학습 없음) 또는 너무 어려운(좌절, 학습 없음) 자료에 시간 낭비.

### 데이터 흐름

```
사용자 세션 시작
        |
        v
getUserThetaState() --> 능력 프로필 조회 (구성요소별 세타값)
        |
        v
detectBottlenecks() --> 어려움 겪는 구성요소 식별
        |
        v
각 LanguageObject에 대해:
        +---> calculateBasePriority() --> z(w) 벡터: F, R, D, M, P
        +---> calculateMasteryAdjustment() --> g(m) 근접발달영역용
        +---> calculateUrgencyScore() --> 시간 기반 복습 압력
        |
        v
calculateEffectivePriority() --> S_eff(w) = S_base * g(m) + urgency + bottleneck_boost
        |
        v
S_eff(w) 내림차순 큐 정렬 --> 최고 우선순위 항목 반환
```

### 기술 개념

**세타 상태(Theta State)**: 문항반응이론(IRT)의 능력 파라미터 벡터. 각 언어 구성요소(음운론, 형태론, 어휘, 통사론, 화용론)에 대한 로짓 척도 잠재 능력.

**우선순위 가중치 z(w) 벡터**: 언어 객체의 5가지 객관적 속성 가중합:
- **F**: 빈도 (0-1), 높을수록 더 흔함
- **R**: 관계 밀도 (0-1), 높을수록 더 많은 연결
- **D**: 도메인 관련성 (0-1), 대상 도메인 출현 정도
- **M**: 형태론적 점수 (0-1), 단어 형성 복잡도
- **P**: 음운론적 난이도 (0-1), 발음 복잡도

기본 가중치: 빈도 0.20, 관계 0.15, 도메인 0.15, 형태론 0.10, 음운론 0.10, 긴급성 0.20, 병목 0.10

**근접발달영역 g(m) 조정(Zone of Proximal Development)**: 힌트 없는 정확도 40-70% 항목에 최고점, 너무 쉬운(>90%) 또는 너무 어려운(<40%) 항목에 감소.

```
g(m) = stageFactor * accuracyFactor * gapFactor
```

- stageFactor: 단계 [0,1,2,3,4]에 대해 [1.0, 0.9, 0.7, 0.5, 0.3]
- accuracyFactor: <40% -> 0.8, 40-70% -> 1.0, 70-90% -> 0.6, >90% -> 0.3
- gapFactor: 1 + scaffoldingGap * 0.5

**비계 간극(Scaffolding Gap)**: 힌트 있을 때 정확도 - 힌트 없을 때 정확도. 높으면 "도움으로는 알지만 혼자는 모름" - 독립 연습 필요.

**긴급성 점수(Urgency Score)**: 복습 기한이 지남에 따라 증가하는 시간 기반 함수.

```
if (연체):
    urgency = min(1.0, 0.5 + 연체시간/48)
else:
    urgency = max(0.1, 0.5 - 기한까지시간/168)
```

48시간+ 연체 항목은 최대 긴급성(1.0). 1주+ 남은 항목은 최소 긴급성(0.1).

**병목 감지(Bottleneck Detection)**: 오류율이 임계값(기본 30%) 초과하거나 증가 추세인 언어 구성요소 식별.

**유효 우선순위 S_eff(w)**: 기본 우선순위, 숙달 조정, 긴급성, 병목 부스트를 결합한 최종 우선순위:

```
S_eff(w) = S_base(w) * g(m) + urgency_weight * urgency + bottleneck_boost
```

### 주요 설계 결정

1. **방어적 기본값**: 데이터 누락 시 중립값(대부분 0.5, 조정은 1.0) 사용으로 충돌 대신 우아한 성능 저하
2. **비동기 병렬 가져오기**: `Promise.all()`로 세타, 숙달, 큐, 병목 데이터 동시 조회하여 지연 최소화
3. **벌크 작업**: `bulkUpdatePriorities()`로 단일 트랜잭션에 모든 갱신을 배치하여 N+1 DB 호출 방지
