# 서비스 문서 (Services Documentation)

> **최종 업데이트**: 2026-01-07
> **번역 원본**: `docs/narrative/src/main/services/`

---

## 서비스 인덱스 - 학습 엔진 허브 (Services Index - Learning Engine Hub)

> **코드 위치**: `src/main/services/index.ts`
> **상태**: 활성화(Active)

---

### 존재 이유

LOGOS는 상호 연결된 여러 알고리즘을 사용하는 정교한 적응형 학습 엔진(adaptive learning engine)을 구현합니다: 학습자 능력 추정을 위한 문항반응이론(Item Response Theory, IRT), 간격 반복 스케줄링을 위한 FSRS, 어휘 관계 분석을 위한 PMI, 그리고 콘텐츠 생성을 위한 Claude AI. 이러한 각 기능은 수십 개의 타입과 함수를 가진 별도의 서비스 모듈에서 구현됩니다.

이 인덱스 파일은 학습 엔진의 **중추신경계** 역할을 합니다 - 모든 서비스 기능을 조직화하고 재내보내기(re-export)하는 단일 임포트 지점입니다. 이것이 없다면 코드베이스의 다른 부분들은 10개 이상의 다른 파일에서 임포트해야 하며, 이는 다음과 같은 문제를 초래합니다:

- 임포트 문 비대화
- 서비스 위치 변경 시 리팩토링 어려움
- 사용 가능한 기능에 대한 불명확한 그림
- 누락되거나 일관성 없는 내보내기

**비즈니스 영향**: 개발 속도. 새로운 기능을 구축할 때 개발자는 사용 가능한 서비스, 타입, 함수를 발견하기 위해 이 하나의 파일만 참조합니다. 계층과 목적에 따른 조직화된 구조는 학습 엔진의 아키텍처를 즉시 보여줍니다.

---

### 핵심 개념

#### 3계층 학습 파이프라인 (Three-Layer Learning Pipeline)

**기술적 정의**: LOGOS는 적응형 학습을 위한 3계층 아키텍처를 구현합니다:
1. **계층 1 (상태 + 우선순위)**: 학습자 능력(theta)을 계산하고 다음에 학습할 항목을 결정
2. **계층 2 (과제 생성)**: 숙련도와 학습 모드에 기반한 적절한 연습문제 생성
3. **계층 3 (채점 + 업데이트)**: 응답 평가 및 숙련도 상태 업데이트

**쉬운 설명**: 개인 과외 선생님을 생각해보세요. (1) 당신이 무엇을 알고 있는지 평가하고 적절한 주제를 선택하며, (2) 적절한 난이도의 퀴즈 문제를 만들고, (3) 답안을 채점하고 당신의 진도에 대한 기록을 업데이트합니다. 이 세 단계가 지속적으로 반복됩니다.

#### 유창성 대 다양성 균형 (Fluency vs Versatility Balance)

**기술적 정의**: 학습 시스템의 Phase 3.4는 유창성 과제(fluency task, 알려진 항목의 빠르고 자동적인 회상)와 다양성 과제(versatility task, 새로운 맥락으로의 전이와 적용)를 구분합니다. 시스템은 학습자의 진도에 따라 이 균형을 동적으로 조정합니다.

**쉬운 설명**: 피아노를 배우는 것처럼 - 때로는 속도와 근육 기억을 키우기 위해 음계를 연습하고(유창성), 다른 때는 새로운 맥락에서 기술을 적용하기 위해 새 곡을 배웁니다(다양성). LOGOS는 당신의 진도에 따라 이 균형을 자동으로 조정합니다.

#### 코퍼스 파이프라인 (Corpus Pipeline)

**기술적 정의**: 코퍼스 파이프라인 서비스는 여러 소스(Wikipedia, Wiktionary, PubMed, 사용자 업로드, Claude AI 생성)에서 어휘를 가져오고, 항목을 추출하고 중복을 제거하며, 언어학적 지표(PMI, 형태론적 복잡성, 음운론적 난이도)를 계산하고 데이터베이스를 채웁니다.

**쉬운 설명**: "의료 영어 어휘"와 같은 학습 목표를 만들 때, 이 시스템은 인터넷과 AI를 통해 관련 단어를 찾아다니고, 중복을 제거하며, 각 단어의 난이도를 측정하고, 당신의 개인 학습 라이브러리를 채웁니다.

#### 오프라인 큐 (Offline Queue)

**기술적 정의**: Claude API 호출이 필요한 작업(과제 생성, 오류 분석, 콘텐츠 생성)을 캡처하고 연결이 가능할 때 실행하는 큐잉 시스템입니다. 실패한 작업은 지수 백오프(exponential backoff)로 재시도됩니다.

**쉬운 설명**: 폭풍이 치는 동안 편지를 보관했다가 길이 열리면 배달하는 우체국과 같습니다. 오프라인으로 공부하거나 Claude API가 다운되어도 학습은 계속됩니다 - AI 향상 기능은 연결이 복구되면 따라잡습니다.

---

### 설계 결정

#### 왜 타입과 함수를 함께 내보내는가?

각 서비스 섹션은 타입(인터페이스, 타입 별칭)과 함수를 함께 내보냅니다. 이를 통해 소비자는 단일 소스에서 필요한 모든 것을 임포트할 수 있습니다.

**고려된 대안**: `types.ts` 파일에서 별도로 타입 내보내기. 관련 개념을 분리하고 더 많은 임포트 문을 생성하므로 거부되었습니다.

#### 왜 파이프라인 계층별로 구성하는가?

내보내기는 개념적 계층(Layer 1, 2, 3, Phase 3.4, PMI, Corpus, Offline, Claude, Agent)별로 명확한 주석과 함께 그룹화됩니다. 이를 통해 학습 시스템의 아키텍처가 코드에서 직접 보입니다.

**고려된 대안**: 알파벳 순서. 서비스 간의 논리적 관계를 가리므로 거부되었습니다.

#### 왜 모든 것을 재내보내는가?

이 파일은 모든 서비스에서 모든 공개 타입과 함수를 재내보냅니다. 필터링이나 이름 변경 없이.

**이유**: 단순성과 발견 가능성. 개발자는 한 곳에서 모든 기능을 탐색할 수 있습니다. 내보내지 않아야 할 것이 있다면 소스 파일에서 모듈 프라이빗이어야 합니다.

#### 왜 코퍼스 모듈을 분리하는가 (Registry, Filter, Pipeline)?

코퍼스 시스템은 세 모듈로 분리됩니다:
- **Registry**: 사용 가능한 코퍼스 소스의 정적 카탈로그
- **Filter**: 목표에 대한 소스 매칭 및 순위 지정
- **Pipeline**: 가져오기, 추출, 데이터베이스 삽입 조율

**이유**: 단일 책임 원칙(Single Responsibility Principle). 각 모듈은 하나의 명확한 역할을 가지므로 독립적으로 테스트하고 수정하기가 더 쉽습니다.

---

### 통합 지점

#### 재내보내기되는 서비스 모듈

| 서비스 모듈 | 목적 | 주요 내보내기 |
|------------|------|-------------|
| `state-priority.service` | 계층 1: 학습자 상태 및 항목 우선순위 지정 | `getUserThetaState`, `getLearningQueue`, `applyIRTReordering` |
| `task-generation.service` | 계층 2: 학습 과제 생성 | `generateTask`, `generateTaskWithClaude`, `getOrGenerateTask` |
| `scoring-update.service` | 계층 3: 응답 평가 및 숙련도 업데이트 | `evaluateResponse`, `calculateMasteryUpdates`, `processResponse` |
| `fluency-versatility.service` | Phase 3.4: 훈련 모드 균형 | `calculateTargetRatio`, `getBalancedTask`, `selectTrainingMode` |
| `pmi.service` | 어휘 관계 분석 | `getWordDifficulty`, `getCollocations`, `updateIRTDifficulties` |
| `corpus-sources/registry` | 코퍼스 소스 카탈로그 | `CORPUS_SOURCES`, `getEnabledSources`, `getSourcesByDomain` |
| `corpus-sources/filter` | 목표를 위한 소스 선택 | `filterSources`, `rankSourcesForGoal`, `getRecommendedSources` |
| `corpus-sources/corpus-pipeline.service` | 어휘 채우기 조율 | `populateVocabularyForGoal`, `processUserUploads`, `clearVocabulary` |
| `offline-queue.service` | 오프라인 작업 큐잉 | `getOfflineQueueService`, `queueTaskGeneration`, `queueErrorAnalysis` |
| `claude.service` | Claude AI 통합 | `getClaudeService`, `ClaudeService` |
| `agent-trigger.service` | 개발 에이전트 시스템 | `detectAgentTriggers`, `registerBottleneck` |
| `agent-hooks.service` | 에이전트 감지 훅 | `createOperationHook`, `wrapWithAgentDetection` |

#### 의존성 흐름

```
[IPC 핸들러]
     |
     v 임포트
[src/main/services/index.ts]  <-- 현재 위치
     |
     v 재내보내기
+-----------------+----------------+------------------+
|                 |                |                  |
v                 v                v                  v
[state-priority]  [task-gen]  [scoring-update]  [pmi.service]
                                                      |
                                                      v
                                              [corpus-sources/*]
```

#### 크리티컬 패스 상태

**심각도**: 중상(MEDIUM-HIGH)

이 파일이 실패하면:
- **빌드 오류**: 서비스에서 임포트하는 모든 파일이 컴파일 실패
- **학습 엔진 없음**: 모든 적응형 학습 기능 사용 불가

**완화**: 이 파일은 로직이 없습니다 - 재내보내기만 합니다. 여기서의 실패는 이 파일 자체가 아닌 소스 모듈의 문제를 나타냅니다.

---

## 과제 생성 서비스 (Task Generation Service) - 계층 2

> **코드 위치**: `src/main/services/task-generation.service.ts`
> **상태**: 활성화(Active)

---

### 맥락 및 목적

이 서비스는 LOGOS 학습 파이프라인의 **Phase 3.2: 계층 2**를 구현합니다. 계층 1(상태 + 우선순위 서비스)이 *무엇을* 가르칠지 결정하는 반면, 계층 2는 *어떻게* 가르칠지 결정합니다. 과제 생성 서비스는 추상적인 학습 큐 항목을 학습자가 실제로 보고 응답하는 구체적이고 상호작용적인 과제로 변환합니다.

**비즈니스 필요성**: 언어 학습 애플리케이션은 단순히 동일한 플래시카드 형식을 반복적으로 보여줄 수 없습니다. 효과적인 학습은 학습자의 현재 숙련 단계에 맞는 적응형 과제 형식, 필요할 때 적절한 스캐폴딩(힌트와 단서), 그리고 역량이 성장함에 따라 점진적으로 지원을 제거하는 것을 필요로 합니다. 이 서비스가 그러한 적응형 경험을 만듭니다.

**사용 시점**: 학습 세션이 사용자에게 새 과제를 제시해야 할 때마다. 계층 1이 학습 큐에서 다음 항목을 선택한 후, 이 서비스는 실제 과제 콘텐츠 - 화면에 나타나는 프롬프트, 답안 옵션, 힌트, 맥락 - 를 생성합니다.

---

### 마이크로스케일: 직접 관계

#### 의존성 (이 서비스가 필요로 하는 것)

- `src/main/db/prisma.ts`: `getPrisma()` - 언어 객체 및 캐시된 과제 쿼리를 위한 데이터베이스 연결 획득
- `src/main/db/repositories/mastery.repository.ts`: `getMasteryState()` - 주어진 객체에 대한 학습자의 현재 숙련도 지표(단계, 정확도, 노출 횟수) 조회
- `src/main/db/repositories/collocation.repository.ts`: `getCollocationsForWord()` - 과제에서 의미 있는 맥락과 관련 단어를 제공하기 위한 PMI 가중 단어 연관성 가져오기
- `src/main/services/state-priority.service.ts`: `LearningQueueItem` 타입 - 과제 생성을 위한 입력으로 계층 1에서 큐 항목 수신

#### 데이터 흐름

```
LearningQueueItem (계층 1에서)
        |
        v
generateTaskSpec() - 형식, 단서 수준, 난이도 결정
        |
        v
generateTask() - 프롬프트, 옵션, 힌트가 포함된 전체 과제 생성
        |
        v
cacheTask() - 향후 조회를 위해 저장
        |
        v
GeneratedTask (UI 계층으로)
```

---

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 서비스는 LOGOS 3계층 학습 파이프라인의 **계층 2**에서 작동합니다:

- **계층 1**: 상태 + 우선순위 (무엇을 배울 것인가) - 사용자 능력(theta) 분석, 우선순위 계산, 큐 관리
- **계층 2**: 과제 생성 (어떻게 배울 것인가) - **이 모듈** - 큐 항목을 상호작용 과제로 변환
- **계층 3**: 응답 처리 (얼마나 잘 했는가) - 응답 평가, 숙련도 업데이트, 복습 일정 예약

파이프라인은 순환을 따릅니다: 계층 1이 항목 선택 -> 계층 2가 과제 생성 -> 사용자 응답 -> 계층 3이 응답 처리 -> 업데이트가 계층 1에 피드백.

#### 큰 그림 영향

과제 생성 서비스는 **알고리즘적 결정과 학습자 경험 사이의 다리**입니다. 이것이 없다면:

- 사용자는 시각적/상호작용적 콘텐츠를 받지 못함
- 계층 1의 정교한 우선순위 계산이 출구가 없음
- 점진적 스캐폴딩이 없음 (Gap 2.4 알고리즘 사용 불가)
- 과제 난이도가 형식이나 단서 수준에 맞게 조정될 수 없음
- 학습이 단일 형식(예: 항상 MCQ)에서 정체됨

이 서비스가 가능하게 하는 것:
- **단계 적합 학습**: 초보자는 인식 과제(MCQ), 고급 학습자는 생산 과제(자유 응답)
- **적응형 스캐폴딩**: 어려워하는 학습자는 힌트 제공; 숙련된 학습자는 단서 없이 연습
- **유창성 대 다양성 균형**: 유창성을 위한 고-PMI 연어, 다양성을 위한 새로운 조합
- **효율적 콘텐츠 전달**: 캐싱으로 중복 과제 생성 방지

#### 크리티컬 패스 분석

**중요도 수준**: 중요(Critical)

이것은 학습 세션 경로의 **동기적 의존성**입니다. 모든 학습 상호작용은 과제 생성을 필요로 합니다:

1. 과제 생성 실패 시: 사용자는 아무것도 보지 못함 - 세션 진행 불가
2. 캐싱 실패 시: 성능 저하되지만 학습은 계속 가능 (우아한 저하)
3. 형식 선택 실패 시: 기본 형식으로 폴백 (복원력 있음)

---

### 기술 개념 (쉬운 설명)

#### 과제 형식 진행 (Task Format Progression)

**기술적**: 숙련도 단계 0-4를 점점 더 까다로운 과제 유형에 연결하는 단계-형식 매핑(`STAGE_FORMAT_MAP`): MCQ -> 빈칸 채우기 -> 매칭 -> 순서 배열 -> 자유 응답.

**쉬운 설명**: 악기를 배우는 것을 생각해보세요. 먼저 음을 식별하고(인식/MCQ), 그다음 보여지면 연주하고(빈칸 채우기), 그다음 정해진 패턴으로 조합하고(매칭/순서), 마지막으로 자유롭게 즉흥 연주합니다(자유 응답). 시스템은 당신이 향상됨에 따라 "난이도 다이얼"을 올립니다.

**사용 이유**: 인식은 생산보다 인지적으로 쉽습니다. 인식으로 시작하면 회상을 요구하기 전에 자신감과 스키마를 구축합니다. 이것은 자연스러운 언어 습득 단계를 반영합니다.

#### 단서 수준 시스템 (Cue Level System) - Gap 2.4 알고리즘

**기술적**: 스캐폴딩 강도를 나타내는 0-3 정수 척도로, **스캐폴딩 갭**(단서 보조 정확도와 단서 없는 정확도의 차이)에서 계산됩니다. 높은 갭은 학습자가 성공하기 위해 단서가 필요함을 나타냅니다.

**쉬운 설명**: 자전거의 보조바퀴와 같습니다. 레벨 3은 완전한 보조바퀴(많은 힌트), 레벨 0은 혼자 타기입니다. 시스템은 힌트가 있거나 없을 때 성공하는지 관찰합니다 - 힌트가 있어야만 성공하면 더 오래 유지하고, 없이도 성공하면 더 빨리 제거합니다.

**사용 이유**: 근접발달영역(Zone of Proximal Development, ZPD) 이론에 따르면 학습은 혼자 할 수 있는 것과 도움으로 할 수 있는 것 사이의 갭에서 지원이 일치할 때 가장 잘 일어납니다. 단서가 그 갭을 연결한 다음 페이드합니다.

#### 단서 수준 설명

| 수준 | 이름 | 학습자가 보는 것 |
|-----|-----|----------------|
| 0 | 없음(None) | 힌트 없음 - 완전한 회상 필요 |
| 1 | 최소(Minimal) | 첫 글자 힌트: "'A'로 시작함" |
| 2 | 보통(Moderate) | 길이 + 부분 공개: "7글자, 'App...'으로 시작" |
| 3 | 전체(Full) | 강한 스캐폴딩: "App____" (단어의 절반 보임) |

#### 유창성 대 다양성 과제 (Fluency vs. Versatility Tasks)

**기술적**: 숙련도 단계, 단서 없는 정확도, 구성 가능한 비율에 의해 결정되는 불리언 플래그(`isFluencyTask`). 유창성 과제는 고-PMI(자주 함께 나오는) 단어 쌍을 강화하고, 다양성 과제는 새로운 조합을 도입합니다.

**쉬운 설명**: 유창성은 "빵과 버터"를 천 번 들었기 때문에 자동으로 말하는 것입니다. 다양성은 평소와 다르지만 "빵과 마멀레이드"를 말할 수 있는 것입니다. 초기 학습은 유창성(일반 패턴)을, 후기 학습은 다양성(유연한 사용)을 구축합니다. 시스템은 둘 다 균형을 맞춥니다.

**사용 이유**: 원어민은 유창한 상용구와 창의적 유연성을 모두 가집니다. 시스템은 다양성이 자연스럽게 나타나기를 바라지 않고 두 기술을 명시적으로 훈련합니다.

#### IRT 기반 난이도 계산

**기술적**: 문항반응이론(Item Response Theory, IRT)은 각 언어 객체에 대한 기본 난이도 매개변수를 제공합니다. 과제 난이도는 다음과 같이 계산됩니다: `IRT 난이도 + 형식 수정자 + 단서 수정자`. 형식 수정자는 생산 과제의 난이도를 높이고, 단서 수정자는 힌트가 제공될 때 난이도를 낮춥니다.

**쉬운 설명**: 단어는 본질적 난이도를 가질 수 있습니다(예: "serendipity"는 "cat"보다 어렵습니다). 하지만 객관식 목록에서 "serendipity"를 *인식*하라고 요청하는 것은 기억에서 *철자*를 쓰라고 요청하는 것보다 쉽습니다. 그리고 처음 세 글자를 주면 더 쉬워집니다. 시스템은 세 가지 요소를 하나의 난이도 숫자로 결합합니다.

**사용 이유**: 정확한 난이도 추정은 최적의 항목 선택을 가능하게 합니다(현재 능력보다 약간 위의 항목이 학습에 가장 좋습니다). 형식과 단서를 고려하지 않으면 시스템이 과제 난이도를 잘못 판단합니다.

#### 만료가 있는 과제 캐싱 (Task Caching with Expiration)

**기술적**: 생성된 과제는 복합 키(objectId + taskType + taskFormat)와 만료 타임스탬프가 있는 `CachedTask` 데이터베이스 테이블에 저장됩니다. `getOrGenerateTask()`는 캐시 우선 조회 패턴을 구현합니다.

**쉬운 설명**: 미리 식사를 준비하는 것과 같습니다. 매번 처음부터 모든 과제를 요리하는 대신 시스템은 최근에 만든 과제를 식료품 창고에 저장합니다. 24시간 이내에 같은 과제가 필요하면 미리 만든 버전을 가져옵니다. 24시간 후에는 과제가 "오래된" 것으로 간주되어 새로 생성됩니다.

**사용 이유**: 과제 생성은 데이터베이스 쿼리, 무작위화, 잠재적으로 AI 호출을 포함합니다. 캐싱은 콘텐츠가 합리적으로 신선하게 유지되면서 활성 학습 세션 중 지연 시간과 데이터베이스 부하를 줄입니다.

#### MCQ 오답지 생성 (MCQ Distractor Generation)

**기술적**: `generateMCQOptions()` 함수는 같은 목표 내에서 같은 유형의 언어 객체를 데이터베이스에서 쿼리하고, 빈도순으로 정렬하고, 섞은 다음, 정답과 함께 오답지(오답)로 하위 집합을 선택합니다.

**쉬운 설명**: 좋은 객관식 문제는 그럴듯한 오답을 가집니다. "apple"을 배우고 있는데 오답이 "quantum"과 "serendipity"라면 문제가 너무 쉽습니다. 시스템은 유형이 비슷하고(다른 명사, 다른 동사) 일반적으로 학습되는 오답을 선택하여 학습자가 실제로 생각하게 합니다.

**사용 이유**: 그럴듯한 오답지는 바람직한 어려움을 만들고 학습자가 실제로 무엇을 아는지 대 추측하는지를 드러냅니다.

---

### 함수 참조

#### 과제 형식 선택

| 함수 | 목적 |
|-----|------|
| `selectTaskFormat(stage, preferProduction)` | 숙련도 단계를 적절한 형식에 매핑, 선택적으로 생산 쪽으로 편향 |
| `shouldBeFluencyTask(stage, accuracy, ratio)` | 현재 학습 상태에 기반하여 유창성 대 다양성 초점 결정 |

#### 단서 수준 결정

| 함수 | 목적 |
|-----|------|
| `determineCueLevel(cueFree, cueAssisted, exposure, max)` | Gap 2.4 알고리즘에서 스캐폴딩 수준 계산 |
| `generateHints(content, cueLevel)` | 단서 수준 1-3에 대한 점진적 힌트 생성 |

#### 과제 난이도

| 함수 | 목적 |
|-----|------|
| `calculateTaskDifficulty(irtDiff, format, cueLevel)` | IRT, 형식, 단서 수정자를 효과적 난이도로 결합 |

#### 과제 생성

| 함수 | 목적 |
|-----|------|
| `generateTaskSpec(item, config)` | 과제 사양 생성 (형식, 모달리티, 단서 수준, 난이도) |
| `generateTask(item, config)` | 프롬프트, 옵션, 힌트, 맥락이 있는 전체 과제 생성 |
| `generateMCQOptions(objectId, correct, count)` | 객관식 과제를 위한 그럴듯한 오답지 생성 |
| `getOrGenerateTask(item, config)` | 자동 생성 폴백이 있는 캐시 우선 과제 조회 |

#### 캐싱

| 함수 | 목적 |
|-----|------|
| `getCachedTask(objectId, taskType, taskFormat)` | 유효하고 만료되지 않은 경우 캐시된 과제 조회 |
| `cacheTask(objectId, taskType, taskFormat, task, hours)` | 구성 가능한 만료로 과제 저장 |

---

### 구성 옵션

`TaskGenerationConfig` 인터페이스는 사용자 정의를 허용합니다:

| 옵션 | 타입 | 기본값 | 효과 |
|-----|-----|-------|------|
| `preferredModality` | 'visual' / 'auditory' / 'mixed' | 'visual' | 과제 콘텐츠의 프레젠테이션 모드 |
| `maxCueLevel` | 0-3 | 3 | 알고리즘이 더 많이 제안해도 스캐폴딩 제한 |
| `fluencyRatio` | 0-1 | 0.6 | 유창성 대 다양성 과제의 비율 |
| `difficultyAdjustment` | -1 ~ 1 | 0 | IRT 난이도에 대한 수동 오프셋 |

---

## 채점 + 업데이트 서비스 (Scoring + Update Service) - 계층 3

> **코드 위치**: `src/main/services/scoring-update.service.ts`
> **상태**: 활성화(Active)
> **단계**: 3.3 - 학습 파이프라인의 계층 3

---

### 맥락 및 목적

이 서비스는 중요한 질문에 답함으로써 적응형 학습 루프를 완성합니다: *"학습자가 어떻게 했고, 결과적으로 무엇이 변해야 하는가?"*

채점 + 업데이트 서비스는 LOGOS 학습 파이프라인의 **피드백 처리기**입니다. 계층 1이 무엇을 가르칠지 결정하고 계층 2가 과제를 생성한 후, 계층 3은 학습자의 응답을 캡처하고, 정확성을 평가하며, 모든 숙련도 추적 시스템을 업데이트하고, 이러한 업데이트를 미래 학습을 이끄는 우선순위 계산에 다시 피드합니다.

**비즈니스 필요성**: 정확한 응답 평가와 체계적인 숙련도 업데이트가 없으면 시스템은 적응할 수 없습니다. 동사 활용에 어려움을 겪는 학습자는 계속해서 같은 비효과적인 과제를 받게 됩니다. 어휘를 마스터한 학습자는 이미 아는 자료를 복습하는 데 갇히게 됩니다. 이 서비스는 루프를 닫아 모든 응답이 시스템에 학습자에 대해 무언가를 가르치도록 합니다.

**사용 시점**:
- 학습자가 과제에 응답을 제출할 때마다
- 대기 중인 응답의 일괄 처리를 위한 세션 종료 시
- 진도 지표를 보여주는 세션 요약 생성 시
- 시간 경과에 따른 학습 결과를 추적하는 분석 생성 중

---

### 마이크로스케일: 직접 관계

#### 의존성 (이 서비스가 필요로 하는 것)

| 파일 | 임포트 | 목적 |
|-----|-------|------|
| `src/main/db/prisma.ts` | `getPrisma()` | 숙련도 상태 쿼리 및 업데이트를 위한 데이터베이스 연결 |
| `src/main/db/repositories/mastery.repository.ts` | `updateMasteryState`, `recordExposure`, `updateFSRSParameters`, `transitionStage`, `StageTransition` | 숙련도 변경, 정확도 업데이트, FSRS 스케줄링, 단계 승급/강등 지속 |
| `src/main/db/repositories/session.repository.ts` | `recordResponse`, `recordStageTransition`, `recordTaskType`, `applyThetaRules`, `SessionMode`, `ThetaState` | 응답 기록, 세션 지표, 유창성/다양성 추적, IRT 능력 업데이트 기록 |
| `src/main/db/repositories/error-analysis.repository.ts` | `createErrorAnalysis`, `recalculateComponentStats`, `ComponentCode` | 오류 분류 저장 및 병목 감지 통계 업데이트 |
| `src/main/db/repositories/goal.repository.ts` | `updateObjectPriority` | 숙련도 변경 후 재계산된 우선순위 지속 |
| `src/main/services/task-generation.service.ts` | `GeneratedTask`, `TaskSpec` | 응답 평가를 위한 과제 컨텍스트 수신 |
| `src/main/services/state-priority.service.ts` | `calculateEffectivePriority`, `calculateMasteryAdjustment`, `calculateUrgencyScore` | 숙련도 업데이트 후 항목 우선순위 재계산 |

#### 데이터 흐름

```
사용자 응답 (텍스트 입력)
        |
        v
evaluateResponse() -----> 예상 답변과 비교
        |                      |
        +-- 정확히 일치? ------+--> correct: true, partialCredit: 1.0
        |                      |
        +-- 90%+ 유사? --------+--> correct: true, partialCredit: 0.95
        |                      |
        +-- 70%+ 유사? --------+--> correct: false, partialCredit: 0.7
        |                      |
        +-- 그 외 -------------+--> analyzeError() --> 오류 유형 분류
        |
        v
recordResponse() -----> 세션 기록에 지속
        |
        v
recordExposure() -----> 정확도 지표(EMA) 업데이트
        |
        v
determineStageTransition() -----> 승급/강등 임계값 확인
        |                              |
        +-- 단계 변경됨? --> transitionStage() + recordStageTransition()
        |
        v
calculateFSRSUpdate() -----> 새 안정성, 난이도, 다음 복습 계산
        |
        v
updateFSRSParameters() -----> FSRS 상태 지속
        |
        v
calculateEffectivePriority() -----> 항목 우선순위 재계산
        |
        v
updateObjectPriority() -----> 새 우선순위 지속
        |
        v
calculateThetaContribution() -----> IRT 능력 업데이트 (학습 모드가 아닌 경우)
        |
        v
applyThetaRules() -----> 사용자 theta 상태 업데이트
        |
        v
createErrorAnalysis() -----> (오답인 경우) 오류 분류 및 저장
        |
        v
recalculateComponentStats() -----> 병목 감지 데이터 업데이트
        |
        v
ResponseOutcome -----> 호출자에게 완전한 결과 반환
```

---

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 서비스는 LOGOS 아키텍처에 정의된 3계층 학습 파이프라인의 **계층 3**에 있습니다:

```
사용자가 과제를 봄 <---- 계층 2: 과제 생성 (형식 선택, 콘텐츠 생성)
        |
        |  사용자가 응답 제출
        v
=====> 계층 3: 채점 + 업데이트 (이 서비스) <=====
        |        - 정확성 평가
        |        - 숙련도 상태 업데이트
        |        - FSRS 스케줄링 적용
        |        - theta(능력) 업데이트
        |        - 우선순위 재계산
        |        - 오류 분석
        v
숙련도 데이터 업데이트 -----> 계층 1: 상태 + 우선순위에 피드
        |
        v
다음 항목 선택 -----> 사이클 계속
```

계층 3은 학습 루프의 **마무리 호**입니다. 일시적인 사용자 행동(응답 입력)을 모든 미래 결정에 영향을 미치는 영구적인 학습 상태 변경으로 변환합니다.

#### 큰 그림 영향

이 서비스는 LOGOS를 적응형으로 만드는 핵심 피드백 메커니즘을 가능하게 합니다:

1. **점진적 숙련도 추적**: 각 응답은 지수 이동 평균(Exponential Moving Average, EMA)을 사용하여 정확도 지표를 업데이트하여 최근 성과가 먼 과거보다 더 무겁게 가중되도록 합니다. 이것은 실제 학습 궤적을 캡처합니다.

2. **단계 진행**: 5단계 숙련도 모델(Unknown -> Recognized -> Recall -> Controlled -> Automatic)은 대략적인 진도 마커를 제공합니다. 이 서비스는 이러한 전환을 게이트하는 승급/강등 임계값을 시행합니다.

3. **간격 반복 스케줄링**: FSRS 알고리즘은 최적의 복습 타이밍을 결정합니다. 이 서비스는 안정성(기억이 얼마나 잘 뿌리 내렸는지)과 난이도(이 학습자에게 항목이 얼마나 어려운지)를 계산하여 예측된 최적의 순간에 다음 복습을 예약합니다.

4. **IRT 능력 추정**: 훈련 및 평가 세션의 경우 정답/오답 응답이 학습자의 theta(능력) 매개변수를 업데이트합니다. 이를 통해 시스템 전반에 걸쳐 점점 더 정확한 난이도 보정이 가능합니다.

5. **오류 패턴 감지**: 오답 응답은 분석되고 분류되어 병목 감지 시스템에 공급됩니다. 예를 들어 형태론의 체계적 오류는 형태론 중심 과제에 대한 우선순위 신호로 표면화됩니다.

**이 서비스 없이 고장나는 것**:
- 응답이 지속적인 효과가 없음 (학습 없음)
- 숙련도 단계가 절대 진행되지 않음 (단계 0에 갇힘)
- 복습 일정이 절대 업데이트되지 않음 (잊힌 항목)
- 우선순위 계산이 오래된 데이터 사용 (잘못된 항목 선택)
- 능력 추정이 절대 개선되지 않음 (나쁜 난이도 보정)
- 오류 패턴이 절대 표면화되지 않음 (놓친 병목)
- LOGOS의 전체 적응형 학습 약속이 허술해짐

---

### 기술 개념 (쉬운 설명)

#### 부분 점수가 있는 응답 평가 (Response Evaluation with Partial Credit)

**기술적**: 텍스트를 정규화(소문자, 트림, 구두점 제거)하고, 레벤슈타인 기반 유사도를 계산하고, 구성 가능한 임계값(90%+ 유사도 = 0.95 점수, 70%+ = 유사도 점수로 점수)에 기반하여 부분 점수를 할당하는 비교 파이프라인.

**쉬운 설명**: 관대한 맞춤법 선생님처럼. "receive" 대신 "recieve"를 쓰면 시스템은 당신이 그 단어를 알지만 작은 실수를 했다는 것을 인식합니다. 완전히 틀렸다고 표시하는 대신 부분 점수를 줍니다 - 오류를 연습용으로 플래그하면서 당신의 지식을 인정하기에 충분합니다.

**사용 이유**: 이진 정답/오답은 정보를 잃습니다. "serendipity"를 요청받았을 때 "serendipitty"를 쓴 학습자는 분명히 "banana"를 쓴 사람보다 더 많이 알고 있습니다. 부분 점수는 이 구분을 보존합니다.

#### 레벤슈타인 거리 (Levenshtein Distance) - 유사도 계산

**기술적**: 한 문자열을 다른 문자열로 변환하는 데 필요한 단일 문자 편집(삽입, 삭제, 대체)의 최소 횟수를 계산하는 알고리즘. 유사도는 `1 - (거리 / 최대길이)`입니다.

**쉬운 설명**: 각 글자 변경이 1포인트가 드는 단어 게임을 한다고 상상해보세요. "cat"에서 "bat"은 1포인트(c를 b로 변경). "cat"에서 "cart"은 1포인트(r 삽입). 레벤슈타인 거리는 총 비용입니다. 0에 가까울수록 단어가 더 유사합니다. 시스템은 이것을 유사도 백분율로 변환합니다.

**사용 이유**: 두 문자열이 "얼마나 가까운지"에 대한 원칙적이고 언어 독립적인 측정을 제공합니다. 이를 통해 모든 언어와 콘텐츠 유형에서 일관된 부분 점수가 가능합니다.

#### 오류 유형 분석 (Error Type Analysis)

**기술적**: 문자열 비교를 기반으로 오류를 세 가지 유형으로 분류하는 휴리스틱 분류기: `spelling`(같은 길이, 적은 문자 차이), `typo`(길이가 1-2 다름), `wrong_word`(상당히 다름).

**쉬운 설명**: 무언가를 틀리면 다른 종류의 틀림이 있습니다. "their"와 "thier"를 혼동하는 것은 철자 오류입니다 - 단어를 알지만 글자를 더듬었습니다. "ther"를 쓰는 것은 오타입니다 - 단어를 알지만 글자를 놓쳤습니다. "their"를 요청받았을 때 "banana"를 쓰는 것은 잘못된 단어입니다 - 답을 전혀 모릅니다. 각 유형은 다른 교정을 제안합니다.

**사용 이유**: 다른 오류 유형은 다른 개입이 필요합니다. 철자 오류는 시각적 훈련에서 도움이 됩니다; 잘못된 단어 오류는 개념 재교육이 필요합니다. 분류는 대상화된 피드백과 병목 분석을 가능하게 합니다.

#### 단계 전환 임계값 (Stage Transition Thresholds) - Gap 1.2

**기술적**: 각 숙련도 단계(0-4)를 단서 없는 정확도에 기반한 승급 및 강등 임계값에 매핑하는 조회 테이블. 단계 0->1은 50%, 1->2는 60%, 2->3은 75%, 3->4는 90% 필요.

**쉬운 설명**: 무술의 띠 테스트와 같습니다. 흰 띠에서 노란 띠로 가려면(단계 0에서 1) 힌트 없이 50% 숙련도를 보여야 합니다. 높은 띠는 더 엄격한 요구 사항이 있습니다. 성과가 강등 임계값 아래로 떨어지면 회복할 때까지 이전 띠로 "강등"될 수 있습니다.

**사용 이유**: 임의의 단계 진행은 의미를 잃습니다. 이러한 임계값은 단계가 진정한 역량 수준을 반영하도록 합니다. 증가하는 엄격함은 고급 숙련도에 대한 더 높은 표준을 반영합니다.

#### 단계 임계값 참조

| 현재 단계 | 단계 이름 | 승급 조건 | 강등 조건 |
|----------|----------|---------|---------|
| 0 | Unknown | 50% | (해당 없음) |
| 1 | Recognized | 60% | 30% |
| 2 | Recall | 75% | 40% |
| 3 | Controlled | 90% | 60% |
| 4 | Automatic | (해당 없음) | 80% |

#### FSRS 알고리즘 (간격 반복)

**기술적**: Free Spaced Repetition Scheduler - 항목당 난이도(D)와 안정성(S) 매개변수를 추적하는 현대적인 간격 반복 알고리즘. 등급(1-4)은 정확성과 응답 시간에서 파생됩니다. 안정성은 성공 시 지수적으로 성장하고 실패 시 부분적으로 리셋됩니다. 다음 복습 간격은 `안정성 * (1 + (5 - 난이도) / 10)` 일로 계산됩니다.

**쉬운 설명**: 일정에 따라 식물에 물을 주는 것과 같습니다. 식물이 잘 자라면(정답) 물을 덜 자주 줄 수 있습니다(더 긴 복습 간격). 시들면(오답) 더 자주 물을 줘야 합니다(더 짧은 간격). 시스템은 각 단어의 "건강"을 추적하고 최적의 시간에 다음 물주기를 예약합니다 - 너무 이르지도(낭비적) 너무 늦지도(잊혀짐) 않게.

**사용 이유**: 인간의 기억은 예측 가능한 망각 곡선을 따릅니다. FSRS는 항목별로 이러한 곡선을 모델링하여 망각이 발생하기 직전에 복습이 일어나도록 합니다. 이것은 학습 시간당 유지율을 최대화합니다.

#### FSRS 등급 척도

| 등급 | 의미 | 트리거 | 효과 |
|-----|-----|-------|------|
| 1 (Again) | 잊음 | 오답 응답 | 안정성이 현재의 20%로 리셋, 난이도 증가 |
| 2 (Hard) | 어렵게 기억함 | 정답이지만 >10초 | 안정성 천천히 성장(1.5x), 난이도 변경 없음 |
| 3 (Good) | 정상적으로 기억함 | 정답, 5-10초 | 안정성 정상 성장(2.0x), 난이도 변경 없음 |
| 4 (Easy) | 쉽게 기억함 | 정답, <5초 | 안정성 빠르게 성장(2.5x), 난이도 감소 |

#### Theta 기여도 (IRT 기반 능력 업데이트)

**기술적**: 문항반응이론(IRT)은 학습자 능력을 잠재 매개변수 theta로 모델링합니다. 각 응답은 항목 변별도에 비례하고 극단적 난이도에 반비례하여 theta에 기여합니다. 기여도는 구성요소별 theta 값(lexical, morphological, phonological, syntactic, pragmatic) + 전역 theta에 매핑됩니다.

**쉬운 설명**: 당신의 "언어 능력 수준"이 질문에 답하면서 점차 조정되는 숨겨진 점수라고 상상해보세요. 어려운 질문을 맞추면 쉬운 것보다 점수가 더 올라갑니다. 쉬운 질문을 틀리면 어려운 것보다 더 상처 받습니다. 시스템은 다른 언어 영역(어휘 대 문법 대 발음)에 대해 별도 점수를 추적하여 당신이 어디서 강하고 약한지 정확히 알 수 있습니다.

**사용 이유**: 정확한 능력 추정은 지능적인 난이도 보정을 가능하게 합니다. 시스템이 당신이 어휘에 강하고(높은 lexical theta) 문법에 약하다는(낮은 syntactic theta) 것을 알면 각 구성요소에 적절하게 과제 난이도를 조정할 수 있습니다.

#### 세션 모드 Theta 규칙

| 모드 | Theta 업데이트 동작 | 근거 |
|-----|-------------------|------|
| Learning | 동결(업데이트 없음) | 단서가 있는 응답은 능력 추정을 편향시킴; 스캐폴드된 연습 중 무시 |
| Training | 50% 가중치 | 응답에 대한 부분 신뢰; 신중하게 능력 추정에 혼합 |
| Evaluation | 100% 가중치 | 단서 없는 응답은 신뢰할 수 있는 지표; 전체 능력 업데이트 |

#### 정확도를 위한 지수 이동 평균 (EMA)

**기술적**: 정확도는 alpha = 0.2인 EMA를 사용하여 업데이트됩니다: `new_accuracy = old_accuracy * (1 - alpha) + new_value * alpha`. 이것은 역사적 맥락을 보존하면서 최근 응답에 더 많은 가중치를 둡니다.

**쉬운 설명**: 오늘 기온과 최근 평균을 혼합하는 일기 예보와 같습니다. 어제가 70도이고 오늘이 80도라면 예보가 80도로 점프하지 않습니다 - 72도라고 할 수 있습니다, 오래된 것과 새것을 혼합합니다. 이 평활화는 하나의 운 좋은(또는 불운한) 응답이 정확도 점수를 크게 흔드는 것을 방지합니다.

**사용 이유**: 원시 정확도(정답 / 총계)는 최근성에 관계없이 모든 응답을 동등하게 취급합니다. EMA는 학습 궤적을 캡처합니다 - 20%에서 시작하여 80%로 끝나는 학습자는 50% 평균이 아닌 80% 능력을 보여야 합니다.

---

### 함수 참조

#### 응답 평가

| 함수 | 목적 |
|-----|------|
| `evaluateResponse(userResponse, expectedAnswer, config)` | 주요 평가 파이프라인: 정규화, 비교, 점수 할당, 피드백 생성 |
| `normalizeResponse(response)` | 비교를 위해 텍스트 표준화(소문자, 트림, 구두점 제거, 공백 정규화) |
| `calculateSimilarity(a, b)` | 두 문자열 간의 레벤슈타인 기반 유사도 점수(0-1) 계산 |
| `analyzeError(response, expected)` | 설명이 있는 오류 유형(spelling, typo, wrong_word) 분류 |

#### 숙련도 상태 업데이트

| 함수 | 목적 |
|-----|------|
| `determineStageTransition(currentStage, cueFreeAccuracy, cueAssistedAccuracy)` | 정확도가 승급 또는 강등을 보장하는지 확인 |
| `calculateFSRSUpdate(correct, currentDifficulty, currentStability, responseTimeMs)` | 새 FSRS 매개변수와 다음 복습 날짜 계산 |
| `calculateThetaContribution(correct, itemDifficulty, itemDiscrimination, componentType)` | IRT 기반 능력 매개변수 업데이트 계산 |

#### 주요 처리

| 함수 | 목적 |
|-----|------|
| `processResponse(userId, userResponse, config)` | 응답에서 결과까지의 완전한 12단계 파이프라인 |
| `batchProcessResponses(userId, responses, config)` | 여러 응답을 순차적으로 처리(세션 종료) |
| `summarizeOutcomes(outcomes)` | 세션 요약을 위해 여러 결과에서 통계 집계 |

---

### 처리 파이프라인 상세

`processResponse()` 함수는 12개의 조정된 단계를 실행합니다:

| 단계 | 작업 | 업데이트되는 데이터 |
|-----|-----|------------------|
| 1 | `evaluateResponse()` | 평가 결과 계산 |
| 2 | LanguageObject + MasteryState 쿼리 | 현재 숙련도 데이터 조회 |
| 3 | 효과적 단서 수준 계산 | 사용된 힌트에 따라 조정 |
| 4 | `recordResponse()` | 세션에 Response 레코드 생성 |
| 5 | `recordExposure()` | 노출 횟수 + 정확도 EMA 업데이트 |
| 6 | 업데이트된 MasteryState 쿼리 | EMA 후 새로운 정확도 가져오기 |
| 7 | `determineStageTransition()` | 승급/강등 확인 |
| 8 | `calculateFSRSUpdate()` + `updateFSRSParameters()` | 간격 반복 스케줄링 업데이트 |
| 9 | `calculateEffectivePriority()` + `updateObjectPriority()` | 우선순위 재계산 및 지속 |
| 10 | `recordTaskType()` | 유창성 대 다양성 균형 추적 |
| 11 | `calculateThetaContribution()` + `applyThetaRules()` | 사용자 능력 업데이트(학습 모드가 아닌 경우) |
| 12 | `createErrorAnalysis()` + `recalculateComponentStats()` | 오류 분류(오답인 경우) |

---

## 상태 + 우선순위 서비스 (State + Priority Service) - 계층 1

> **코드 위치**: `src/main/services/state-priority.service.ts`
> **상태**: 활성화(Active)
> **단계**: 3.1 - 학습 파이프라인의 계층 1

---

### 맥락 및 목적

이 서비스는 **학습 스케줄러의 두뇌**입니다. 모든 적응형 학습 시스템이 해결해야 하는 근본적인 질문에 답합니다: *"학습자가 다음에 무엇을 공부해야 하고, 왜?"*

상태 + 우선순위 서비스가 존재하는 이유는 언어 학습이 선형 과정이 아니기 때문입니다. 학습자는 단순히 알파벳 순으로 어휘 목록을 행진할 수 없습니다. 대신 효과적인 학습은 다음을 이해해야 합니다:

1. **학습자의 현재 위치** (언어 구성요소별 능력 프로필)
2. **최대 학습을 생산할 자료** (근접발달영역의 항목)
3. **진전을 막는 것** (연쇄 실패를 일으키는 병목 구성요소)
4. **긴급하게 복습이 필요한 것** (곧 잊혀질 항목)

**비즈니스 필요성**: 지능적 우선순위 지정 없이 학습자는 너무 쉬운(지루함, 학습 이득 없음) 또는 너무 어려운(좌절, 학습 이득 없음) 자료에 시간을 낭비합니다. 이 서비스는 모든 학습 세션이 최대한 생산적이도록 보장합니다.

**사용 시점**:
- 모든 학습 세션 시작 시 다음 항목 결정
- 항목 완료 후 큐 재우선순위 지정
- 시간이 지남에 따라 우선순위를 재계산하기 위해 백그라운드에서 주기적으로
- 병목 감지가 큐 재균형을 트리거할 때

---

### 마이크로스케일: 직접 관계

#### 의존성 (이 서비스가 필요로 하는 것)

| 파일 | 임포트 | 목적 |
|-----|-------|------|
| `src/main/db/prisma.ts` | `getPrisma()` | 사용자 theta 상태 쿼리를 위한 데이터베이스 연결 |
| `src/main/db/repositories/mastery.repository.ts` | `getMasteryStatistics`, `getReviewQueue`, `ReviewQueueItem` | 숙련도 데이터, 복습 일정, 학습 지표 조회 |
| `src/main/db/repositories/goal.repository.ts` | `getLanguageObjects`, `bulkUpdatePriorities` | 언어 객체 가져오기 및 우선순위 업데이트 지속 |
| `src/main/db/repositories/error-analysis.repository.ts` | `detectBottlenecks`, `getPrimaryBottleneck`, `BottleneckResult` | 진전을 막는 언어 구성요소 식별 |

#### 데이터 흐름

```
사용자 세션 시작
        |
        v
getUserThetaState() -----> 능력 프로필(구성요소당 theta 값) 조회
        |
        v
detectBottlenecks() -----> 어려움을 겪는 구성요소 식별
        |
        v
각 LanguageObject에 대해:
        |
        +---> calculateBasePriority() -----> z(w) 벡터: F, R, D, M, P
        |
        +---> calculateMasteryAdjustment() --> 근접발달영역을 위한 g(m)
        |
        +---> calculateUrgencyScore() -------> 시간 기반 복습 압력
        |
        v
calculateEffectivePriority() ---> S_eff(w) = S_base * g(m) + urgency + bottleneck_boost
        |
        v
S_eff(w) 내림차순으로 큐 정렬
        |
        v
가장 높은 우선순위 항목을 학습자에게 반환
```

---

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 서비스는 LOGOS 아키텍처에 정의된 3계층 학습 파이프라인의 **계층 1**에 있습니다:

```
계층 3: 과제 생성 (과제 유형 선택, 콘텐츠 생성)
              ^
              |  "우선순위 0.87인 항목이 여기 있습니다"
              |
계층 2: 응답 평가 (정확성 평가, 숙련도 업데이트)
              ^
              |  "사용자가 항목 X를 틀렸음, 구성요소 MORPH"
              |
=====> 계층 1: 상태 + 우선순위 (이 서비스) <=====
              ^
              |  "사용자 theta, 병목, 복습 일정"
              |
데이터베이스 계층: 숙련도 상태, 오류 분석, 사용자 프로필
```

상태 + 우선순위 서비스는 다른 모든 학습 결정이 구축되는 **기초 계층**입니다. 정확한 상태 분석과 지능적 우선순위 지정 없이는 상위 계층이 효과적으로 기능할 수 없습니다.

#### 큰 그림 영향

이 서비스는 LOGOS의 핵심 적응형 학습 루프를 가능하게 합니다:

1. **개인화된 학습 경로**: theta 상태(능력), 숙련도 수준, 병목 감지를 결합하여 각 학습자는 현재 지식 상태에 최적화된 고유한 학습 순서를 얻습니다.

2. **근접발달영역 타겟팅**: 숙련도 조정 함수 `g(m)`는 비고츠키의 ZPD 이론을 구현합니다. 40-70% 정확도를 가진 항목이 가장 높은 우선순위를 받는데, 이는 학습자가 거의 하지만 완전히는 독립적으로 처리할 수 없는 자료를 나타내기 때문입니다.

3. **간격 반복 통합**: 긴급도 점수는 복습이 예정된 항목이 적시에 표면화되도록 하여 망각을 방지하면서 조기 복습을 피합니다.

4. **병목 해결**: 오류 분석 시스템이 어려움을 겪는 구성요소(예: 임계값 이상의 형태론 오류)를 감지하면 이 서비스는 해당 구성요소를 대상으로 하는 항목의 우선순위를 높입니다.

**이 서비스 없이 고장나는 것**:
- 학습 큐가 무작위 또는 알파벳 순이 됨 (비효과적)
- 기한이 지난 복습이 놓침 (망각)
- 어려움을 겪는 영역이 추가 주의를 받지 못함 (정체)
- 난이도 보정에 능력 추정이 없음 (좌절)
- LOGOS의 전체 적응형 학습 약속이 무너짐

---

### 기술 개념 (쉬운 설명)

#### Theta 상태

**기술적**: 문항반응이론의 능력 매개변수 벡터(theta 값)로, 각 언어 구성요소(phonology, morphology, lexical, syntactic, pragmatic)에 대해 로짓 척도에서 학습자의 잠재 능력을 나타냅니다.

**쉬운 설명**: theta를 비디오 게임의 "스킬 레벨"이라고 생각하세요, 하지만 카테고리별로 분류됩니다. 어휘(lexical)에서 레벨 7이지만 문법(syntactic)에서 레벨 3일 수 있습니다. theta 상태는 이 미묘한 능력 프로필을 캡처하여 시스템이 당신이 어디서 강하고 약한지 정확히 알 수 있게 합니다.

**사용 이유**: 구성요소별 능력 추정 없이는 모든 학습자를 모든 영역에서 동등하게 능력 있다고 취급할 것입니다. Theta 상태는 각 학습자의 실제 약점에 대한 정밀 타겟팅을 가능하게 합니다.

#### 우선순위 가중치 (z(w) 벡터)

**기술적**: 각 언어 객체의 다섯 가지 객관적 속성의 가중 합: 빈도(Frequency, F), 관계 밀도(Relational density, R), 도메인 관련성(Domain relevance, D), 형태론적 복잡성(Morphological complexity, M), 음운론적 난이도(Phonological difficulty, P).

**쉬운 설명**: 모든 단어나 구문은 배우는 것이 더 중요하게 만드는 속성을 가집니다. 고빈도 단어("the" 같은)는 드문 단어보다 더 중요합니다. 다른 단어와 많은 연결을 가진 단어(관계 밀도)는 가치 있는 앵커입니다. 도메인(의료, 법률 등)과 관련된 단어가 우선순위를 받습니다. z(w) 벡터는 이 모든 요소를 단일 "중요도 점수"로 결합합니다.

**사용 이유**: 모든 어휘가 동등하게 가치 있지 않습니다. 의료 영어를 배우는 의사는 "serendipity" 전에 "diagnosis"가 필요합니다. z(w) 벡터는 학습자의 현재 상태와 독립적으로 이러한 객관적 중요도 요소를 인코딩합니다.

#### 근접발달영역 (g(m) 조정)

**기술적**: 40-70% 단서 없는 정확도를 가진 항목에 대해 정점을 이루고 너무 쉬운(>90%) 또는 너무 어려운(<40%) 항목에 대해 감소하는 숙련도 기반 조정 함수.

**쉬운 설명**: 학습을 위한 스위트 스팟을 상상해보세요. 무언가가 너무 쉬우면 지루하고 배우지 못합니다. 너무 어려우면 좌절하고 배우지 못합니다. ZPD는 약간의 도움으로 거의 할 수 있는 골디락스 영역입니다. g(m) 함수는 당신의 개인 스위트 스팟에 있는 항목을 찾아 우선순위를 매깁니다.

**사용 이유**: 학습 과학은 최대 성장이 현재 능력을 약간 넘어서 일어난다는 것을 보여줍니다. 이 함수는 그 통찰을 운영화하여 학습자가 그들을 늘리지만 부수지 않는 자료에 시간을 보내도록 합니다.

#### 스캐폴딩 갭 (Scaffolding Gap)

**기술적**: 주어진 항목에 대한 단서 보조 정확도와 단서 없는 정확도의 차이. 계산: `scaffoldingGap = cueAssistedAccuracy - cueFreeAccuracy`.

**쉬운 설명**: 힌트가 주어지면 맞출 수 있나요? 힌트가 제거되면 여전히 기억하나요? 스캐폴딩 갭은 이 차이를 측정합니다. 높은 갭은 "도움으로는 알지만 혼자서는 모름"을 의미합니다 - 이러한 항목은 지식을 견고히 하기 위해 더 많은 독립적 연습이 필요합니다.

**사용 이유**: "지원되지만 내재화되지 않은" 상태에 갇힌 항목을 드러냅니다. 높은 스캐폴딩 갭 항목은 지원에서 독립적 회상으로 전환해야 하는 지식을 나타내므로 우선순위가 지정됩니다.

#### 긴급도 점수 (Urgency Score)

**기술적**: 간격 반복 일정에서 시간적 압력을 구현하여 항목이 복습 기한이 지나면 증가하는 시간 기반 함수.

**쉬운 설명**: 유통기한이 있는 우유처럼 기억도 "복습 마감" 날짜가 있습니다. 기한이 지난 항목은 더 긴급해지고(잊혀질 수 있음), 아직 기한이 안 된 항목은 긴급도가 낮습니다(너무 일찍 복습하는 것은 낭비적). 긴급도 점수는 다음에 무엇을 볼지에 영향을 미치는 카운트다운 타이머와 같습니다.

**사용 이유**: 간격 반복은 적시에 복습이 일어나야만 작동합니다. 긴급도 점수는 잊혀지기 전에 기한이 지난 항목이 맨 위로 올라오도록 하면서 최적의 간격을 방해하는 조기 복습을 방지합니다.

#### 병목 감지 (Bottleneck Detection)

**기술적**: 임계값(기본 30%)을 초과하는 오류율 또는 증가 추세를 보이는 언어 구성요소의 식별로, 전반적 진전을 막고 있습니다.

**쉬운 설명**: 언어 학습이 파이프를 통해 흐르는 물과 같다고 상상해보세요. 하나의 파이프(예: 문법)가 막히면 물이 모든 곳에서 역류합니다. 병목 감지는 막힌 파이프를 찾습니다. 형태론 오류율이 갑자기 급증하면 형태론에 의존하는 모든 것(동사, 활용, 단어 형태)이 그 기본 문제를 해결할 때까지 어려움을 겪습니다.

**사용 이유**: 병목은 연쇄 실패를 일으킵니다. 동사 활용에 어려움을 겪는 학습자는 어휘가 강해도 많은 문장에서 실패합니다. 병목 구성요소를 감지하고 우선순위를 지정함으로써 증상을 쫓는 대신 근본 원인을 해결합니다.

#### 효과적 우선순위 S_eff(w)

**기술적**: 기본 우선순위(S_base), 숙련도 조정(g(m)), 긴급도, 병목 부스트를 결합한 최종 우선순위 점수: `S_eff(w) = S_base(w) * g(m) + urgency_weight * urgency + bottleneck_boost`.

**쉬운 설명**: 이 학습자에게 지금 항목이 얼마나 중요한지에 대한 "최종 답변"입니다. 다음을 혼합합니다: (1) 항목이 객관적으로 얼마나 중요한지, (2) 당신의 학습 스위트 스팟에 있는지, (3) 곧 잊어버릴 것인지, (4) 어려움을 겪는 영역을 대상으로 하는지. 가장 높은 S_eff를 가진 항목이 다음에 공부할 것입니다.

**사용 이유**: 단일 요소가 최적의 학습 순서를 결정하지 않습니다. 효과적 우선순위는 모든 고려 사항을 단일 실행 가능한 순위로 균형 맞추는 종합입니다.

---

### 알고리즘 상세

#### 기본 우선순위 공식 (S_base)

기본 우선순위는 알고리즘 기초에서 FRE(Frequency-Relational-Domain) 공식을 구현합니다:

```
S_base(w) = w_F * F + w_R * R + w_D * D + w_M * M + w_P * P
```

여기서:
- **F**: 정규화된 빈도(0-1), 높을수록 더 일반적
- **R**: 관계 밀도(0-1), 높을수록 더 많은 연결
- **D**: 도메인 관련성(0-1), 항목이 대상 도메인에 얼마나 나타나는지
- **M**: 형태론적 점수(0-1), 단어 형성의 복잡성
- **P**: 음운론적 난이도(0-1), 발음 복잡성

기본 가중치:
- 빈도: 0.20
- 관계: 0.15
- 도메인: 0.15
- 형태론적: 0.10
- 음운론적: 0.10
- 긴급도: 0.20
- 병목: 0.10

#### 숙련도 조정 공식 (g(m))

```
g(m) = stageFactor * accuracyFactor * gapFactor
```

여기서:
- **stageFactor**: 단계 [0, 1, 2, 3, 4]에 대해 [1.0, 0.9, 0.7, 0.5, 0.3]
- **accuracyFactor**:
  - <40%: 0.8 (너무 어려움)
  - 40-70%: 1.0 (ZPD 스위트 스팟)
  - 70-90%: 0.6 (쉬워지고 있음)
  - >90%: 0.3 (마스터됨)
- **gapFactor**: 1 + scaffoldingGap * 0.5

#### 긴급도 점수 공식

```
if (overdue):
    urgency = min(1.0, 0.5 + hoursOverdue / 48)
else:
    urgency = max(0.1, 0.5 - hoursUntilDue / 168)
```

48시간 이상 기한이 지난 항목은 최대 긴급도(1.0)에 도달합니다.
1주 이상 후에 예정된 항목은 최소 긴급도(0.1)를 가집니다.

---

## PMI 서비스 (Pointwise Mutual Information)

> **코드 위치**: `src/main/services/pmi.service.ts`
> **상태**: 활성화(Active)

---

### 맥락 및 목적

이 서비스는 원시 통계적 코퍼스 분석과 실용적인 언어 학습 난이도 추정 사이의 격차를 메우기 위해 존재합니다. `core/pmi.ts`의 순수 PMI 계산기가 단어 동시 발생의 수학을 처리하는 반면, PMI 서비스는 목표별 캐싱, 데이터베이스 지속성, LOGOS 적응형 학습 시스템과의 통합으로 그 기능을 래핑합니다.

**비즈니스 필요성**: 언어 학습자는 난이도별로 우선순위가 지정된 콘텐츠가 필요합니다. 일부 단어는 예측할 수 없는 맥락에 나타나기 때문에 배우기 어렵고(낮은 PMI), 다른 단어는 익숙한 파트너와 일관되게 나타나기 때문에 더 쉽습니다(높은 PMI). 이 서비스는 그 난이도를 수량화하고 우선순위 계산 시스템(FRE 공식)에 공급하여 학습 큐가 최적의 순서로 항목을 제시하도록 합니다.

**사용 시점**:
- 처음으로 새 학습 목표의 코퍼스를 채울 때
- 학습 큐의 언어 객체에 대한 우선순위 점수를 계산할 때
- FRE(Frequency-Relational-contextual) 우선순위 공식이 "R"(관계 밀도) 구성요소가 필요할 때
- 코퍼스 변경 후 IRT 난이도 매개변수를 일괄 업데이트할 때
- 학습 세션 중 빠른 조회를 위해 연어 관계를 데이터베이스에 지속할 때

---

### 마이크로스케일: 직접 관계

#### 의존성 (이 서비스가 필요로 하는 것)

- `src/main/db/prisma.ts`: `getPrisma()` - 언어 객체 및 연어 쿼리 및 업데이트를 위한 데이터베이스 클라이언트 제공
- `src/core/pmi.ts`: `PMICalculator`, `pmiToDifficulty()`, `frequencyToDifficulty()`, `TaskType`, `PMIResult` - PMI 계산을 위한 순수 수학 엔진; 이 서비스는 캐싱과 지속성으로 래핑

#### 의존 대상 (이것을 필요로 하는 것)

- `src/main/services/state-priority.service.ts`: FRE 우선순위 공식의 "R" 구성요소를 계산하기 위해 `getRelationalDensity()` 사용
- `src/main/ipc/learning.ipc.ts`: 초기 난이도 매개변수를 설정하기 위해 코퍼스 채우기 후 `updateIRTDifficulties()` 호출 가능
- `src/main/services/task-generation.service.ts`: 유창성 과제(고-PMI 쌍)와 다양성 과제(저-PMI 쌍)를 생성하기 위해 연어 데이터 사용
- `src/main/db/repositories/collocation.repository.ts`: 이 서비스와 함께 작동; 서비스가 연어를 쓰고 저장소가 특화된 쿼리 패턴 제공

#### 데이터 흐름

```
목표 코퍼스 (언어 객체)
        |
        v
getCalculatorForGoal() -- 콘텐츠에서 토큰 배열 구축
        |
        v
PMICalculator.indexCorpus() -- 단어 빈도 + 동시 발생 계산
        |
        v
캐시가 계산기 저장 (30분 TTL)
        |
        +---> getWordDifficulty() --> 단일 단어의 난이도
        |
        +---> getCollocations() --> PMI 점수가 있는 상위-K 단어 쌍
        |
        +---> getRelationalDensity() --> 0-1로 정규화된 허브 점수
        |
        +---> updateIRTDifficulties() --> 데이터베이스에 일괄 업데이트
        |
        +---> storeCollocations() --> Collocation 테이블에 지속
```

---

### 매크로스케일: 시스템 통합

#### 아키텍처 계층

이 서비스는 LOGOS의 3계층 아키텍처의 **애플리케이션 서비스 계층**에 있습니다:

- **계층 1**: 렌더러(React UI) - 학습 과제와 우선순위 큐 표시
- **계층 2**: 이 서비스(PMI 서비스) - 언어학적 난이도 지표 계산
- **계층 3**: 데이터베이스(Prisma/SQLite) - 언어 객체와 연어 저장

PMI 서비스는 순수 알고리즘 계층(`core/pmi.ts`)과 지속성 계층을 연결합니다. 다음을 담당합니다:
1. **캐싱**: 코퍼스 통계 재계산을 피하기 위해 목표당 인메모리 PMI 계산기 유지
2. **오케스트레이션**: 순수 계산과 데이터베이스 업데이트 간 조정
3. **정규화**: 원시 PMI 값을 IRT 호환 난이도 매개변수로 변환

#### 큰 그림 영향

PMI 서비스는 적응형 난이도 시스템에 대한 **중요 의존성**입니다. 다음을 가능하게 합니다:

1. **우선순위 계산(FRE 공식)**: 관계 밀도 "R" 구성요소는 `getRelationalDensity()`에서 옵니다. 이것 없이는 우선순위 점수가 빈도만 고려하여 잘 연결된 단어(예측 가능한 파트너와 함께 나타나는)가 배우기 쉽다는 언어학적 통찰을 놓칩니다.

2. **IRT 난이도 추정**: 초기 IRT 난이도 매개변수(문항반응이론의 "b")는 `updateIRTDifficulties()`를 통해 PMI 분석에서 부트스트랩됩니다. 이것은 실제 사용자 응답이 수집되기 전에 적응형 시스템을 콜드 스타트합니다.

3. **유창성 대 다양성 과제 선택**: 고-PMI 쌍은 유창성 과제("take medication" 같은 일반 연어 연습)가 되고, 저-PMI 쌍은 다양성 과제(유연성 구축을 위한 비정상적 조합 연습)가 됩니다.

4. **연어 네트워크 시각화**: 저장된 연어는 학습자에게 단어가 서로 어떻게 연결되는지 보여주는 관계 그래프를 구동합니다.

#### 크리티컬 패스 분석

**중요도 수준**: 높음

- **이 서비스가 실패하면**: 우선순위 계산이 빈도만으로 폴백하여 관계 밀도 구성요소를 잃습니다. IRT 난이도가 기본값(0)에 유지되어 실제 응답이 보정할 때까지 적응형 알고리즘이 덜 정확해집니다.
- **실패 모드**: 우아한 저하 - 함수가 오류를 던지는 대신 합리적인 기본값(빈 연어, 빈도 기반 난이도)을 반환합니다.
- **성능 우려**: 대규모 코퍼스의 경우 계산기 구축이 느릴 수 있습니다. 30분 캐시가 이를 완화하지만 코퍼스 업데이트 후 `clearCalculatorCache()`를 호출하여 새 데이터를 보장해야 합니다.

---

### 기술 개념 (쉬운 설명)

#### 점별 상호 정보량 (Pointwise Mutual Information, PMI)

**기술적**: PMI는 두 단어의 관찰된 동시 발생 확률을 독립적일 경우 예상되는 것과 비교하여 연관 강도를 측정합니다: `PMI(w1, w2) = log2[P(w1,w2) / (P(w1) * P(w2))]`. 양수 값은 단어가 우연보다 더 자주 함께 나타남을 나타내고, 음수 값은 서로 피한다는 것을 나타냅니다.

**쉬운 설명**: "take"라는 단어를 들으면 - 다음 단어가 "medication" 대 "elephant"일 때 얼마나 놀라시겠습니까? PMI는 그 놀라움을 수량화합니다. 높은 PMI는 쌍이 예측 가능함(낮은 놀라움)을 의미하고, 낮은 PMI는 예상치 못함(높은 놀라움)을 의미합니다. 언어 학습에서 예측 가능한 쌍은 서로를 강화하기 때문에 기억하기 쉽습니다.

**사용 이유**: PMI는 학습자가 항목을 시도하기 전에 난이도를 추정하는 원칙적인 방법을 제공합니다. 예측 가능한 맥락에 나타나는 단어는 "보조 바퀴"가 있습니다 - 맥락이 회상을 돕습니다. 예측할 수 없는 맥락에 나타나는 단어는 더 많은 인지 노력이 필요합니다.

#### 정규화된 PMI (Normalized PMI, NPMI)

**기술적**: NPMI는 결합 확률의 음의 로그로 나누어 PMI를 [-1, +1] 범위로 스케일링합니다: `NPMI = PMI / -log2(P(w1,w2))`. 이것은 다른 크기의 코퍼스 간에 점수를 비교 가능하게 합니다.

**쉬운 설명**: 원시 PMI 값은 코퍼스 크기에 따라 달라집니다 - 거대한 코퍼스는 -5에서 +15의 PMI 값을 가질 수 있고, 작은 코퍼스는 -2에서 +5만 가질 수 있습니다. NPMI는 온도를 섭씨로 변환하는 것처럼 작동합니다: 모든 것을 같은 척도에 놓아 사과와 사과를 비교할 수 있습니다.

**사용 이유**: PMI 데이터를 다른 지표(빈도, IRT 난이도)와 결합할 때 정규화된 값은 코퍼스 크기가 결과를 왜곡하는 것을 방지합니다.

#### 허브 점수 (Hub Score, 관계 밀도)

**기술적**: 허브 점수는 단어의 모든 유의미한 연어에 대한 양의 PMI 값을 합한 다음 경험적으로 선택된 최대값(50)으로 나누어 [0, 1]로 정규화합니다.

**쉬운 설명**: 일부 단어는 "사교적 나비"입니다 - 다른 많은 단어와 강한 연결을 가집니다("take"는 "medication", "break", "time", "care"와 강하게 연결됩니다). 다른 단어는 연결이 적은 "외톨이"입니다. 허브 점수는 단어가 어휘 네트워크에서 얼마나 연결되어 있는지 측정합니다. 고도로 연결된 단어는 많은 방향에서 강화되기 때문에 배우기 쉬운 경향이 있습니다.

**사용 이유**: FRE 우선순위 공식은 관계 밀도를 "R" 구성요소로 사용합니다. 높은 허브 점수를 가진 단어가 우선순위를 받는 이유는 그것을 배우면 많은 관련 구문의 이해가 풀리기 때문입니다.

#### 로그 우도비 (Log-Likelihood Ratio, 유의성)

**기술적**: 던닝의 G-검정(로그 우도비)은 관찰된 동시 발생 빈도가 독립 하의 예상 빈도와 유의미하게 다른지 테스트합니다. 3.84 이상의 값은 p < 0.05 유의성을 나타냅니다.

**쉬운 설명**: 두 단어가 코퍼스에서 한 번 함께 나타났다고 해서 정말 연관이 있다는 것은 아닙니다 - 우연일 수 있습니다. 유의성 검정은 묻습니다: "이 단어들이 서로 관련이 없다면 이렇게 자주 함께 보게 될 가능성이 얼마나 될까?" 높은 유의성은 관계가 노이즈가 아닌 실제임을 의미합니다.

**사용 이유**: 서비스는 유의성(기본 임계값: 3.84)으로 연어를 필터링하여 가짜 쌍을 저장하는 것을 방지합니다. 이것은 연어 데이터베이스를 깨끗하게 유지하고 유창성 과제가 진정으로 일반적인 구문을 사용하도록 보장합니다.

#### IRT 난이도 매개변수 (b)

**기술적**: 문항반응이론에서 난이도 매개변수 "b"는 학습자가 50% 확률로 정답을 맞출 수 있는 능력 수준을 나타냅니다. 로짓 척도에서 일반적인 값은 -3(매우 쉬움)에서 +3(매우 어려움) 범위입니다.

**쉬운 설명**: 일본어를 배우고 있고 "sushi"라는 단어의 난이도가 -2라면 초보자(낮은 능력)도 아마 맞출 수 있다는 의미입니다. 하지만 "tsundoku"(책을 사고 읽지 않는 것)은 난이도가 +2여서 신뢰성 있게 회상하려면 고급 능력이 필요합니다.

**사용 이유**: PMI-난이도 변환(`pmiToDifficulty()`)은 실제 응답이 보정하기 전에 새 항목에 대한 IRT 매개변수를 부트스트랩합니다. 높은 PMI(예측 가능한 맥락)는 낮은 난이도에 매핑되고, 낮은 PMI(예측할 수 없는 맥락)는 높은 난이도에 매핑됩니다.

#### 계산기 캐시 (Calculator Cache)

**기술적**: 목표당 하나의 PMI 계산기를 저장하는 인메모리 `Map<string, { calculator: PMICalculator, lastUpdated: Date }>`로, 30분(CACHE_TTL_MS) 후 제거됩니다.

**쉬운 설명**: PMI 계산기를 구축하려면 목표 코퍼스의 모든 단어를 스캔하고 모든 쌍을 세어야 합니다 - 대규모 어휘에는 비용이 많이 듭니다. 캐시는 매번 창고까지 걸어가는 대신 작업대에 도구를 두는 것과 같습니다. 30분 후에는 코퍼스가 변경되었을 수 있으므로 새로 다시 구축합니다.

**사용 이유**: 캐싱 없이는 `getWordDifficulty()` 또는 `getCollocations()`에 대한 모든 호출이 전체 코퍼스를 다시 스캔합니다. 캐시는 반복 조회를 즉각적으로 만듭니다.

---

### 주요 함수 참조

#### getWordDifficulty(goalId, word, taskType)

다음을 포함하는 `WordDifficultyResult` 반환:
- `difficulty`: 로짓 척도의 IRT 난이도(-3 ~ +3)
- `frequency`: 언어 객체의 정규화된 빈도(0-1)
- `hasCollocations`: 이 단어에 대해 PMI 데이터가 있는지
- `pmiBasedDifficulty`: PMI 파생 난이도, 또는 빈도로 폴백 시 null

연어가 존재하면 PMI 기반 난이도 사용; 그렇지 않으면 빈도 기반 난이도로 폴백. 과제 유형 수정자가 결과를 조정(인식은 더 쉽고, 생산은 더 어려움).

#### getCollocations(goalId, word, topK)

다음을 포함하는 `CollocationResult` 반환:
- `collocations`: PMI 결과 배열(단어 쌍, 점수, 유의성)
- `hubScore`: 양의 PMI 값의 합(원시, 정규화되지 않음)

유창성 연습 쌍을 찾기 위해 과제 생성에서 사용.

#### getRelationalDensity(goalId, word)

FRE 우선순위 공식에서 사용하기 위해 정규화된 허브 점수(0-1) 반환. 내부적으로 상위 20개 연어를 가져와 합을 정규화.

#### updateIRTDifficulties(goalId)

목표의 모든 언어 객체에서 `irtDifficulty` 필드를 업데이트하는 일괄 작업. 적응형 시스템을 부트스트랩하기 위해 코퍼스 채우기 후 호출. 업데이트된 객체 수 반환.

#### updateRelationalDensities(goalId)

모든 언어 객체에서 `relationalDensity` 필드를 업데이트하는 일괄 작업. 우선순위 점수의 "R" 구성요소를 새로 고치기 위해 코퍼스 변경 후 호출. 업데이트된 객체 수 반환.

#### storeCollocations(goalId, minSignificance)

빠른 데이터베이스 조회를 위해 `Collocation` 테이블에 유의미한 연어 지속. 기존 쌍을 업데이트하기 위해 upsert 사용. 기본 유의성 임계값은 3.84(p < 0.05). 저장된 연어 수 반환.

#### clearCalculatorCache(goalId) / clearAllCalculatorCaches()

캐시된 계산기 무효화. 다음 요청에서 새로운 PMI 계산을 보장하기 위해 코퍼스 변경(언어 객체 추가/제거) 후 호출.

---

## 변경 이력

| 날짜 | 변경 내용 | 이유 | 영향 |
|-----|---------|------|------|
| 2026-01-06 | Services Index 문서 생성 | 서비스 조직에 대한 서사적 맥락 수립 | 개발자가 서비스 계층 아키텍처 이해 |
| 2026-01-05 | PMI Service 문서 생성 | Shadow Map 문서화 방법론 지원 | 구현 세부사항 없이 서비스 역할 이해 가능 |
| 2026-01-04 | Task Generation Service 문서 생성 | 모든 코드 파일에 섀도우 문서 필요 | 비기술 이해관계자가 과제 생성 시스템 이해 가능 |
| 2026-01-04 | Scoring + Update Service 구현 | 적응형 학습 루프 완성을 위한 최종 계층 | 응답 평가, 숙련도 추적, FSRS 스케줄링, IRT 업데이트, 오류 분석 가능 |
| 2026-01-04 | State + Priority Service 구현 | 적응형 학습 파이프라인을 위한 기초 계층 | 지능적 큐 정렬, ZPD 타겟팅, 병목 인식 우선순위 지정 가능 |
