# 핵심 심리측정 모듈 (Core Psychometric Modules)

> **최종 업데이트**: 2026-01-07
> **관련 코드**: `src/core/irt.ts`, `src/core/quadrature.ts`
> **상태**: 활성

이 문서는 LOGOS의 적응형 학습 시스템의 심리측정학적 기반을 구성하는 두 가지 핵심 모듈인 **문항반응이론(Item Response Theory, IRT)** 모듈과 **가우스-에르미트 구적법(Gauss-Hermite Quadrature)** 모듈에 대한 한국어 기술 문서입니다.

---

## 문항반응이론(Item Response Theory) 모듈

> **코드 위치**: `src/core/irt.ts`

---

### 맥락 및 목적

이 모듈은 **문항반응이론(Item Response Theory)**을 구현합니다. 이는 LOGOS 적응형 학습 시스템의 심리측정학적 핵심입니다. IRT를 통해 LOGOS는 학습자의 응답 패턴을 기반으로 학습자의 숙련도를 추정하고, 해당 숙련도 수준에 대해 가장 많은 정보를 제공할 문항을 선택할 수 있습니다.

**비즈니스 필요성**: 언어 학습 플랫폼은 개별 학습자에게 적응해야 합니다. IRT가 없으면 시스템은 모든 학습자에게 동일한 문항을 제공하거나(숙련도 차이 무시), "정답률"과 같은 조잡한 지표에 의존하게 됩니다(문항 난이도를 고려하지 않음). IRT는 학습자 능력과 문항 난이도를 동일한 척도에 배치하여 도전 수준을 현재 숙련도에 정밀하게 매칭함으로써 이 문제를 해결합니다.

**사용 시점**:
- 모든 학습자 응답 후: 세타(Theta, 능력)가 재추정됨
- 다음 문항 선택 시: 정보 최대화가 문항 선택을 안내함
- 초기 보정 중: 새로운 어휘에 대한 난이도 매개변수 설정 시
- 분석 시: 학습자에게 시간에 따른 능력 궤적을 보여줄 때

---

### 미시적 관점: 직접적 관계

#### 의존성 (이 모듈이 필요로 하는 것)

- **`src/core/types.ts`**:
  - `ItemParameter` - 문항 속성 (a, b, c 매개변수)
  - `ThetaEstimate` - 표준오차가 포함된 능력 추정치
  - `ItemCalibrationResult` - 문항 보정 출력

#### 피의존성 (이 모듈을 필요로 하는 것)

**핵심 모듈:**
- `src/core/g2p-irt.ts`: 자소-음소 규칙에 IRT 적용
- `src/core/priority.ts`: 우선순위 계산에 세타 추정치 사용
- `src/core/task-matching.ts`: 과제 적합성 평가에 세타 사용
- `src/core/quadrature.ts`: 대안적 EAP 추정 방법 제공

**서비스 레이어:**
- `src/main/services/task-generation.service.ts`: 적응형 문항 선택에 `selectNextItem()` 사용
- `src/main/services/scoring-update.service.ts`: 응답 후 `estimateThetaEAP()` 사용
- `src/main/services/state-priority.service.ts`: 큐 구축에 세타 사용

**인덱스 재내보내기:**
- `src/core/index.ts`: 쉬운 임포트를 위해 모든 IRT 함수 내보내기

#### 데이터 흐름

```
응답 기록됨
       |
       v
[scoring-update.service.ts]
       |
       | responses[], items[]
       v
estimateThetaEAP() -----> 새 세타 추정치
       |
       v
[selectNextItem()] -----> 제시할 다음 문항
       |                         |
       v                         v
데이터베이스에서           학습자에게 과제 표시
사용자 세타 업데이트
```

---

### 거시적 관점: 시스템 통합

#### 아키텍처 레이어

이 모듈은 핵심 레이어의 **순수 알고리즘 코드**입니다:

```
+-----------------------------------------------+
| 렌더러: SessionView, QuestionCard             |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| IPC: session.ipc.ts, learning.ipc.ts          |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 서비스: scoring-update, task-generation       |
|         (IRT 사용 조율)                       |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 핵심: IRT 모듈 (이 파일)                      |  <-- 현재 위치
| 순수 함수, I/O 없음, 부작용 없음              |
+-----------------------------------------------+
```

#### 큰 그림 영향

IRT는 LOGOS의 **개인화 엔진**입니다. 다음을 가능하게 합니다:

| 기능 | IRT가 가능하게 하는 방법 |
|------|-------------------------|
| 적응형 난이도 | 학습자 능력 수준에서 문항 선택 |
| 능력 추적 | 세타 추정치가 시간에 따른 진전을 보여줌 |
| 효율적 학습 | 최대 정보 문항이 낭비되는 연습 최소화 |
| 공정한 평가 | 점수가 문항 난이도를 고려함 |
| 보정 | 새 문항이 학습자 응답으로부터 보정됨 |

**IRT 없이는:**
- 모든 학습자가 숙련도와 관계없이 동일한 문항을 받게 됨
- 진전이 원시 정확도로 측정됨 (오해의 소지)
- 어려운 문항이 적절할 때도 "나쁘게" 보임
- 쉬운 문항이 인위적으로 자신감을 부풀림
- 다음에 무엇을 연습할지 선택할 원칙적 방법이 없음

#### 임계 경로 분석

**중요도 수준**: 임계 (핵심 알고리즘)

- **확률 함수에 버그가 있으면**: 모든 능력 추정치가 틀려짐
- **추정이 발산하면**: 세타가 무한대 또는 NaN이 됨
- **문항 선택이 최적이 아니면**: 학습 효율성이 크게 떨어짐

**처리되는 엣지 케이스:**
- 전부 정답인 응답 패턴 (MLE가 +무한대로 발산하게 만듦)
- 전부 오답인 응답 패턴 (MLE가 -무한대로 발산하게 만듦)
- 피셔 정보량(Fisher Information)이 0인 경우 (0으로 나누기 발생)
- 빈 응답 배열 (사전 평균 반환)

---

### 알고리즘 설명

#### 세 가지 IRT 모델

LOGOS는 복잡성이 증가하는 세 가지 IRT 모델을 구현합니다:

##### 1PL (라쉬 모델, Rasch Model)

```
P(정답) = 1 / (1 + e^(-(theta - b)))
```

**쉬운 설명**: 문항을 맞출 확률은 그 문항이 당신의 숙련도(theta)보다 얼마나 어려운지(b)에만 의존합니다. 모든 문항은 숙련도 차이에 대해 동등하게 "민감"하다고 가정합니다.

**용도**: 변별력이 비교적 균일한 음운론적 문항에 사용.

**예시**: 세타가 0(평균)이고 문항 난이도 b가 0(평균)이면, P = 0.5 (50% 확률).

##### 2PL 모델

```
P(정답) = 1 / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 1PL과 유사하지만 문항마다 다른 "예리함"(a)을 가질 수 있습니다. 높은 a 값의 문항은 숙련자와 비숙련자를 명확히 구분하고, 낮은 a 값의 문항은 숙련도와 관계없이 비슷한 결과를 제공합니다.

**용도**: 변별력이 다양한 어휘 및 통사 문항에 사용.

**a가 중요한 이유**:
- a = 2.0: 가파른 곡선 - 작은 숙련도 차이가 큰 확률 변화를 야기
- a = 0.5: 완만한 곡선 - 큰 숙련도 차이도 작은 확률 변화만 보여줌

##### 3PL 모델

```
P(정답) = c + (1-c) / (1 + e^(-a(theta - b)))
```

**쉬운 설명**: 2PL과 유사하지만 추측을 고려합니다. 매우 낮은 숙련도의 사람도 때때로 정답을 추측할 수 있습니다. 매개변수 c는 추측 하한선입니다.

**용도**: 추측이 가능한 화용론적 문항과 객관식 문제에 사용.

**c가 중요한 이유**: 4지선다 문제에서 무작위 추측도 25% 정답률을 줍니다. 3PL 모델은 낮은 능력의 학습자가 운 좋은 추측에 대해 불이익을 받지 않게 합니다.

#### 세타 추정 방법

##### 최대우도추정(Maximum Likelihood Estimation, MLE)

**역할**: 관찰된 응답 패턴을 가장 확률적으로 만드는 세타 값을 찾습니다.

**작동 방식**:
1. theta = 0으로 시작
2. 우도 함수의 기울기(그래디언트) 계산
3. 더 가파른 우도 방향으로 뉴턴-랩슨(Newton-Raphson) 단계 진행
4. 수렴까지 반복

**장점**:
- 불편 추정량 (평균적으로 정확)
- 효율적 (불편 추정량 중 최소 분산)

**약점**:
- 극단적 패턴에서 발산 (전부 정답 또는 전부 오답)
- 안정성을 위해 여러 응답 필요

**사용 시기**: 혼합된 결과가 있는 5개 이상의 응답이 있을 때.

##### 사후기대치 추정(Expected A Posteriori, EAP)

**역할**: 응답과 사전 믿음이 주어졌을 때 세타의 사후 분포의 평균을 계산합니다.

**작동 방식**:
1. 사전 분포 정의 (일반적으로 정규분포, 평균=0, 표준편차=1)
2. 많은 세타 값에서 사전분포와 우도를 곱함 (구적법)
3. 정규화하여 사후 분포 얻기
4. 사후분포의 평균 반환

**장점**:
- 항상 유한함 (발산하지 않음)
- 사전 지식 통합
- 적은 응답으로도 안정적

**약점**:
- 사전분포 쪽으로 편향됨 (축소 추정)
- 계산 집약적

**사용 시기**: 항상, 특히 학습 초기나 극단적 패턴에서. LOGOS는 EAP를 기본값으로 사용.

#### 문항 선택 전략

##### 피셔 정보량 최대화(Fisher Information Maximization)

**역할**: 세타에 대한 불확실성을 가장 많이 줄여줄 문항을 선택합니다.

**작동 방식**:
1. 각 후보 문항에 대해 현재 세타에서 피셔 정보량 계산
2. 피셔 정보량 = a^2 * P * (1-P)
3. 최대 정보량을 가진 문항 선택

**쉬운 설명**: 성공 여부가 가장 불확실한 문항(P가 0.5 근처)을 선택합니다. 그곳에서 학습자의 진정한 능력에 대해 가장 많이 배울 수 있습니다.

**정보 최대화 곡선**:
```
정보량
     |
     |        *****
     |      **     **
     |    **         **
     |  **             **
     | *                 *
     |*                   *
     +-------------------------> Theta
        (theta = b에서)
```

최대 정보량은 theta = 난이도(b)일 때 발생합니다.

##### 쿨백-라이블러 발산 선택(Kullback-Leibler Divergence Selection)

**역할**: 피셔 정보량과 유사하지만 현재 세타 추정치의 불확실성을 고려합니다.

**작동 방식**:
1. 세타의 사후 분포에 대해 KL 발산을 적분
2. 점 추정치뿐만 아니라 전체 불확실성을 고려
3. 세타 추정치의 표준오차가 높을 때 더 견고함

**사용 시기**: 세타의 표준오차가 높을 때 (학습 초기, 적은 응답).

#### 문항 보정 (EM 알고리즘)

**역할**: 응답 행렬로부터 문항 매개변수(a, b)를 추정합니다.

**작동 방식**:
1. **E-단계**: 현재 문항 매개변수가 주어졌을 때 각 사람의 세타 추정
2. **M-단계**: 세타 추정치가 주어졌을 때 문항 매개변수 업데이트
3. 수렴까지 반복

**쉬운 설명**: 사람들의 능력이나 문항의 난이도를 모릅니다. 하지만 능력을 알면 난이도를 추정할 수 있습니다. 그리고 난이도를 알면 능력을 추정할 수 있습니다. EM 알고리즘은 둘 다 안정화될 때까지 왔다갔다합니다.

**용도**: 파일럿 테스트 데이터로부터 새로운 어휘 문항 보정.

---

### 기술 개념 (쉬운 설명)

#### 로짓 척도(Logit Scale)

**기술적 정의**: 로지스틱 오즈 변환으로 logit(p) = ln(p/(1-p))이며, 확률 (0,1)을 (-inf, +inf)로 매핑합니다.

**쉬운 설명**: "75% 확률"이라고 말하는 대신 로짓 = 1.1이라고 합니다. "50%" 대신 로짓 = 0이라고 합니다. 로짓 척도는 수학을 깔끔하게 만들고 능력과 난이도를 비교하는 자연스러운 방법을 제공합니다.

**사용 이유**: 로짓 척도에서 차이는 의미가 있습니다. 세타 1.0 vs 2.0은 2.0 vs 3.0과 동일한 숙련도 격차를 의미합니다. 원시 확률에서는 이것이 성립하지 않습니다 (75% vs 88%는 88% vs 97%와 같은 격차가 아님).

#### 표준오차(Standard Error, SE)

**기술적 정의**: 세타 추정치의 표본분포의 추정된 표준편차.

**쉬운 설명**: 우리 추정치에 대해 얼마나 확신하는지. SE = 0.3이면 꽤 확신함 (세타 +/- 0.6이 95%를 커버). SE = 1.5이면 매우 불확실함.

**사용 이유**: SE는 언제 추정치를 신뢰할지 알려줍니다. 학습 초기에 SE는 높습니다 - 더 많은 데이터가 필요합니다. 많은 응답 후 SE는 줄어듭니다 - 학습자를 잘 알게 됩니다.

#### 변별력(Discrimination, a 매개변수)

**기술적 정의**: 문항특성곡선(Item Characteristic Curve, ICC)의 변곡점에서의 기울기로, 능력과 성공 확률 사이의 관계를 결정합니다.

**쉬운 설명**: 문항이 얼마나 "진단적"인지. 높은 a 값의 문항은 예리한 진단 테스트처럼 숙련자와 비숙련자를 명확히 구분합니다. 낮은 a 값의 문항은 노이즈가 많은 측정처럼 숙련도가 결과에 거의 영향을 미치지 않습니다.

**사용 이유**: 일부 어휘는 전반적인 능력을 매우 진단적으로 보여줍니다. 다른 것들은 특이합니다 (일부 고급 학습자가 모르고, 일부 초보자가 앎). a 매개변수가 이것을 포착합니다.

#### 추측 매개변수(Guessing Parameter, c)

**기술적 정의**: ICC의 하한 점근선으로, 무한히 낮은 능력을 가진 수험자가 정답을 맞출 확률을 나타냅니다.

**쉬운 설명**: 추측의 하한선. 4지선다 문제에서 완전한 초보자도 25%의 시간에 정답을 맞춥니다. c 매개변수는 모델이 운 좋은 추측에 속지 않게 합니다.

**사용 이유**: c 없이는 낮은 능력 학습자의 운 좋은 추측이 그들의 세타 추정치를 인위적으로 높일 것입니다.

---

### 구현 노트

#### 수치 안정성

모듈은 여러 안전장치를 포함합니다:

1. **매개변수 제한**: a는 [0.2, 3.0], b는 [-4.0, 4.0]으로 제한
2. **나눗셈 보호**: L2 (헤시안)가 나눗셈 전에 0인지 검사
3. **우도 하한**: 로그 우도가 log(0)을 피하기 위해 엡실론 사용
4. **수렴 제한**: 최대 50회 반복으로 무한 루프 방지

#### 성능 특성

| 함수 | 복잡도 | 일반적 시간 |
|------|--------|-------------|
| probability2PL | O(1) | < 1ms |
| estimateThetaMLE | O(n * iterations) | 50개 문항에 < 5ms |
| estimateThetaEAP | O(n * quadPoints) | 41개 점에 < 10ms |
| selectNextItem | O(n) 문항 | < 1ms |
| calibrateItems | O(n * m * iterations) | 100-500ms |

여기서 n = 문항, m = 사람.

---

## 가우스-에르미트 구적법(Gauss-Hermite Quadrature) 모듈

> **코드 위치**: `src/core/quadrature.ts`

---

### 맥락 및 목적

이 모듈은 LOGOS 적응형 학습 시스템에서 베이지안 능력 추정을 위한 고정밀 수치 적분을 제공하기 위해 존재합니다. 기저 적분을 해석적으로 풀 수 없을 때 학습자 능력(세타)의 **사후기대치(Expected A Posteriori, EAP) 추정**을 계산하는 근본적인 문제를 해결합니다.

**비즈니스/사용자 필요**: 학습자가 문제에 답하면 시스템은 적절히 도전적인 콘텐츠를 선택하기 위해 그들의 능력 수준을 추정해야 합니다. 이 추정치는:
1. **정확해야 함** - 잘못된 추정치는 좌절스러운 경험(너무 어려움)이나 시간 낭비(너무 쉬움)로 이어짐
2. **안정적이어야 함** - 극단적인 응답 패턴(전부 정답 또는 전부 오답)에서도 심하게 변동하지 않아야 함
3. **빨라야 함** - 학습 세션 중 실시간으로 계산되어야 함

이 모듈은 순진한 균일 샘플링 대신 **가우스-에르미트 구적법**(특수 수치 적분 기법)을 사용합니다. 정규(가우시안) 사전 분포에 대해 적분할 때 더 적은 계산 점으로 훨씬 더 나은 정확도를 제공하기 때문입니다 - 이것이 정확히 베이지안 IRT가 요구하는 것입니다.

**사용 시점**:
- 학습자가 문제에 답한 후 능력을 재추정할 때마다
- 적응형 문항 선택을 위해 사후 평균과 분산을 계산할 때
- 보고를 위해 최종 세션 점수를 계산할 때
- 연구 등급의 고정밀 능력 추정 시

---

### 미시적 관점: 직접적 관계

#### 의존성 (이 모듈이 필요로 하는 것)

이것은 외부 의존성이 전혀 없는 **자체 완결 모듈**입니다. 다음에만 의존합니다:
- 수학 연산을 위한 JavaScript 내장 `Math` 객체
- 다른 LOGOS 모듈로부터의 임포트 없음

이 격리는 의도적입니다 - 구적법은 완전히 결정론적이고 격리된 상태에서 테스트 가능해야 하는 수학적 원시 함수입니다.

#### 피의존성 (이 모듈을 필요로 하는 것)

- `src/core/irt.ts`: 주요 소비자. EAP 추정 정확도를 향상시키기 위해 이 모듈 사용.
  - irt.ts의 `estimateThetaEAP()`는 균일 구적법을 사용하지만, 이 모듈의 `estimateThetaEAPGaussHermite()`는 더 정확한 대안 제공
  - irt.ts의 `selectItemKL()` 함수는 가우스-에르미트 노드를 사용하도록 향상될 수 있음

- `src/main/services/scoring-update.service.ts`: 각 응답 후 세타 추정 호출
- `src/main/services/state-priority.service.ts`: 우선순위 계산에 세타 추정치 사용

#### 데이터 흐름

```
사용자가 문제에 답함
       |
       v
응답 기록됨 (정답/오답)
       |
       v
모든 응답과 문항 매개변수로부터 우도 함수 구축
       |
       v
[이 모듈] 가우스-에르미트 적분이 계산:
  1. 분자: integral of theta * L(theta) * prior(theta) d(theta) (가중 평균)
  2. 분모: integral of L(theta) * prior(theta) d(theta) (정규화 상수)
       |
       v
EAP = 분자 / 분모
       |
       v
{theta: EAP, se: 사후 표준편차} 반환
       |
       v
문항 선택 및 세션 진행에 사용
```

---

### 거시적 관점: 시스템 통합

#### 아키텍처 레이어

이 모듈은 LOGOS 아키텍처의 **핵심 알고리즘 레이어**에 위치합니다:

```
+-------------------------------------------------------------+
| 레이어 1: 렌더러 (React UI)                                  |
|   -> 능력 추정치, 진행 차트 표시                             |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
| 레이어 2: 메인 프로세스 서비스                               |
|   -> 학습 세션 조율, 추정 호출                               |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
| 레이어 3: 핵심 알고리즘 <- 현재 위치                         |
|   -> 순수 수학: IRT, FSRS, PMI, 구적법                       |
|   -> 이 모듈이 적분 원시 함수 제공                           |
+-------------------------------------------------------------+
                    |
                    v
+-------------------------------------------------------------+
| 레이어 4: 데이터 (Prisma/SQLite)                             |
|   -> 세타 추정치, 문항 매개변수 저장                         |
+-------------------------------------------------------------+
```

#### 큰 그림 영향

이 모듈은 적응형 학습을 가능하게 하는 **추정 서브시스템**의 일부입니다:

```
+-------------------------------------------------------------+
|                    적응형 학습 루프                          |
+-------------------------------------------------------------+
|                                                             |
|  +----------+     +----------+     +------------------+     |
|  | 과제     | --> | 응답     | --> | 세타 추정        |     |
|  | 제시     |     | 기록     |     | (이 모듈)        |     |
|  +----------+     +----------+     +--------+---------+     |
|       ^                                     |               |
|       |           +-------------------------+               |
|       |           v                                         |
|  +----+-----+     +------------------+                      |
|  | 콘텐츠   | <-- | 다음 문항 선택   |                      |
|  | 생성     |     | (최고 정보량)    |                      |
|  +----------+     +------------------+                      |
|                                                             |
+-------------------------------------------------------------+
```

정확한 세타 추정 없이는 전체 적응 루프가 무너집니다:
- **문항 선택 실패**: 적절히 도전적인 문항을 선택할 수 없음
- **진행 추적 실패**: 의미 있는 개선 지표를 보여줄 수 없음
- **숙달 평가 실패**: 학습 목표 달성 여부를 결정할 수 없음
- **세션 최적화 실패**: 연습 시간을 효율적으로 배분할 수 없음

#### 임계 경로 분석

**중요도 수준**: 높음 (핵심 인프라)

- **이 모듈이 실패하면**: 세타 추정치가 사전 평균(0)으로 폴백되어 적응이 비효과적이 됨. 시스템이 개인화된 콘텐츠 대신 무작위 난이도의 콘텐츠를 제시하게 됨.
- **실패 모드**: 수학적 계산이므로 실패는 조용함 (충돌이 아닌 잘못된 숫자). 시스템은 "작동"하지만 최적이 아닌 학습 결과를 만듦.
- **폴백**: `irt.ts`의 기존 `estimateThetaEAP()`가 균일 구적법 폴백을 제공하지만 정확도가 감소함.

---

### 기술 개념 (쉬운 설명)

#### 수치 적분 / 구적법(Numerical Integration / Quadrature)

**기술적 정의**: 특정 점에서의 함수 값의 가중 합을 사용하여 정적분의 값을 근사. integral of f(x)dx를 sum of w_i * f(x_i)로 대체.

**쉬운 설명**: 곡선 아래의 면적을 측정하려 한다고 상상해보세요. 등간격으로 배치된 세로 막대 그리드를 곡선 아래에 놓고 그 면적들을 더할 수 있습니다 (막대 차트처럼). 하지만 영리한 수학자들이 특정 "마법의" 위치에 막대를 배치하고 각 막대에 특별한 승수를 부여하면 훨씬 적은 막대로 훨씬 더 정확한 답을 얻을 수 있다는 것을 발견했습니다.

**사용 이유**: 베이지안 IRT는 닫힌 형태의 해가 없는 적분을 계산해야 합니다. 수치적으로 근사해야 합니다. 더 나은 근사 = 더 나은 능력 추정치 = 더 나은 학습 경험.

#### 가우스-에르미트 구적법 (균일과 비교)

**기술적 정의**: 에르미트 다항식의 근을 노드로 사용하고 가우시안 가중 함수 e^(-x^2)에서 파생된 가중치를 사용하는 가우스 구적법 규칙. integral of f(x)e^(-x^2)dx 형태의 적분에 최적.

**쉬운 설명**: 측정하는 곡선이 종 모양(정규 분포)이라는 것을 안다면, 측정 점을 배치하면 최대 정확도를 주는 "스위트 스팟"이 있습니다. 가우스-에르미트 구적법은 그 스위트 스팟이 정확히 어디인지 알려줍니다. x = -2, -1, 0, 1, 2에서 측정하는 대신 x = -2.02, -0.96, 0, 0.96, 2.02에서 측정할 수 있습니다 (실제 5점 노드).

**사용 이유**: 베이지안 IRT에서 항상 정규 사전 분포에 대해 적분합니다. 가우스-에르미트는 이 특정 케이스에 수학적으로 최적입니다. 21개의 가우스-에르미트 점이 종종 100개 이상의 균일 점을 능가합니다.

#### 사전 계산된 노드와 가중치(Pre-computed Nodes and Weights)

**기술적 정의**: 5, 11, 21, 41개 점의 정밀도 수준에서 에르미트 다항식의 근(x_i)과 해당 적분 가중치(w_i)에 대한 표로 정리된 값.

**쉬운 설명**: 그 "마법의 위치"를 계산하려면 복잡한 다항식 방정식을 풀어야 합니다 - 런타임에 하기엔 비쌉니다. 그래서 수학 표(1972년 수치 계산의 "바이블"인 Abramowitz & Stegun)에서 찾아서 하드코딩했습니다. 수학 시험을 위한 컨닝 페이퍼를 갖는 것과 같습니다.

**사용 이유**: 런타임 효율성. 학습 세션 중에 다항식 근을 풀 필요가 없습니다; 사전 계산된 값을 찾아보기만 하면 됩니다.

#### 사후기대치(Expected A Posteriori, EAP) 추정

**기술적 정의**: 능력(theta)의 베이지안 점 추정치로 사후 평균으로 계산됨: EAP = integral of theta * p(theta|data)d(theta) = integral of theta * L(data|theta) * prior(theta)d(theta) / integral of L(data|theta) * prior(theta)d(theta).

**쉬운 설명**: 학습자에 대해 알고 있는 것(사전 능력)과 그들이 문제에 어떻게 답했는지(우도)가 주어졌을 때, EAP는 "그들의 능력을 가장 잘 나타내는 단일 숫자는 무엇인가?"라고 묻습니다. 답은 모든 가능한 능력의 평균이며, 각 능력이 응답 패턴을 고려했을 때 얼마나 가능성 있는지에 따라 가중됩니다. "이 테스트 답안이 주어졌을 때, 이 점수를 가진 일반적인 사람은 어떤 능력 수준을 가질까?"라고 묻는 것과 같습니다.

**사용 이유**: EAP는 특히 학습자가 모든 문제를 맞추거나 모두 틀릴 때 최대우도추정(MLE)보다 더 안정적입니다. MLE는 능력이 무한대이거나 음의 무한대라고 말할 것입니다; EAP는 합리적으로 경계된 추정치를 제공합니다.

#### 피셔 정보량(Fisher Information)

**기술적 정의**: 측정(문항 응답)이 미지의 매개변수(능력)에 대해 얼마나 많은 정보를 제공하는지의 측도. IRT의 경우: I(theta) = a^2 * P(theta) * Q(theta), 여기서 a는 변별력, P는 정답 확률, Q = 1-P.

**쉬운 설명**: 의료 검사를 상상해보세요. 일부 검사는 매우 정보적입니다 (양성 결과는 정말로 그 상태가 있다는 것을 의미). 다른 것들은 모호합니다 (양성이 무엇이든 의미할 수 있음). 피셔 정보량은 이것을 정량화합니다 - 이 문제에 답하는 것이 학습자의 진정한 능력에 대해 얼마나 알려주는가? 학습자가 50% 확률(P = 0.5)인 문항이 가장 정보적입니다; 너무 쉽거나(P 약 1) 너무 어려운(P 약 0) 문항은 거의 아무것도 알려주지 않습니다.

**사용 이유**: 적응형 문항 선택을 주도합니다. 각 응답 후 현재 세타 추정치에서 가장 높은 피셔 정보량을 가진 다음 문항을 선택합니다 - 이것이 불확실성을 가장 빨리 줄이는 데 수학적으로 최적입니다.

#### RECOMMENDED_SETTINGS 프리셋

**기술적 정의**: 다양한 정확도/속도 트레이드오프를 위해 11, 21, 41개 점으로 사전 구성된 QuadratureRule 객체.

**쉬운 설명**: 비디오 스트리밍처럼 세 가지 "품질 수준":
- **빠름 (11개 점)**: 빠른 연습 중 실시간 피드백용. 충분히 좋지만 완벽하지 않음.
- **표준 (21개 점)**: 일반 세션 업데이트용. 속도와 정확도의 우수한 균형.
- **정밀 (41개 점)**: 최종 점수, 보고서, 연구용. 가장 높은 정확도, 약간 느림.

**사용 이유**: 학습 경험의 다른 순간들은 다른 요구 사항을 가집니다. 즉각적인 피드백은 속도가 필요합니다; 최종 성적은 정밀도가 필요합니다.

---

### 알고리즘 참조

#### 수학적 기초

모듈은 다음에 대한 수치 적분을 구현합니다:

**표준 가우스-에르미트 적분:**
```
integral from -infinity to +infinity of f(x) * e^{-x^2} dx ≈ sum of w_i * f(x_i)
```

**평균 mu와 표준편차 sigma를 가진 정규 사전분포에 적응:**
```
integral from -infinity to +infinity of f(x) * phi(x; mu, sigma) dx ≈ (1/sqrt(pi)) * sum of w_i * f(mu + sigma*sqrt(2) * x_i)
```

여기서:
- `x_i` = 가우스-에르미트 노드 (에르미트 다항식의 근)
- `w_i` = 가우스-에르미트 가중치
- `phi(x; mu, sigma)` = 정규 밀도 함수

#### 정확도 vs 점의 수

| 점의 수 | 오차 차수 | 사용 사례 |
|---------|-----------|-----------|
| 5 | O(10^-6) | 빠른 추정, 매끄러운 사후분포 |
| 11 | O(10^-12) | 실시간 피드백 |
| 21 | O(10^-24) | 표준 세션 업데이트 |
| 41 | O(10^-48) | 연구 등급 정밀도 |

#### 주요 학술 참조
- Bock & Mislevy (1982): IRT를 위한 원래 EAP 공식화
- Press et al. (2007): Numerical Recipes - 가우시안 구적법 알고리즘
- Abramowitz & Stegun (1972): 노드와 가중치에 대한 표준 표

---

### API 표면

#### 핵심 함수

| 함수 | 목적 | 반환값 |
|------|------|--------|
| `getGaussHermiteNodes(n)` | n개 점에 대한 사전 계산된 노드 얻기 | `QuadratureNode[]` |
| `createGaussHermiteRule(n)` | 완전한 구적법 규칙 생성 | `QuadratureRule` |
| `createUniformRule(n, range)` | 균일 구적법 생성 (폴백) | `QuadratureRule` |
| `integrateNormal(f, mean, sd, rule)` | 정규 가중치에 대해 f 적분 | `number` |
| `computeEAP(likelihood, mean, sd, rule)` | 사후 평균과 표준편차 계산 | `{mean, sd}` |
| `estimateThetaEAPGaussHermite(...)` | 전체 IRT 세타 추정 | `{theta, se}` |
| `compareQuadratureMethods(...)` | 다른 구적법 접근 방식 비교 | `Record<string, {mean, sd}>` |

#### 타입

| 타입 | 설명 |
|------|------|
| `QuadratureNode` | 단일 적분 점: `{x: number, w: number}` |
| `QuadratureRule` | 완전한 규칙: 노드, 개수, 타입 식별자 |

---

## 변경 이력

### 2026-01-07 - 한국어 문서 생성
- **변경 내용**: IRT 및 구적법 모듈에 대한 한국어 통합 문서 생성
- **이유**: 한국어 사용자를 위한 기술 문서 제공
- **영향**: 한국어로 LOGOS의 심리측정학적 기반 이해 가능

### 2026-01-06 - IRT 모듈 문서화
- **변경 내용**: irt.ts에 대한 섀도우 문서 생성
- **이유**: 핵심 알고리즘은 시스템 이해를 위한 포괄적인 문서가 필요
- **영향**: 개발자와 AI 에이전트가 IRT 구현을 이해할 수 있게 함

### 2026-01-05 - 구적법 모듈 문서화
- **변경 내용**: 구적법 모듈에 대한 초기 내러티브 문서
- **이유**: 모든 핵심 알고리즘에 섀도우 문서 필요
- **영향**: LOGOS의 수치 적분 이해 가능
