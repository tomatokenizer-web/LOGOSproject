# 의미 네트워크 모듈

> **최종 업데이트**: 2026-01-06
> **코드 위치**: `src/core/semantic-network.ts`
> **상태**: 활성

---

## 맥락 및 목적

이 모듈은 어휘 관계를 위한 **의미 네트워크 모델**을 구현합니다. LOGOS가 단어들이 서로 어떻게 연결되는지 이해할 수 있게 하는 언어학적 지식을 제공합니다 - 동의어, 반의어, 상위어(범주 관계), 그리고 연어를 통해서.

**비즈니스 필요성**: 언어 학습은 단순히 고립된 단어들을 암기하는 것이 아닙니다. 학습자들은 단어들이 어떻게 연결되는지 이해해야 합니다 - "big"과 "large"가 비슷한 의미라는 것, "hot"이 "cold"의 반대라는 것, "dog"가 "animal"의 한 종류라는 것. 이 의미적 지식은 학습자들이:
- 맥락에 맞는 적절한 단어를 선택하도록 돕습니다 (동의어가 항상 대체 가능한 것은 아닙니다)
- 의미 관계를 이해하도록 합니다 ("vehicle"을 알면 "car," "bus," "truck"에 도움이 됩니다)
- 혼동을 피하도록 합니다 (반의어, 유사한 철자)
- 자연스러운 표현을 구축하도록 합니다 (연어)

**사용 시점**:
- 과제 생성: 의미적 지식을 테스트하는 연습문제 생성
- 오답 선택: 실제 구별을 테스트하는 오답 선택
- 어휘 확장: 다음에 학습할 관련 단어 제안
- 난이도 계산: 연결이 많은 단어가 더 쉽게 학습됨
- 네트워크 시각화: 학습자에게 어휘가 어떻게 연결되는지 보여주기

---

## 미시적 관점: 직접적 관계

### 의존성 (이 모듈이 필요로 하는 것)

이 모듈은 외부 의존성이 없는 **자체 완결형**입니다. 다음을 포함합니다:
- 내장된 어휘 데이터 (동의어 그룹, 반의어 쌍, 상위어 계층)
- 파일 내 타입 정의

### 종속자 (이 모듈을 필요로 하는 것)

**핵심 모듈:**
- `src/core/priority.ts`: FRE 계산에서 관계적 밀도 사용
- `src/core/tasks/distractor-generator.ts`: 오답지에 동의어/반의어 사용
- `src/core/content/content-generator.ts`: 맥락을 위한 의미장 사용

**서비스 계층:**
- `src/main/services/pmi.service.ts`: PMI를 의미 관계로 보완
- `src/main/services/task-generation.service.ts`: 과제 생성에 의미 데이터 사용

**렌더러:**
- `src/renderer/components/analytics/NetworkGraph.tsx`: 의미 네트워크 시각화

### 데이터 흐름

```
사용자가 "happy" 단어를 학습 중
            |
            v
findSynonyms("happy")  -----> ["joyful", "cheerful", "glad", "delighted"]
            |
            v
findAntonyms("happy")  -----> ["sad", "unhappy"]
            |
            v
buildSemanticNetwork("happy", depth=2)
            |
            v
+-------------------------------------------------------+
|  네트워크 시각화:                                       |
|  - 중심: "happy"                                      |
|  - 연결됨: 동의어, 반의어                               |
|  - 확장됨: 깊이 2의 관련 단어들                          |
+-------------------------------------------------------+
```

---

## 거시적 관점: 시스템 통합

### 아키텍처 계층

이 모듈은 IRT, FSRS, PMI와 함께 **핵심 알고리즘** 계층에 위치합니다:

```
+-----------------------------------------------+
| 렌더러: NetworkGraph 시각화                     |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 서비스: 과제 생성, PMI 분석                      |
+-----------------------------------------------+
                    |
                    v
+-----------------------------------------------+
| 핵심 알고리즘:                                  |
|   IRT    FSRS    PMI    SEMANTIC-NETWORK      |  <-- 현재 위치
|                          (이 모듈)             |
+-----------------------------------------------+
```

### 전체적 영향

의미 네트워크는 LOGOS에 **언어학적 지능**을 제공합니다:

| 기능 | 의미 네트워크가 가능하게 하는 것 |
|---------|--------------------------------|
| 오답지 생성 | 의미적으로 관련된 오답이 실제 지식을 테스트함 |
| 어휘 확장 | "X를 알고 있으니 다음에 Y를 배우세요" 추천 |
| 난이도 추정 | 네트워크 위치가 학습 난이도에 영향 |
| 맥락 생성 | 의미장이 자연스러운 맥락 제공 |
| 오류 분석 | 동의어 혼동이 이해 격차를 드러냄 |

**의미 네트워크 없이는:**
- 오답지가 무작위가 됨 (실제 구별을 테스트하지 않음)
- 어휘 학습이 고립됨 (연결 없음)
- 다음에 무엇을 배울지 제안할 원칙적 방법 없음
- 네트워크 시각화 불가능
- 난이도가 의미적 관계를 무시함

### 임계 경로 분석

**중요도 수준**: 높음 (언어학적 기반)

- **동의어 데이터가 잘못된 경우**: 학습자가 잘못된 의미 정보를 얻음
- **반의어 데이터가 불완전한 경우**: 중요한 대조가 누락됨
- **계층이 잘못된 경우**: 범주 관계가 학습자를 오도함

**데이터 품질**: 내장 데이터는 일반적인 영어 어휘를 다룹니다. 특정 분야 어휘(의학, 법률)의 경우 추가 소스가 필요할 수 있습니다.

---

## 어휘 관계 유형

### 동의어 (동일한 의미)

**정의**: 유사한 의미를 가지며 때때로 서로 대체할 수 있는 단어들.

**데이터 구조**: `SYNONYM_GROUPS`는 의미 영역별로 동의어를 구성합니다:
```typescript
{
  emotion: [
    ['happy', 'joyful', 'cheerful', 'glad', 'delighted', 'pleased'],
    ['sad', 'unhappy', 'sorrowful', 'melancholy', 'dejected'],
    // ...
  ],
  // ...
}
```

**핵심 통찰**: 동의어는 완벽하게 대체 가능하지 않습니다. "Big"과 "large"는 동의어이지만, "big sister"는 "large sister"가 아닙니다. 그룹핑은 대체 가능성이 아닌 의미적 근접성을 보여줍니다.

### 반의어 (반대 의미)

**정의**: 어떤 차원에서 반대 의미를 가진 단어들.

**데이터 구조**: `ANTONYM_PAIRS`는 튜플로 저장됩니다:
```typescript
[
  ['good', 'bad'],
  ['hot', 'cold'],
  ['up', 'down'],
  // ...
]
```

**핵심 통찰**: 반의어에는 유형이 있습니다:
- **등급적**: hot-cold (척도상의 정도)
- **상보적**: dead-alive (중간 지점 없음)
- **관계적**: buy-sell (반대 역할)

### 상위어/하위어 (범주 관계)

**정의**: 상위어 = 더 일반적인 범주 ("animal"). 하위어 = 더 구체적인 유형 ("dog").

**데이터 구조**: `HYPERNYM_HIERARCHIES`는 트리 구조로:
```typescript
[
  ['animal', ['dog', 'cat', 'bird', 'fish', ...]],
  ['dog', ['poodle', 'bulldog', 'labrador', ...]],
  // ...
]
```

**핵심 통찰**: 이것은 상속을 만듭니다. "dog"를 알면, "animal"의 일부 속성을 이미 알고 있는 것입니다. 이것이 전이 학습을 가능하게 합니다.

### 연어 (단어 파트너십)

**정의**: 자연어에서 자주 함께 나타나는 단어들.

**데이터 구조**: `COLLOCATIONS`는 동사를 일반적인 명사 파트너에 매핑합니다:
```typescript
{
  make: ['decision', 'mistake', 'progress', 'effort', ...],
  take: ['time', 'action', 'place', 'risk', ...],
  // ...
}
```

**핵심 통찰**: "Make a decision"은 자연스럽지만; "do a decision"은 그렇지 않습니다. 원어민은 연어를 직관적으로 알지만; 학습자는 명시적으로 습득해야 합니다.

---

## 핵심 함수

### 조회 함수

| 함수 | 입력 | 출력 | 목적 |
|----------|-------|--------|---------|
| `findSynonyms(word)` | "happy" | ["joyful", "cheerful", ...] | 유사한 의미의 단어 찾기 |
| `findAntonyms(word)` | "hot" | ["cold"] | 반대 의미의 단어 찾기 |
| `findHypernyms(word)` | "dog" | ["animal"] | 범주 찾기 (더 일반적) |
| `findHyponyms(word)` | "animal" | ["dog", "cat", ...] | 유형 찾기 (더 구체적) |
| `findCollocations(word)` | "make" | ["decision", "mistake", ...] | 일반적인 파트너 찾기 |

### 분석 함수

#### `calculateSemanticSimilarity(word1, word2)`

여러 측정값을 사용하여 두 단어가 얼마나 유사한지 계산합니다:

```typescript
{
  word1: "happy",
  word2: "joyful",
  pathSimilarity: 0.9,      // 동의어/계층 거리 기반
  icSimilarity: 0.81,       // 정보 내용 기반
  distribSimilarity: 0.77,  // 공동 출현 기반
  combinedScore: 0.83       // 가중 평균
}
```

**쉬운 설명**: 이것은 유사성을 측정하는 여러 방법을 결합합니다. "Happy"와 "joyful"은 동의어이므로 (높은 경로 유사성), 유사한 의미를 가지므로 (높은 IC), 유사한 맥락에서 나타나므로 (높은 분포적 유사성) 유사합니다.

#### `buildSemanticNetwork(word, depth)`

관련 단어의 그래프를 구성합니다:

```typescript
{
  nodes: [
    { id: "happy", type: "word", centrality: 1.0 },
    { id: "joyful", type: "word", centrality: 0.5 },
    { id: "sad", type: "word", centrality: 0.5 },
    // ...
  ],
  edges: [
    { source: "happy", target: "joyful", relation: "synonym" },
    { source: "happy", target: "sad", relation: "antonym" },
    // ...
  ],
  stats: { nodeCount: 15, edgeCount: 20, averageDegree: 2.67, density: 0.1 }
}
```

**쉬운 설명**: 한 단어에서 시작하여 모든 관계를 통해 바깥쪽으로 탐색합니다. 깊이=1은 직접 이웃을 얻습니다. 깊이=2는 이웃의 이웃을 얻습니다. 결과는 대상 단어를 중심으로 한 미니 네트워크입니다.

#### `calculateNetworkBasedDifficulty(word)`

네트워크 위치를 기반으로 단어를 학습하기가 얼마나 어려운지 추정합니다:

```typescript
{
  difficulty: 0.45,  // 0-1 척도
  factors: {
    synonymDensity: 0.6,    // 동의어가 많을수록 = 더 쉬움 (더 많은 학습 연결고리)
    hierarchyDepth: 0.3,    // 깊을수록 = 더 어려움 (더 전문적)
    polysemy: 0.2,          // 다의어 = 더 어려움
    abstractness: 0.5       // 추상적 = 구체적보다 더 어려움
  }
}
```

**쉬운 설명**: 동의어가 많으면 (여러 이해 방법), 계층에서 너무 깊지 않으면 (너무 전문적이지 않음), 단일 의미를 가지면 (혼란스럽지 않음), 구체적이면 (시각화하기 쉬움) 단어를 배우기 더 쉽습니다.

### 학습 지원 함수

#### `suggestVocabularyExpansion(knownWords, count)`

현재 어휘를 기반으로 다음에 무엇을 배울지 제안합니다:

```typescript
suggestVocabularyExpansion(['happy', 'big', 'run'], 5)
// 반환:
[
  { word: 'joyful', reason: '"happy"의 동의어 - 표현 다양성 확장', priority: 0.8 },
  { word: 'sad', reason: '"happy"의 반대말 - 대조 이해 구축', priority: 0.7 },
  { word: 'large', reason: '"big"의 동의어 - 표현 다양성 확장', priority: 0.8 },
  // ...
]
```

**쉬운 설명**: "happy"를 알면 "joyful"을 배우는 것이 효율적입니다 (서로를 강화합니다). "sad"를 배우면 대조 이해가 구축됩니다. 제안은 이미 알고 있는 것을 고려하여 가치에 따라 우선순위가 매겨집니다.

#### `findBridgeWords(domain1Words, domain2Words)`

두 의미 영역을 연결하는 단어를 찾습니다:

```typescript
findBridgeWords(['patient', 'diagnosis'], ['data', 'analysis'])
// 의료 및 데이터 분석 맥락 모두에 나타나는 단어 반환
```

**쉬운 설명**: 일부 단어는 여러 영역에 속합니다. "Analysis"는 의학과 데이터 과학을 연결합니다. "Treatment"는 의학과 심리학을 연결합니다. 다리 단어는 학습자가 영역 간에 지식을 전이하도록 돕습니다.

---

## 기술적 개념 (쉬운 설명)

### 동의어 집합 (Synset)

**기술적**: WordNet에서 조직된 것처럼 동일한 기저 개념을 나타내는 어휘 항목(표제어)의 집합.

**쉬운 설명**: 같은 것을 의미하는 단어 그룹. "happiness"의 동의어 집합에는 그 개념을 나타내는 "felicity," "joy" 및 기타 단어가 포함됩니다. 각 동의어 집합은 하나의 의미를 포착합니다 - 여러 의미를 가진 단어는 여러 동의어 집합에 속합니다.

**사용 이유**: 동의어 집합은 단어 의미를 구별하는 데 도움이 됩니다. "Bank" (금융)와 "bank" (강둑)는 다른 동의어 집합입니다. 이것은 관련 없는 의미를 혼동하는 것을 방지합니다.

### 상위어 / 하위어

**기술적**: IS-A 계층에서 상위어는 더 일반적인 용어이고 하위어는 더 구체적인 용어입니다. "Dog" IS-A "animal" (animal = 상위어, dog = 하위어).

**쉬운 설명**: 범주의 가계도와 같습니다. "Animal"이 부모이고, "dog"가 자식입니다. 부모를 알면 자식을 이해하는 데 도움이 되고 (개는 동물의 속성을 가짐) 그 반대도 마찬가지입니다 (개를 알면 동물에 대해 무언가를 알게 됨).

**사용 이유**: 범주 관계는 전이를 가능하게 합니다. "vehicle"을 배우면 공유 속성 때문에 "car," "bus," "truck"이 더 쉬워집니다.

### 연어 (Collocation)

**기술적**: 우연히 예상되는 것보다 더 자주 함께 나타나는 단어 시퀀스로, 종종 반고정 표현을 형성합니다.

**쉬운 설명**: 원어민에게 "옳게 들리는" 단어 파트너십. "Heavy rain" (자연스러움), "strong rain" (부자연스러움). "Make a decision" (자연스러움), "do a decision" (부자연스러움).

**사용 이유**: 연어는 유창성에 매우 중요합니다. 올바른 연어를 사용하는 학습자는 자연스럽게 들립니다; 그렇지 않은 학습자는 완벽한 문법에도 외국인처럼 들립니다.

### 의미적 유사성

**기술적**: 어휘 계층에서의 위치, 정보 내용 및/또는 분포 패턴에서 계산된 두 단어가 의미에서 얼마나 가까운지의 측정값.

**쉬운 설명**: 두 단어가 얼마나 유사한지 말하는 숫자 (0-1). "Big"과 "large" = 0.9 (매우 유사). "Big"과 "small" = 0.3 (관련되지만 반대). "Big"과 "democracy" = 0.1 (관련 없음).

**사용 이유**: 유사성은 오답지 선택 (유사하지만 틀린 답), 동의어 제안 및 어휘 구성에 도움이 됩니다.

### 네트워크 중심성

**기술적**: 연결의 수와 품질을 기반으로 한 그래프에서 노드의 중요성 측정값.

**쉬운 설명**: 어휘 네트워크에서 단어가 얼마나 "중심적"인지. "good," "make," "have"와 같은 높은 중심성 단어는 많은 다른 단어에 연결됩니다. "quixotic"과 같은 낮은 중심성 단어는 더 고립되어 있습니다.

**사용 이유**: 중심 단어는 종종 높은 가치의 학습 대상입니다 (많은 관련 단어의 이해를 열어줍니다).

---

## 데이터 범위

### 동의어 그룹

| 영역 | 그룹 | 총 단어 |
|--------|--------|-------------|
| 크기 | 4 그룹 | ~20 단어 |
| 감정 | 5 그룹 | ~30 단어 |
| 이동 | 3 그룹 | ~15 단어 |
| 발화 | 5 그룹 | ~25 단어 |
| 인지 | 4 그룹 | ~20 단어 |
| 품질 | 5 그룹 | ~25 단어 |
| 수량 | 4 그룹 | ~20 단어 |
| 시간 | 4 그룹 | ~20 단어 |

### 반의어 쌍

- 50개 이상의 일반적인 반의어 쌍
- 형용사, 동사 및 일부 명사 포함
- 등급적 및 상보적 반의어 모두

### 상위어 계층

- 20개 이상의 계층
- 구체적인 명사 포함 (동물, 차량, 음식)
- 상위어당 5-10개의 하위어

### 연어

- 10개의 고빈도 동사
- 동사당 10개의 연어
- 학습자에게 문제가 되는 조합에 초점

---

## 한계 및 향후 작업

### 현재 한계

1. **영어만**: 다국어 지원 없음
2. **일반 어휘**: 특정 분야 용어는 추가 소스 필요
3. **정적 데이터**: 학습이나 적응 없음
4. **얕은 계층**: 대부분의 경우 2단계만
5. **의미 구별 없음**: 다의어가 단일 단위로 취급됨

### 잠재적 확장

1. **WordNet 통합**: 전체 어휘 데이터베이스 범위
2. **분야 어휘**: 의료, 법률, 기술 하위 집합
3. **임베딩 기반 유사성**: 더 넓은 범위를 위한 신경망 단어 임베딩
4. **다국어 네트워크**: 전이를 위한 L1-L2 매핑
5. **동적 확장**: 사용자 데이터에서 새로운 관계 학습

---

## 변경 이력

### 2026-01-06 - 초기 문서화

- **변경 사항**: semantic-network.ts에 대한 섀도우 문서 생성
- **이유**: 언어학 모듈은 어휘 관계 이해를 위한 문서가 필요함
- **영향**: 개발자와 AI 에이전트가 의미 네트워크 구현을 이해할 수 있게 함

### 학술 참고문헌

- Miller, G.A. (1995). WordNet: A Lexical Database for English
- Fellbaum, C. (1998). WordNet: An Electronic Lexical Database
- Turney, P.D. & Pantel, P. (2010). From Frequency to Meaning
- Mikolov, T. et al. (2013). Distributed Representations of Words and Phrases
